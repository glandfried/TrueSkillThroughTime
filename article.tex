\documentclass[article]{jss}
\usepackage[utf8]{inputenc}
% \usepackage{draftwatermark}
% \SetWatermarkText{Draft}
% \SetWatermarkScale{2}
\newif\ifen
\newif\ifes
\newcommand{\en}[1]{\ifen#1\fi}
\newcommand{\es}[1]{\ifes#1\fi}
\entrue
\usepackage[utf8]{inputenc}
\usepackage{paracol}
%\newcommand{\jan}{%
%  \en{January}%
%  \es{Enero}
%}

\newcommand\Wider[2][3em]{%
\makebox[\linewidth][c]{%
  \begin{minipage}{\dimexpr\textwidth+#1\relax}
  \raggedright#2
  \end{minipage}%
  }%
}

\usepackage{wrapfig}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath} %para escribir funci\'on partida , matrices
\usepackage{amsthm} %para numerar definciones y teoremas
\usepackage{amsfonts} % \mathbb{N} -> conjunto de los n\'umeros naturales

\usepackage{bm} % \bm{\alpha} bold greek symbol
\usepackage[makeroom]{cancel} % \cancel{} \bcancel{} etc
\usepackage{wrapfig} % \begin{wrapfigure} Pone figura al lado del texto
\usepackage{mdframed}
\usepackage{algorithm}
\usepackage{comment}
%\usepackage{quoting}
\usepackage{mathtools}
\usepackage{tikz}
\usepackage{csvsimple}
\usepackage{listings}
\renewcommand{\lstlistingname}{Code}% Listing -> Algorithm
\usepackage{hyperref}
\usepackage{todonotes}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\definecolor{julia}{rgb}{1, 0.8, 1}
\definecolor{python}{rgb}{0.8, 0.9, 1}
\definecolor{r}{rgb}{0.8, 1, 0.8}
\definecolor{all}{rgb}{0.85, 0.85, 0.85}



\input{tikzlibrarybayesnet.code.tex}

\newcommand{\vm}[1]{\mathbf{#1}}
\newcommand{\N}{\mathcal{N}}
\newcommand\hfrac[2]{\genfrac{}{}{0pt}{}{#1}{#2}} %\frac{}{} sin la linea del medio

\usepackage{listings}
\lstset{
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=true,
  columns=flexible,
  basicstyle={\footnotesize\ttfamily},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4,
  showlines=true
}


%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{thumbpdf,lmodern}

%% another package (only for this demo article)
\usepackage{framed}

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}

 
%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Gustavo Landfried \\Universidad de Buenos Aires
   \And Matias Mazzanti \\Universidad de Buenos Aires
   \And Esteban Mocskos \\Universidad de Buenos Aires}
\Plainauthor{Gustavo Landfried, Matias Mazzanti, Esteban Mocskos }

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{TrueSkill Through Time: the \proglang{Julia}, \proglang{Python} and \proglang{R} packages}
\Plaintitle{TrueSkill Through Time: the Julia, Python and R packages}
\Shorttitle{TrueSkill Through Time: the \proglang{Julia}, \proglang{Python} and \proglang{R} packages (Draft)}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  Gustavo Andr\'es Landfried\\
  Departamento de Computaci\'on\\
  Facultad de Ciencias Exactas y Naturales\\
  Universidad de Buenos Aires\\
  Buenos Aires, Argentina\\
  E-mail: \texttt{gustavolandfried@gmail.com}\\

  \vspace{0.3cm}

  Matias Mazzanti\\
  Departamento de F\'isica\\
  Facultad de Ciencias Exactas y Naturales\\
  Universidad de Buenos Aires\\
  Buenos Aires, Argentina\\

  \vspace{0.3cm}

  Esteban Mocskos\\
  Departamento de Computaci\'on\\
  Facultad de Ciencias Exactas y Naturales\\
  Universidad de Buenos Aires\\
  Buenos Aires, Argentina\\
  \emph{and}\\
  Departamento de Computaci\'on\\
  Facultad de Ciencias Exactas y Naturales\\
  Universidad de Buenos Aires\\
  Buenos Aires, Argentina\\
}




























%% - \Abstract{} almost as usual
\Abstract{
 \en{Humans develop complex skills through time.}
 \es{Los humanos desarrollan habilidades complejas a trav\'es del tiempo.}
 %
 \en{Knowing how they change is crucial in many areas, such as educational systems and the video game industry.}
 \es{Saber c\'omo cambian es crucial en muchas \'areas, como los sistemas educativos y la industria de los videojuegos.}
 %
 \en{All widely used skill estimators share the same underlying causal model, but differ in their inferential procedure.}
 \es{Todos los estimadores de habilidad ampliamente utilizados comparten el mismo modelo causal subyacente, pero se diferencian en sus procedimientos metodol\'ogicas.}
 %
 \en{The success of TrueSkill was based on the application of an efficient algorithm to find the best approximation of the exact posterior.}
 \es{El \'exito del TrueSkill se bas\'o en la aplicaci\'on de un algoritmo eficiente para encuentrar la mejor aproximaci\'on del posterior exacto.}
 %
 \en{TrueSkill Through Time is a major enhancement that uses a single generative model for the entire history of activities, rather than a sequence of independent observations, allowing historical information to propagate throughout the system, resulting in better estimates with even less data.}
 \es{TrueSkill Through Time utiliza un único modelo generativo para toda la historia de las actividades, en lugar de una secuencia de observaciones independientes, lo que permite que la informaci\'on hist\'orica se propague por todo el sistema, lo que da lugar a mejores estimaciones con aún menos datos.}
 %
 \en{The use of an efficient algorithm, that requires only a few linear iterations over the data, allows scaling to millions of observations in few minutes.}
 \es{El uso de un algoritmo eficiente, que requiere s\'olo unas pocas iteraciones lineales sobre los datos, permite escalar a millones de observaciones en pocos minutos.}
 %
 \en{This paper offer the first packages for \proglang{Julia}, \proglang{Python}, and \proglang{R} together with its scientific documentation.}
 \es{Mediante este art\'iculo ofrecemos los primeros paquetes para \proglang{Julia}, \proglang{Python} y \proglang{R}, junto con su documentaci\'on cient\'ifica.}
}
\Keywords{Learning, skill, inference, gaming, education, sports, \proglang{Julia}, \proglang{Python},  \proglang{R}}
\Plainkeywords{}


% Para fijar que la siguiente cita la incluya como primer autor y et al. Usar con citas de muchos autores.
\shortcites{Koster2020}
\shortcites{Herrmann2007}
\shortcites{Kschischang2001}
\shortcites{Herbrich2007}
\shortcites{Dangauthier2007}
\shortcites{jaynes2003-bookProbabilityTheory}
\shortcites{VanHorn2003}
\shortcites{maystre2019-pairwise}

\begin{document}
%\lstset{language=Python}

\section[Introduction]{Introduction: } \label{sec:intro}

\en{Humans develop complex skills because of an special integration of biological, cognitive and social processes~\citep{Koster2020}.}
\es{Los humanos desarrollan habilidades complejas gracias a una integraci\'on especial de los procesos biol\'ogicos, cognitivos y sociales~\citep{Koster2020}.}
%
\en{An exceptional cognitive ability to imitate, combined with long periods of juvenile dependency and postreproductive life span, allows humans to learn things from others and transmit innovations through generations~\citep{Richerson2020}.}
\es{Una extraordinaria capacidad para imitar, combinada con los largos per\'iodos de aprendizaje juvenil y vida posreproductiva, permite a los humanos aprender de los dem\'as y transmitir las innovaci\'on a trav\'es de la generaciones~\citep{Richerson2020}.}
%
\en{As a population-based process, human adaptation is also affected by demographic characteristics, such as the size and structure of populations~\citep{Derex2020}.}
\es{Al ser un proceso poblacional, la adaptaci\'on humana tambi\'en se ve afectada por caracter\'isticas demogr\'aficas, como el tama\~no y estructura de las poblaciones~\citep{Derex2020}.} 

%

\en{Knowing how individual skills change over time is essential in sports and educational contexts.}
\es{Conocer c\'omo cambian las habilidades individuales a lo largo del tiempo es esencial para en contextos deportivos y educativos.}
%
\en{Since they are hidden variables, the best we can do is to estimate them based on their direct observable consequences: the outcome of problem solving and competitions.}
\es{Dado que son variables ocultas, lo mejor que podemos hacer es estimarlas a partir de sus consecuencias observables directas: el producto de resoluci\'on de problemas y competencias.}
%
\en{Considering only the frequency of positive results as an indicator of the individuals' ability could lead to wrong approximations, mainly because the outcome also depends on the difficulty of the challenge.}
\es{Considerar s\'olo la frecuencia de resultados positivos como indicador de la habilidad de los individuos puede conducir a aproximaciones erroneas, fundamentalmente porque su valor depende tambi\'en de la dificultad de los desaf\'ios.}
%
\en{For this reason, all widely used skill estimators are based on pairwise comparisons.}
\es{Por esta raz\'on, todos los estimadores de habilidad ampliamente usados se basan en comparaciones por pares.}
%
\en{Since the first generative models, proposed almost a century ago by~\cite{Thurstone1927} and~\cite{Zermelo1929}, it is assumed that the probability of the observed result $r$ depends on the performance $p$ of the agent $i$ and their opponent $j$, expressed as $P(\, r \,|\, p_i, \, p_j \,)$.}
\es{Desde los primeros modelos generativos, propuestos hace casi un siglo por~\cite{Thurstone1927} y~\cite{Zermelo1929}, se supone que la probabilidad de un resultado observado, $r$, depende del rendimiento, $p$, del agente $i$ y de su oponente $j$, expresada como $P(\, r \,|\, p_i, \, p_j \,)$.}
%
\en{The field continued to progress with the work of~\cite{Bradley1952} and~\cite{Mosteller1951a,Mosteller1951b,Mosteller1951c}, leading to the breakthrough that took place with the methodology developed by~\cite{Elo2008} for the US Chess Federation (USCF), which is still used by the International Chess Federation (FIDE).}
\es{El campo sigui\'o progresando con los trabajos de \cite{Bradley1952} y~\cite{Mosteller1951a,Mosteller1951b,Mosteller1951c}, que condujo al gran avance que tuvo lugar con la metodología desarrollada por~\cite{Elo2008} para la Federaci\'on de Ajedrez de los Estados Unidos (USCF), adoptada hasta el d\'ia de hoy por la Federaci\'on Internacional de Ajedrez (FIDE).}

% Parrafo

\en{All currently widely used skill estimators share some variant of the probabilistic model proposed by Elo~\citep{Glickman1999,Herbrich2007,VanDerLinden2016,Fox2010}.}
\es{Todos los estimadores de habilidad ampliamente utilizados actualmente comparten alguna variante del modelo probabil\'istico propuesto por Elo~\cite{Glickman1999, Herbrich2007, VanDerLinden2016, Fox2010}.}
%
\begin{figure}[h!]
\centering \small
    \tikz{         
    \node[det, fill=black!10] (r) {$r$} ; 
    \node[const, left=of r, xshift=-1.35cm] (r_name) {\small \en{Result}\es{Resultado}:}; 
    \node[const, right=of r] (dr) {\normalsize $ r = (d > 0)$}; 

    \node[latent, above=of r, yshift=-0.45cm] (d) {$d$} ; %
    \node[const, right=of d] (dd) {\normalsize $ d = p_i-p_j$}; 
    \node[const, left=of d, xshift=-1.35cm] (d_name) {\small \en{Difference}\es{Diferencia}:};
    
    \node[latent, above=of d, xshift=-0.8cm, yshift=-0.45cm] (p1) {$p_i$} ; %
    \node[latent, above=of d, xshift=0.8cm, yshift=-0.45cm] (p2) {$p_j$} ; %
    \node[const, left=of p1, xshift=-0.55cm] (p_name) {\small \en{Performance}\es{Rendimiento}:}; 

    \node[accion, above=of p1,yshift=0.3cm] (s1) {} ; %
    \node[const, right=of s1] (ds1) {$s_i$};
    \node[accion, above=of p2,yshift=0.3cm] (s2) {} ; %
    \node[const, right=of s2] (ds2) {$s_j$};
    
    \node[const, right=of p2] (dp2) {\normalsize $p \sim \N(s,\beta^2)$};

    \node[const, left=of s1, xshift=-.85cm] (s_name) {\small \en{Skill}\es{Habilidad}:}; 
    
    \edge {d} {r};
    \edge {p1,p2} {d};
    \edge {s1} {p1};
    \edge {s2} {p2};
    %\node[invisible, right=of p2, xshift=4.35cm] (s-dist) {};
}
     \caption{
     \en{Generative model in which skills cause the observable results mediated by the difference of hidden performances, $d =p_i - p_j$, both random variables around their unknown true skill, $p \sim \N(s,\beta^2)$.}
    \es{Modelo generativo en el que las habilidades causan los resultados observables a trav\'es de la diferencia de rendimientos ocultos, $d=p_i-p_j$, ambas variables aleatorias centradas en la verdadera habilidad, $p \sim \N(s,\beta^2)$}
    %
    \en{The one with the highest performance wins, $r = (d > 0)$.}
    \es{Gana quien haya obtenido mayor rendimiento, $r = (d > 0)$.}
    %
    \en{Observable variables are painted gray, hidden in white, and constants are shown as black dots.}
    \es{Las variables observables se pintan de gris, la ocultas en blanco, y las constantes se muestran como puntos negros.}
    }
    \label{fig:generative_model}
\end{figure}
%
\en{Figure~\ref{fig:generative_model} provides a causal model in which skills generates the observable result.}
\es{La figura~\ref{fig:generative_model} ofrece un modelo causal en la que las habilidades generan el resultado observable.}
%
\en{The agents exhibit different performances at each event, varying around their true skill, $\N(p_i\,|\,s_i,\beta^2)$.}
\es{Los agentes exhiben distintos desempe\~nos en cada evento, que var\'ian alrededor de su verdadera habilidad, $\N(p\,|\,s,\beta^2)$.}
%
%
\en{The model assumes that the agent with the highest performance wins, $r = (p_i > p_j)$. In other words, whoever obtains a difference of performance greater than 0 wins, $r = (p_i - p_j > 0)$.}
\es{El modelo supone que gana el agente con mayor rendimiento, $r = (p_i > p_j)$, o en otras palabras, gana quien obtenga una diferencia de rendimiento mayor a 0, $r = (p_i - p_j > 0)$.}
\en{The parameter $\beta^2$ is used as a global scale for the model.}
\es{La varianza $\beta^2$ s\'olo sirve como escala: habilidades separada por un $\beta$ siempre tienen una probabilidad de ganar de 76\%.}

% Parrafo

\en{Using the graphical representation proposed in Fig.~\ref{fig:generative_model}, it is possible to derive the prediction of the result given the previous estimates, $P(\,r\,|\,s_{i_\text{old}},s_{j_\text{old}}\,)$.}
\es{A partir de su representaci\'on gr\'afica se puede derivar entre otras, la predicci\'on del resultado dadas las estimaciones previas, $P(\,r\,|\,s_{i_\text{old}},s_{j_\text{old}}\,)$.}
%
\en{Elo's methodological solution is simple and smart: updates both previous estimates, $s_{i_\text{old}}$ and $s_{j_\text{old}}$, based on the surprise (i.e. the complement of the prediction of the observed result).}
\es{La soluci\'on metodol\'ogica de Elo es simple y astuta: actualizar las estimaciones previas, $s_{i_\text{old}}$ y $s_{j_\text{old}}$, en base a la sorpresa (i.e. el complemento de la predicci\'on del resultado observado).}
%
\begin{equation} \label{eq:elo_delta}
 \Delta = \underbrace{\left(1-P(\,r\,|\,s_{i_\text{old}},s_{j_\text{old}}\,)\right)}_{\text{\en{Surprise}\es{Sorpresa}}}
\end{equation}
%
\en{where the probability arises from instantiating the previous estimates, $s_{i_\text{old}}$ and $s_{j_\text{old}}$, in the generative model (more details in section~\ref{sec:exactSolution}).}
\es{Donde la probabilidad surge de instanciar las estimaciones previas en el modelo generativo (detalles en la secci\'on~\ref{sec:exactSolution}).}
%
\en{The idea is that the magnitude of the surprise $\Delta$ is related to the accuracy of the previous estimates and, therefore, can be used to update them.}
\es{La idea es que la magnitud de la sorpresa $\Delta$ est\'a relacionada con cuan buenas son las estimaciones previas, y por lo tanto puede usarse para actualizarlas.}
%
\en{Unexpected results would indicate that current estimates should be updated to a greater extent than if they had occurred as expected.}
\es{Los resultados inesperados indicar\'ian que las estimaciones actuales no son del todo correctas y deber\'ian actualizarse en mayor medida que si hubieran ocurrido como se esperaba.}
%
\begin{equation}\label{eq:elo_update}
 s_{\text{winner}_\text{new}} = s_{\text{winner}_\text{old}} + \Delta \ \ \ \ \ s_{\text{loser}_\text{new}} = s_{\text{loser}_\text{old}} - \Delta 
\end{equation}
%
\en{where the surprise $\Delta$ acts as a correction factor for both previous estimates.}
\es{Donde la sorpresa $\Delta$ act\'ua como factor de correcci\'on para ambas estimaciones previas.}
%
\en{This procedure can recover the relative scale of the agents, starting from arbitrary initial values.}
\es{Esta soluci\'on puede recuperar la escala relativa de los agentes, partiendo de de valores iniciales arbitrarios.}
%
\en{However, it does have a major weaknesses.}
\es{Sin embargo, tiene algunas debilidades importantes.}
%
\en{The update rule (Eq.~\ref{eq:elo_update}) is symmetric: what one agent wins is lost by the other.}
\es{La regla de actualizaci\'on (Eq.~\ref{eq:elo_update}) es sim\'etrica, as\'i que lo que un agente gana el otro lo pierde.}
%
\en{Because new agents start with arbitrary skills (the same initial value is used for all individuals), they tend to generate greater surprise values and abruptly modify estimates that had already converged.}
\es{Debido a que a los agentes nuevos comienzan con estimaciones arbitrarias (el mismo valor inicial para cualquier individuo), ellas tienden a generan alta sorpresa y a modificar bruscamente estimaciones que ya hab\'ian convergido.}
%
\en{This weakness emerges because the skill estimation's uncertainties are not considered.}
\es{Esta debilidad ocurre porque no se tiene en cuenta la incertidumbre sobre las estimaciones de cada agente.}
%
\en{An ad-hoc solution was proposed to solve this problem: reducing the impact of the surprise based on the number of times the agent has participated previously.}
\es{Para resolver este problema, una soluci\'on ad-hoc fue propuesta: reducir el impacto de la sorpresa en funci\'on de la cantidad de veces que el agente ha participado previamente.}
%
% \en{This is the role played by the K-factor used by FIDE,  $\Delta_i = \Delta \cdot K_i$.}
% \es{Ese es rol que desempe\~na el K-factor usado por la FIDE, $\Delta_i = \Delta \cdot K_i$.}

% Cambio de parrafo

\en{Instead of selecting a single value as an estimate, an enhancement consists of distributing the certainty among all possible skill hypotheses.}
\es{En vez de seleccionar un \'unico valor como estimaci\'on, una alternativa superadora consiste en cuantificar la ``certidumbre relativa'' entre todas las posibles hip\'otesis de habilidad.}
%
\en{This approach known as \emph{Bayesian inference} has proven successful in practice~\citep{Bishop2006} and ensures consistent reasoning when handling uncertainty (plausible beliefs)~\citep{jaynes2003-bookProbabilityTheory,VanHorn2003}.}
\es{Este enfoque conocido como inferencia bayesiana ha demostrado ser exitoso en la pr\'actica~\citep{Bishop2006} y garantiza un razonamiento consistente en el manejo de la incertidumbre (o creencias plausibles)~\citep{jaynes2003-bookProbabilityTheory,VanHorn2003}.}
%
\en{Any inference, independently of its complexity, can be solved by the rules of probability: the~\ref{eq:sum_rule} and the~\ref{eq:product_rule}.}
\es{Toda inferencia, no importa cuan compleja sea, puede ser resuelta mediante las reglas de la probabilidad: la~\ref{eq:sum_rule} y la~\ref{eq:product_rule}.}
%
\en{The \ref{eq:sum_rule} states that any marginal distribution can be obtained by integrating, or summing up, the joint distribution:}
\es{La \ref{eq:sum_rule} afirma que cualquier distribuci\'on marginal se puede obtener integrando o sumando la distribuci\'on conjunta.}
%
\begin{equation} \label{eq:sum_rule}
 \tag{\en{sum rule}\es{regla de la suma}}
 P(x) = \sum_{y} P(x,y) \ \ \ \ \ \text{or} \ \ \ \ \ p(x) = \int p(x,y) \, dy
\end{equation}
%
\en{where $ P(\cdot)$ and $p(\cdot)$ represent discrete and continuous probabilities distributions respectively.}
\es{Donde $P(\cdot)$ y $p(\cdot)$ representan distribuciones de probabilidad discretas y continuas respectivamente.}
%
\en{Additionally, the \ref{eq:product_rule} states that any joint distribution can be expressed as the product of one-dimensional conditional distributions.}
\es{Adem\'as, la \ref{eq:product_rule} se\~nala que cualquier distribuci\'on conjunta puede ser expresada como el producto de distribuciones condicionales uni-dimensionles.}
%
\begin{equation}\label{eq:product_rule}
\tag{\en{product rule}\es{regla del producto}}
 p(x,y) = p(x|y) p(y)
\end{equation}
%
%
\en{From these rules and the symmetry property $p(x,y) = p(y,x)$, we immediately obtain the~\ref{eq:bayes_theorem}:}
\es{De estas reglas y la propiedad de simetr\'ia $p(x,y) = p(y,x)$, obtenemos inmediatamente el~\ref{eq:bayes_theorem},}
%
\begin{equation}\label{eq:bayes_theorem}
\tag{\en{Bayes' theorem}\es{Teorema de bayes}}
 p(y|x) = \frac{p(x|y)p(y)}{p(x)}
\end{equation}
%
% \en{The inferential use of Bayes' theorem plays a central role in modern statistical learning techniques.}
% \es{El uso inferencial del teorema de bayes juega un rol central en las t\'ecnicas modernas de aprendizaje estad\'isitico.}
%
\en{The \ref{eq:bayes_theorem} allows us to optimally update our beliefs about the hypotheses, given a model and the data.}
\es{El \ref{eq:bayes_theorem} permite actualizar de forma \'optima las creencia sobre las hip\'otesis, dado un modelo y los datos.}
%
\en{In our case, to quantify the relative certainty of the skill hypotheses using the information provided by the observed result and the described causal model, we need to solve:}
\es{En nuestro caso, para cuantificar la certidumbre relativa de las hip\'otesis de habilidades utilizando la informaci\'on que nos ofrece el resultado observado y el modelo causal descrito, necesitamos resolver:}
%
\begin{equation}\label{eq:event_inference} 
 \underbrace{p(\overbrace{\text{\en{Skill}\es{Habilidad}$_i$}}^{\text{\en{Hidden}\es{Oculta}}}|\overbrace{\text{Result\es{ado}}}^{\text{Observ\en{ed}\es{ado}}}, \text{Model\es{o}})}_{\text{Posterior}} = \frac{\overbrace{P(\,\text{Result\es{ado}}\,|\,\text{\en{Skill}\es{Habilidad}$_i$}\,,\text{Model\es{o}})}^{\text{\en{Likelihood}\es{Verosimilitud}}}\overbrace{p(\text{\en{Skill}\es{Habilidad}$_i$})}^{\text{Prior}}}{\underbrace{P(\text{Result\es{ado}}\,|\,\text{Model\es{o}})}_{\text{Evidenc\en{e}\es{ia} o\en{r}\es{ predicci\'on a} prior \en{prediction}}}}
\end{equation}
%
\en{where the only free variable is the skill hypothesis of agent $i$.}
\es{Donde la única variable libre es la hip\'otesis de habilidad del agente $i$.}
%
\en{The prior quantifies the uncertainty about the known player's skill and the posterior decreases this uncertainty based on the information provided by the data (i.e. the result) and the given the model.}
\es{El prior cuantifica la incertidumbre previa, y el posterior la reduce en base a la informaci\'on provista por el dato, dado el modelo.}
%
\en{The likelihood and the evidence are both probabilities of the observed result, so they can be seen as predictions (since the results are discrete variables, those probabilities are expressed using capital letters).}
\es{La verosimilitud como la evidencia son ambas probabilidades del resultado observado, por lo que pueden ser vistas como predicciones (como los resultados son variables discretas, esas probabilidad se escribe con letras mayúsculas).}
%
\en{Because the evidence is the same for all hypotheses, the only factor that updates our beliefs is the likelihood.}
\es{Debido a que la evidencia es la misma para todas las hip\'otesis, el único factor que actualiza nuestras creencias es la verosimilitud.}

% Parrafo

\en{As an instance, let's consider a winning case ($p_i > p_j$) using a Gaussian prior (i.e. $\N(\,s\,|\,\mu, \sigma^2)$) for each of the skill estimations.}
\es{A modo de ejemplo, consideremos un caso ganador ($p_i > p_j$) usando priors Gaussianos, $\N(\,s\,|\,\mu, \sigma^2)$.}
%
\en{The difference of performances, $d=p_i-p_j$, can also be expressed as a Gaussian distribution, centered on the difference of the prior estimate means ($\mu_i -\mu_j$), with a variance that incorporates the uncertainty of both estimates ($\sigma$) and the variance of both performances ($\beta$), $\N( d \, | \, \mu_i -\mu_j \, ,\ 2\beta^2 + \sigma_i^2 + \sigma_j^2 \,)$.}
\es{La diferencia de rendimientos, $d=p_i-p_j$, tambi\'en se puede expresar como una Gaussiana centrada en la diferencia de las medias de las estimaciones a priori ($\mu_i - \mu_j$), con una varianza que incorpora la incertidumbre de ambas estimaciones ($\sigma$) y la varianza de ambos rendimientos ($\beta$), $\N(\, d \, | \, \mu_i -\mu_j \, ,\ 2\beta^2 + \sigma_i^2 + \sigma_j^2 \,)$.}
%
\en{As we observed that the agent $i$ won, we know from the causal model that the hidden difference of performances was, indeed, positive.}
\es{Como observamos que el agente $i$ gan\'o, sabemos por el modelo causal que la diferencia de rendimientos oculta fue en efecto positiva.}
%
\en{Therefore, the prior prediction of the observed result (or evidence) is the cumulative density, $\Phi$, of all positive values of the difference of performances (Eq.~\ref{eq:evidence}).}
\es{Por lo tanto, la predicci\'on a priori del resultado observado (o evidencia) es la densidad acumulada, $\Phi$, de todos los valores positivos de la diferencia de rendimientos (Eq.~\ref{eq:evidence}).}
%
\en{From now on the role of the model will be left implicit.}
\es{A partir de ahora el rol del modelo se dejr\'a impl\'icito.}
%
\begin{equation}\label{eq:evidence}
 \overbrace{P(r)}^{\text{Evidenc\en{e}\es{ia}}} = 1-\Phi(0 \, | \overbrace{\mu_i^{\phantom{2}} - \mu_j}^{\hfrac{\text{\en{Expected}\es{Diferencia}}}{\text{\en{difference}\es{esperada}}}} , \, \overbrace{2\beta^2 + \sigma_i^2+ \sigma_j^2}^{\hfrac{\text{\en{Total}\es{Incertidumbre}}}{\text{\en{uncertainty}\es{total}}}})
\end{equation}
%
\en{The evidence is a prediction made with all the prior hypotheses.}
\es{La evidencia es una predicci\'on hecha con todas las hip\'otesis a priori.}
%
\en{Since the evidence is a constant value, the posterior uncertainty of each hypothesis is proportional to the product of their prior uncertainty and their likelihood, as shown in equation~\ref{eq:posterior_win}.}
\es{Como la evidencia es constante, la incertidumbre a posteriori de cada hip\'otesis es proporcional al producto de su incertidumbre a priori y su verosimilitud, como se muestra en la ecuaci\'on~\ref{eq:posterior_win}.}
%
\en{Section~\ref{sec:exactSolution} shows how these equations arise by applying the sum and product rule over the model.}
\es{En la secci\'on~\ref{sec:exactSolution} veremos en detalle c\'omo todas estas ecuaciones surge de aplicar las reglas de las suma y el producto sobre el modelo.}
%
\begin{equation}\label{eq:posterior_win}
\underbrace{p(\,s_i\, | \, r \, )}_{\text{Posterior}} \propto \underbrace{1-\Phi(0 \, |  s_i - \mu_j , \, 2\beta^2 + \sigma_j^2)}_{\text{\en{Likelihood}\es{Verosimilitud}} \ P(r|s_i)} \,  \underbrace{\N(s_i \, | \, \mu_i,\, \sigma_i^2)}_{\text{Prior} \ p(s_i)} 
\end{equation}
%
% \begin{equation}\label{eq:posterior_win}\tag{\text{mejor esta?}}
% \textcolor{black!60}{
% \underbrace{p(\,s_i\, | \, r \, )}_{\text{Posterior}} = \frac{ \overbrace{1-\Phi(0 \, | s_i^{\textcolor{white}{2}} - \mu_j , \, 2\beta^2 + \sigma_j^2)}^{\text{\en{Likelihood}\es{Verosimilitud}}} \,  \overbrace{\N(s_i \, | \, \mu_i,\, \sigma_i^2)}^{\text{Prior}} }{\underbrace{1-\Phi(0 \, | \mu_i - \mu_j , \, 2\beta^2 + \sigma_i^2+ \sigma_j^2)}_{\text{Evidenc\en{e}\es{ia}}}}
% }
% \end{equation}
%
\en{The normalized posterior can be found dividing the right hand by the evidence $P(r)$.}
\es{Donde el el posterior normalizado se obtiene dividiendo el lado derecho por la evidencia, $P(r)$.}
%
\en{It is interesting to note the similarities and differences between likelihood and evidence.}
\es{Es interesante notar las similitudes y diferencias entre el likelihood y el evidencia.}
%
\en{The likelihood quantifies the same cumulative density as the evidence, but now centered at the difference between the hypothesis we are evaluating $s_i$ and the opponent's mean estimate $\mu_j$, with a variance that includes all uncertainties except the one of $s_i$.}
\es{La verosimilitud cuantifica la misma densidad acumulada que la evidencia, pero centrada ahora en la diferencia entre la hip\'otesis que estamos evaluando $s_i$ y la estimaci\'on media del oponente $\mu_j$ con una varianza que incluye todas las incertidumbres salvo la de la propia hip\'otesis $s_i$.}
%
\en{In other words, the likelihood is just the prior prediction of the observed result assuming true the skill hypothesis we are evaluating.}
\es{En otras palabras, la verosimilitud no es m\'as que la predicci\'on a priori del resultado observado suponiendo verdadera la hip\'otesis de habilidad que estamos evaluando.}
%, made with all the skill opponent's hypotheses,
% \en{For each hypothesis $s_i$, the filtered density is exactly proportional to the magnitude of the surprise, defined as the complement of the likelihood.}
% \es{Para cada hip\'otesis $s_i$, la masa filtrada es exactamente proporcional a la magnitud de la sorpresa, definida como el complemento de la verosimilitud.}
%
\en{Figure~\ref{fig:posterior_win} shows, in graphical terms, the updating procedure executed in equation~\ref{eq:posterior_win}.}
\es{La figura~\ref{fig:posterior_win} muestra, en t\'erminos gr\'aficos, el procedimiento de actualizaci\'on que se realiza en la ecuaci\'on~\ref{eq:posterior_win}.}
%
\begin{figure}[h!]
    \centering
    \en{\includegraphics[page={1},width=.6\linewidth]{figures/posterior_win}}
    \es{\includegraphics[page={2},width=.6\linewidth]{figures/posterior_win}}
    \caption{
    %
    \en{Belief update for the winning case.}
    \es{Actualizaci\'on de creencias para el caso ganador.}
    %
    \en{The proportinal posterior is obtained as the product of the prior (Gaussian) and the likelihood (cumulative Gaussian).}
    \es{El posterior proporcional se obtiene como el producto de la distribuci\'on a priori (distribuci\'on Gaussiana) y la verosimilitud (distribuci\'on Gaussiana acumulada).}
    %
    \en{The evidence is the integral of the proportional posterior.}
    \es{La evidencia es la integral del posterior proporcional.}
    %
    \en{The distributions are not neccesary on the same scale: the prior integrates 1, while the likelihood goes from 0 to 1.}
    \es{Las distribuciones no est\'an necesariamente en la misma escala: la distribuci\'on a priori integra 1, mientras que la verosimilitud va de 0 a 1.}
    }
    \label{fig:posterior_win}
\end{figure}
%
\en{The surprise, defined as the complement of the likelihood, works as a filter for the prior.}
\es{La sorpresa, definida como el complemento de la verosimilitud, funciona como un filtro para el prior.}
%
\en{The posterior is just the density of the prior not filtered by the likelihood.}
\es{El posterior no es m\'as que la densidad del prior no filtrada por la verosimilitud.}
%    
\en{At the region of very high skill hypotheses, where the winning result would have generated almost no surprise ($\lim_{s_i \to \infty}P(r|s_i) = 1$), the posterior receives almost all the density of the prior.}
\es{En la regi\'on de hip\'otesis de muy alta habilidad, donde el resultado ganador no nos hubiera generado casi ninguna sorpresa ($\lim_{s_i \to \infty}P(r|s_i) = 1$), el posterior recibe casi toda la masa del prior.}
%
\en{At the region of very low skill hypotheses, where the winning result would have generated a lot of surprise ($\lim_{s_i \to -\infty}P(r|s_i) = 0$), the posterior receives almost no density from the prior.}
\es{En cambio, en la regi\'on de hip\'otesis de muy baja habilidad, donde el resultado habr\'ia generado mucha sorpresa ($\lim_{s_i \to -\infty}P(r|s_i) = 0$), el posterior no recibe casi nada de la masa del prior.}

% Parrafo

\en{It is important to stress that the posterior, although similar, is not a Gaussian distribution, preventing us from using equation~\ref{eq:posterior_win} iteratively.}
\es{Es importante remarcar que la posterior, aunque se parezca, no es una distribuci\'on Gaussiana, lo que nos impedir\'a usar la ecuaci\'on~\ref{eq:posterior_win} iterativamente.}
%
\en{But due to the shape of the exact posterior, a Gaussian distribution could be used as a good approximation, allowing us to avoid the computational cost of the sampling methodologies.}
\es{Por la forma del posterior exacto, una Gaussiana parece una aproximaci\'on suficientemente buena, que nos permitir\'ia evitar el costo computacional de las metodolog\'ias de sampleo.}
%
\en{The main contribution of the Glicko system~\citep{glikman_gliko_2} was the development of an efficient method to approximate the exact posterior using a Gaussian distribution.}
\es{El principal aporte del sistema Glicko~\citep{glikman_gliko_2} fue el desarroll\'o de un m\'etodo eficiente para aproximar la posterior exacta con una distribuci\'on Gasussiana.}
%
\en{However, this method does not guarantee the quality of the approximation used.}
\es{Sin embargo, esta no ofrece garant\'ias de que la Gaussiana seleccionada sea la que mejor aproxima.}
%
\en{The success of the TrueSkill solution~\citep{Herbrich2007} is based on the application of an efficient method for computing the Gaussian distribution that best approximates the exact posterior (section~\ref{sec:approximate_posterior}).}
\es{El \'exito de la soluci\'on TrueSkill~\citep{Herbrich2007} se basa en la aplicaci\'on de m\'etodo eficiente para calcular la Gaussiana que mejor aproxima a la posterior exacta (secci\'on~\ref{sec:approximate_posterior}).}
%
\begin{equation} \label{eq:approx} 
 \widehat{p}(s_i| r, s_j) = \underset{\mu, \sigma}{\text{ arg min }} \ \ \text{KL}(\, p(s_i| r, s_j) \, || \,  \N(s_i|\mu, \sigma^2) \, )
\end{equation}
%
\en{This kind of methods, which minimize the Kullback-Leibler divergence between the true and the approximate distribution, allows to perform Bayesian inference in situations that otherwise would be impossible.}
\es{Esta clase de m\'etodos, que minizan la divergencia Kullback-Leibler entre la distribuci\'on verdadera y aproximada, permiten realizar Inferencia Bayesiana en situaciones que de otra forma no ser\'ia posibles.}
%
\en{In our case, in which we need to know how skills change over time, this technique allows us to efficiently apply the equation~\ref{eq:posterior_win} iteratively over a sequence of observations.}
\es{En nuestro caso, en el que necesitamos conocer c\'omo cambian las habilidades a trav\'es del tiempo, est\'a t\'ecnica nos permite aplicar eficientemente la ecuaci\'on~\ref{eq:posterior_win} iterativamente sobre una secuencia de observaciones.}

%

\en{The approach adopted by TrueSkill to treat the dynamical process, known as \emph{filtering}, uses the posterior as the prior for the next event.}
\es{El enfoque adoptado por TrueSkill para tratar el proceso din\'amico, conocido como \emph{filtering}, usa el posterior como prior del siguiente evento.}
%
\en{Then, the posterior at any given time is,}
\es{Luego, el posterior en un determinado momento es,}
%
\begin{equation}\label{eq:filter} %\tag{\text{filtering}}
 \widehat{\text{Posterior}}_t \propto \widehat{\text{Likelihood}}_t  \overbrace{\widehat{\text{Likelihood}}_{t-1} \dots \widehat{\text{Likelihood}}_{2} \underbrace{\widehat{\text{Likelihood}}_{1} \text{Prior}_1}_{\widehat{\text{Posterior}}_{1} \text{ \en{as}\es{como} } \text{Prior}_{2}} }^{\widehat{\text{Posterior}}_{t-1} \text{ \en{as}\es{como} } \text{Prior}_{t}} %= \text{Prior}_1 \prod_{i=1}^t \text{Likelihood}_i 
\end{equation}
%
\en{where {\footnotesize $\widehat{\text{Posterior}}_i$} and {\footnotesize $\widehat{\text{Likelihood}}_i$} represents the approximations induced by the equation~\ref{eq:approx} at the $i$-est event.}
\es{Donde {\footnotesize $\widehat{\text{Posterior}}_i$} y {\footnotesize $\widehat{\text{Likelihood}}_i$} representan la aproximaciones inducidas por la ecuaci\'on~\ref{eq:approx} en el $i$-\'esimo evento.}
%
\en{If we consider the likelihood as a filter of the prior, each posterior can be seen as an accumulation of all previous filters.}
\es{Si consideramos la verosimilitud como un filtro del prior, cada posterior puede ser visto como una acumulaci\'on de todos los filtros anterios.}
%
\en{In this way, information propagates from past to future estimates.}
\es{De esta forma, la informaci\'on propaga del estimaciones pasadas hacia futuras.}
%
%\en{Learning is a dynamical process.}
%\es{El aprendizaje es un proceso din\'amico.}
%
\en{Since skills are dynamic variables it is important to add some uncertainty $\gamma$ at each step.}
\es{Debido a que las habilidades son variables din\'amicas es importante agregar alguna incertidumbre $\gamma$ en cada paso.}
%
\begin{equation}\label{eq:dynamic_factor}
 \widehat{p}(s_{i_t}) = \N(s_{i_t} | \mu_{i_{t-1}}, \sigma_{i_{t-1}}^2 + \gamma^2 )
 \end{equation}
 %
\en{Because the filtering approach does not arise from any probabilistic model, it suffers from a number of problems related to the fact that the information propagates in only one direction through the system.}
\es{Debido a que el enfoque de filtrado no se surge de ningún modelo probabil\'istico, sufre de un serie de problemas, todos relacionados con el hecho de que la informaci\'on se propaga en una sola direcci\'on a trav\'es del sistema.}
%
\en{The most obvious is that the beginning of any sequence of estimates always has high uncertainty.}
%, making them useless
\es{El m\'as obvio es que el inicio de toda secuencia de estimaciones siempre tiene alta incertidumbre.}
% , lo que las hace inservibles
\en{But it also suffer from ``temporary'' and ``spatial'' decoupling.}
\es{Pero tambi\'en sufre de desacoplamientos ``temporales'' y ``espaciales''.}
%
\en{Although the relative differences between contemporary estimates within well-connected communities are correct, estimates separated in time and between poorly connected communities are often incorrect.}
% preventing comparability over time and between communities.
\es{Aunque la diferencias relativas entre estimaciones contempor\'aneas al interior de comunidades bien conectadas sean correctas, las estimaciones separadas en el tiempo y entre comunidades poco conectadas suelen ser incorrectas.}
% impidiendo as\'i la comparabilidad temporal y entre comunidades.

% Parrafo

\en{To obtain good initial estimates and ensure temporal and spatial comparability we need a causal model of the temporal process that links all historical activities.}
\es{A fin de obtener buenas estimaciones iniciales y garantizar comparbilidad temporal y espacial, necesitamos un modelo causal del proceso temporal que vincule todas las actividades hist\'oricas.}
%
\en{In any video game this typically involves evaluating a complex network made up of millions of events.}
\es{En cualquier video juego esto típicamente implica evaluar una red compleja compuesta por millones de eventos.}
%
% \en{For this reason, figure~\ref{fig:smoothing} shows only the closest neighbors of a sequence of estimates.}
% \es{Por esta raz\'on, la figura~\ref{fig:smoothing} muestra s\'olo los vecinos m\'as pr\'oximos de una secuencia de estimaciones.}
%
\en{This approach, known as \emph{smoothing}, is the one implemented by TrueSkill Through Time~\citep{Dangauthier2007}.}
\es{Este enfoque, conocido como \emph{smoothing}, es el implementado por TrueSkill Through Time~\citep{Dangauthier2007}.}
%
% \begin{figure}[h!]
%   \centering
%   \scalebox{.9}{
%     \tikz{ %
%       \node[latent] (s0) {$s_{i_0}$} ;
%       
%       \node[latent,right=of s0,xshift=-0.15cm] (s1) {$s_{i_1}$} ;
%       \node[latent, below=of s1,yshift=0.3cm] (p1) {$p_{i_1}$};
%       \node[const, below=of p1, yshift=-0.6cm] (t1) {\LARGE $\hfrac{}{\dots}$} ;
% 
%       \node[latent, right=of s1,xshift=-0.15cm] (s2) {$s_{i_2}$} ;
%       \node[latent, below=of s2,yshift=0.3cm] (p2) {$p_{i_2}$};
%       \node[const, below=of p2, yshift=-0.6cm] (t2) {\LARGE $\hfrac{}{\dots}$} ;
%       
%       \node[const, right=of s2, xshift=0.6cm] (s3) {$\dots$} ;
% 
%       \node[latent, right=of s3,xshift=-0.3cm] (sn) {$s_{i_n}$} ;
%       \node[latent, below=of sn,yshift=0.3cm] (pn) {$p_{i_n}$};
%       \node[const, below=of pn, yshift=-0.6cm] (tn) {\LARGE $\hfrac{}{\dots}$} ;
%       
%       \edge {s0} {s1};
%       \edge {s1} {p1,s2};
%       \edge {s2} {p2,s3};
%       \edge {s3} {sn};
%       \edge {sn} {pn};
%       \edge {p1} {t1};
%       \edge {p2} {t2};
%       \edge {pn} {tn};
%       
%       }  
%   }
%   \caption{
%   \en{Schematic representation of a single causal model for the entire history of events.}
%   \es{Representaci\'on esquem\'atica de un único modelo causal para toda la historia de eventos.}
%   %
%   \en{Only the neighbors of a sequence of estimates are displayed.}
%   \es{S\'olo se muestra los vecinos de una secuencia de estimaciones.}
%   %
%   %\en{These types of models are known as \emph{state-space models}.}
% %   %\es{Este tipo de modelos se conocen como \emph{state space models}.}
%   }
%   \label{fig:smoothing}
% \end{figure}
%
\en{By applying the rules of probability over this temporal model, historical information naturally propagate throughout the system, solving the problems of the filtering approach.}
\es{Al aplicar las reglas de la probabilidad sobre este modelo temporal, la informaci\'on hist\'orica propaga naturalmente hacia todo el sistema, resolviendo los problemas del enfoque de filtro.}
%
%\en{Now, the prior at each event $t$ depends on all the past and future information.}
%\es{Ahora, el prior en cada evento $t$ depende de toda la informaci\'on pasada y futura.}
%
\en{Excluding the dynamic component, $\gamma = 0$, the prior of an agent $i$ at the $t$-eth event is just the product of all their likelihoods, except that of the $t$-eth event.}
\es{Exluyendo el aspecto din\'amico, $\gamma = 0$, el prior de un agente $i$ en el $t$-\'esimo evento es el producto del todas sus verosimilitudes, salvo la del $t$-\'esimo evento.}
%
\begin{equation}\label{eq:smooth_prior}
 \text{Prior}_{i_t} = \text{Prior}_{i_0} \underbrace{\prod_{k = 1}^{t-1} \text{\en{Likelihood}\es{Verosimilitud}}_{i_k}}_{\text{\en{Past information}\es{Informaci\'on pasada}}} \underbrace{\prod_{k = t + 1}^{T_i} \text{\en{Likelihood}\es{Verosimilitud}}_{i_k}}_{\text{\en{Future information}\es{Informaci\'on futura}}}
\end{equation}
%
\en{where $T_i$ is the total number of events in which the $i$ agent participated, with {\small Prior$_{i_0}$} the initial prior of agent $i$.}
\es{Donde $T_i$ es la cantidad total de eventos del agente $i$, con {\small Prior$_{i_0}$} el prior inicial del agente $i$.}
%
\en{This produce a mutual dependency between likelihoods, forcing us to implement an iterative algorithm to solve inference (details at secci\'on~\ref{sec:throguthTime}).}
\es{Esto produce una mutua dependencia entre verosimilitudes, oblig\'andonos a implementar un algoritmo iterativo para resolver la inferencia (detalles en la secci\'on~\ref{sec:throguthTime}).}
%
\en{In the first pass, the priors of each event are calculated using only the past likelihoods that have already been defined.}
\es{En la primera pasada, los priors de cada evento se calculan usando s\'olo las verosimilitudes pasadas que ya han sido definidas.}
%
\en{Once all the likelihoods have been calculated, we can run a new pass using the latest available likelihoods.}
\es{Una vez calculadas todas las verosimilitudes, podemos realizar una nueva pasada usando las últimas verosimilitudes disponibles.}
%
%\en{The first likelihoods will necessarily be incorrect because the priors had been partially defined.}
%\es{Las primeras verosimilitudes necesariamente ser\'an incorrectas debido a que los priors habían sido definidos parcialmente.}
%
%\en{But so will be the likelihoods calculated in the second pass, because its outcome will depend partially on the likelihoods calculated in the previous pass.}
%\es{Pero tambi\'en lo ser\'an las verosimilitudes calculadas en la segunda pasada, debido a que su resutado depender\'a parcialmente de las verosimilitudes calculadas en la pasada anterior.}
%
\en{This procedure converge with a few linear iterations over the data.}
\es{Este procedimiento converge con unas pocas iteraciones lineales sobre los datos.}

% Parrafo

\en{TrueSkill Through Time outperforms TrueSkill and others filtering models.}
\es{TrueSkill Through Time supera a TrueSkill y otros modelos de filtrado.}
%
\en{In Figure~\ref{fig:smooth_example} we show the behavior of the estimates in a data set with two agents and two events.}
\es{En la figura~\ref{fig:smooth_example} se muestra el comportamiento de las estimaciones en conjunto de datos de dos agentes y dos eventos.}
\begin{figure}[h!]
  \centering
  \scalebox{.92}{
    \tikz{ %
      \node[latent] (s10) {$s_{a_0}$} ;
      %
      \node[latent,  below=of s10,yshift=-1cm] (s11) {$s_{a_1}$} ;
      
      \node[latent, right=of s11, xshift=3cm] (p11) {$p_{a_1}$} ;
      %
      \node[latent, below=of s11,yshift=-1cm] (s12) {$s_{a_2}$} ;
      \node[latent, right=of s12, xshift=3cm] (p12) {$p_{a_2}$} ;
      
      \node[const, right=of p11,xshift=0.5cm] (r1) {$\bm{>}$} ;
      \node[const, above=of r1, yshift=0.3cm] (nr1) {\footnotesize \ \  Observed result} ;
      \node[const, right=of p12,xshift=0.5cm] (r2) {$\bm{<}$} ;
      \node[const, above=of r2, yshift=0.3cm] (nr2) {\footnotesize \ \ Observed result} ;
      
      \node[latent, left=of s10, xshift=13.4cm] (s20) {$s_{b_0}$} ;
      \node[latent, below=of s20,yshift=-1cm] (s21) {$s_{b_1}$} ;
      \node[latent, left=of s21, xshift=-3cm] (p21) {$p_{b_1}$} ;
      
      \node[latent, below=of s21, yshift=-1cm] (s22) {$s_{b_2}$} ;
      \node[latent, left=of s22, xshift=-3cm] (p22) {$p_{b_2}$} ;
      
      
      \edge {s10} {s11};
      \edge {s11} {s12};
      \edge {s20} {s21};
      \edge {s21} {s22};
      \edge {s11} {p11};
      \edge {s12} {p12};
      \edge {s21} {p21};
      \edge {s22} {p22};
      
      \node[const, right=of s10, yshift=0.6cm ] (wp10) {\includegraphics[page={13},width=.125\linewidth]{figures/smoothing}} ;
      \node[const, left=of s20, yshift=0.6cm ] (wp20) {\includegraphics[page={13},width=.125\linewidth]{figures/smoothing}} ;
      
      
      \node[const, left=of s11, yshift=0.6cm ] (post11) {\includegraphics[page={1},width=.125\linewidth]{figures/smoothing}} ;
      \node[const, right=of s11, yshift=0.6cm ] (wp11) {\includegraphics[page={2},width=.125\linewidth]{figures/smoothing}} ;
      \node[const, left=of p11, yshift=0.6cm ] (lh11) {\includegraphics[page={3},width=.125\linewidth]{figures/smoothing}} ;
      
      \node[const, left=of s12, yshift=0.6cm ] (post12) {\includegraphics[page={4},width=.125\linewidth]{figures/smoothing}} ;
      \node[const, right=of s12, yshift=0.6cm ] (wp12) {\includegraphics[page={5},width=.125\linewidth]{figures/smoothing}} ;
      \node[const, left=of p12, yshift=0.6cm ] (lh12) {\includegraphics[page={6},width=.125\linewidth]{figures/smoothing}} ;
      
      
      \node[const, right=of s21, yshift=0.6cm ] (post21) {\includegraphics[page={7},width=.125\linewidth]{figures/smoothing}} ;
      \node[const, left=of s21, yshift=0.6cm ] (wp21) {\includegraphics[page={8},width=.125\linewidth]{figures/smoothing}} ;
      \node[const, right=of p21, yshift=0.6cm ] (lh21) {\includegraphics[page={9},width=.125\linewidth]{figures/smoothing}} ;
      
      
      \node[const, right=of s22, yshift=0.6cm ] (post22) {\includegraphics[page={10},width=.125\linewidth]{figures/smoothing}} ;
      \node[const, left=of s22, yshift=0.6cm ] (wp22) {\includegraphics[page={11},width=.125\linewidth]{figures/smoothing}} ;
      \node[const, right=of p22, yshift=0.6cm ] (lh22) {\includegraphics[page={12},width=.125\linewidth]{figures/smoothing}} ;
      
      \node[const, above=of post11] (npost11) {\scriptsize Posterior} ;
      \node[const, above=of wp11] (nwp11) {\scriptsize Prior} ;
      \node[const, above=of lh11] (nlh11) {\scriptsize \en{Likelihood}\es{Verosimilitud}} ;
      \node[const, above=of post21] (npost21) {\scriptsize Posterior} ;
      \node[const, above=of wp21] (nwp21) {\scriptsize Prior} ;
      \node[const, above=of lh21] (nlh21) {\scriptsize \en{Likelihood}\es{Verosimilitud}} ;
      
      \node[const, above=of post12] (npost12) {\scriptsize Posterior} ;
      \node[const, above=of wp12] (nwp12) {\scriptsize Prior} ;
      \node[const, above=of lh12] (nlh12) {\scriptsize \en{Likelihood}\es{Verosimilitud}} ;
      \node[const, above=of post22] (npost22) {\scriptsize Posterior} ;
      \node[const, above=of wp22] (nwp22) {\scriptsize Prior} ;
      \node[const, above=of lh22] (nlh22) {\scriptsize \en{Likelihood}\es{Verosimilitud}} ;
      
      \node[const, above=of wp10,yshift=-0.35cm] (nwp10) {\scriptsize Prior} ;
      \node[const, above=of wp20,yshift=-0.35cm] (nwp20) {\scriptsize Prior} ;
      
      }  
  }
  \caption{
  \en{Convergence of TrueSkill Through Time in a history with only two events and two agents.}
  \es{Convergencia de TrueSkill Through Time en una historia con s\'olo dos eventos y dos agentes.}
  %
  \en{The first game is won by the player $a$, $p_{a_1} > p_{b_1}$, and the second is won by the player $b$, $p_{a_2} < p_{b_2}$.}
  \es{La primera partida la gana el jugador $a$, $p_{a_1} > p_{b_1}$, y la segunda la gana el jugador $b$, $p_{a_2} < p_{b_2}$.}
  %
  \en{The brightness of the curves indicates the order of convergence: the darkest are the latest estimates.}
  \es{La luminosidad de las curvas indican el orden en la convergencia.}
  %
  \en{The first one (the clearest) corresponds to the TrueSkill solution.}
  \es{La primera (la m\'as clara) se correponde a la soluci\'on TrueSkill.}
  %
  \en{The last one (the darkest) corresponds to the TrueSkill Through Time solution.}
  \es{La última (la m\'as oscura) se correponde a la soluci\'on TrueSkill Through Time.}
  %
  \en{Once convergence is reached, the posterior is centered at 0 for both players, indicating that they have the same skill.}
  \es{Alcanzada la convergencia, el posterior se centra en 0 para ambos jugadores, indicando que tienen misma habilidad.}
  }
  \label{fig:smooth_example}
\end{figure}
%
\en{TrueSkill Through Time recovers the true differences between hidden skills even at the beginning of the sequence.}
\es{TrueSkill Through Time recupera las verdaderas diferencias entre habilidades ocultas incluso al principio de la secuencia.}
%  
\en{Similar methodologies to TrueSkill Through Time have been developed by \cite{coulom2008-wholeHistoryRating} and \cite{maystre2019-pairwise}.}
\es{Metodologías similares a TrueSkill Through Time han sido desarrollads por \cite{coulom2008-wholeHistoryRating} y \cite{maystre2019-pairwise}.}
%
%\en{This methodology has not been available until now in any of the major programming languages.}
%\es{Esta metodolog\'ia no hab\'ia estado hasta ahora disponible en ninguno de los principales lenguajes de programaci\'on.}
%
\en{With this paper we make available the first TrueSkill Through Time packages for \proglang{Julia}, \proglang{Python} and \proglang{R}, together with its scientific documentation.}
\es{Con este art\'iculo ponemos a disposici\'on los primeros paquetes de TrueSkill Through Time para \proglang{Julia}, \proglang{Python} y \proglang{R}, junto con su documentaci\'on cient\'ifica.}


% \cite{A Guide to state-space modeling of ecological time series}


%En este punto es razonable preguntarse si los priors de los \emph{state-space} model son priors honestos en el sentido de que desconocen la informacion del dato  para el que son priors.
% 
%Si bien en la ecuaci\'on~\ref{eq:smooth_prior} vimos que el prior efectivamente no se multiplica directamente por el likelihood presente, ¿Ser\'a que la informaci\'on de ese likelihood esta siendo incorporada de manera oculta por el algoritmo iterativo?
%
%Si esto fuera as\'i, entonces en cada paso de la convergencia deber\'ia ocurrir que la sorpresa disminuye.
%
%Para responder a este pregunta y para entender el funcionamiento general de los state-space models mostramos en la Figura~\ref{fig:smooth_example} una solcuci\'on de forma gr\'afica.
%
















































































%% -- Manuscript ---------------------------------------------------------------
%% - When describing longer chunks of code that are _not_ meant for execution
%%   (e.g., a function synopsis or list of arguments), the environment {Code}
%%   is recommended. Alternatively, a plain {verbatim} can also be used.
%%   (For executed code see the next section.)

\section{Models and software} 

\en{Driven by the growth in computing power, researchers have developed over the past five decades thousands of successful machine learning algorithms tailored to specific sets of problems.}
\es{Impulsado por la creciento en la capacidad de c\'omputo ocurrida, en las últimas cinco d\'ecadas los investigadores han desarrollado miles de algoritmos exitosos de aprendizaje de autom\'atico, hechos a medida de conjuntos de problemas espec\'ificos.}
%
\en{In contrast, probabilistic inference offers a generally applicable framework~\citep{Bishop2013}.}
\es{Por el contrario, la inferencia probabil\'istica ofrece un marco de aplicaci\'on general~\citep{Bishop2013}.}
%
\en{The assumptions made by standard machine learning algorithms are generally difficult to remember and often difficult to perceive.}
\es{Las suposiciones hechas por los algoritmos est\'andar de aprendizaje autom\'atico son generalmente dif\'iciles de recordar y a menudo dif\'iciles de percibir.}
%
\en{Similarly, the algorithms used vary from application to application, forcing us to learn a variety of methods.}
\es{Del mismo modo, los algoritmos empleadas var\'ian de aplicaci\'on en aplicaci\'on, oblig\'andonos a aprender una gran variedad de m\'etodos.}
%
\en{Instead of having to transform the problem to fit some standard algorithm, probabilistic inference provides the building blocks to solve any specific problem.}
\es{En lugar de tener que transformar el problema para que encaje en algún algoritmo est\'andar, la inferencia probabil\'istica ofrece los bloques de construcci\'on que permiten resolver cualquier problema espec\'ifico.}
%
\en{All the assumptions are made explicit through a generative (or causal) model, which can be intuitively specified in a graphical way.}
\es{Todos los supuestos se hacen expl\'icitos a trav\'es de un modelo generativo (o causal), que puede ser especificado intuitivamente de forma gr\'afica.}
%
\en{Inference can always be solved by applying the rules of probability (the sum and product rules) over the joint distribution represented by the model.}
\es{Y toda inferencia se hace aplicando las reglas de la probabilidad, de la suma y del producto, sobre el modelo representado como una distribuci\'on conjunta.}

% Parrafo

\en{In this section we will explain all the details of the probabilistic framework in the context of the TrueSkill Through Time problem.}
\es{En esta secci\'on explicaremos todos los detalles del marco probabil\'isitico en el contexto del problema TrueSkill Through Time.}
%
\en{In the section~\ref{sec:sumProductAlgorithm} we will introduce the \emph{sum-product algorithm}, which allows to efficiently compute any marginal distribution from a joint distributions.}
\es{En la secci\'on~\ref{sec:sumProductAlgorithm} introduciremos el \emph{sum-product algorithm}, que permite computar eficientemente cualquier distribuciones marginal a partir de una distribuci\'on conjunta.}
%
\en{In the section~\ref{sec:propiedades} we list the properties that we will need to derive the marginal distributions of interest.}
\es{En la secci\'on~\ref{sec:propiedades} enumeramos las propiedades que necesitaremos para derivar las distribuciones marginales de inter\'es.}
%
% Afortunadamente, gracias a la distribuci\'on de probabilidad elegida para representar el modelo causal~\ref{modelo_elo}, la distribuci\'on de creencias a posteriori de la habilidad de los agentes y la predicci\'on a priori del resultado observado (aka evidencia) tienen soluci\'on anal\'itica.
%
\en{In the section \ref{sec:Gasussian}, \ref{sec:rating} and \ref{sec:game} we introduce the implementation details of the classes \texttt{Gaussian}, \texttt{Rating} and \texttt{Game}.}
\es{En las secciones \ref{sec:Gasussian}, \ref{sec:rating} y \ref{sec:game} introducimos los detalles de implementaci\'on de las clases \texttt{Gaussian}, \texttt{Rating} y \texttt{Game}.}
%
\en{In the sections \ref{sec:exactSolution}, \ref{sec:empate}, \ref{sec:approximate_posterior}, and \ref{sec:iterative_posterior} we show respectively how to solve the prior prediction and the exact posterior of an event, we modified the model to include ties, we explain how to approximate the posterior, and we give the general multi-team solution.}
\es{En las secciones \ref{sec:exactSolution}, \ref{sec:empate}, \ref{sec:approximate_posterior}, y \ref{sec:iterative_posterior} mostramos respectivamente c\'omo resolver la predicci\'on a priori y el posterior exacto de un evento, modificamos el modelo para que incluya empates, explicamos c\'omo aproximar el posterior y damos la soluci\'on general multi-equipos.}
%
FALTA HISTORY
% %
% En la secci\'on~\ref{history} mostamos los pasos matem\'aticos requeridos para resolver el modelo TTT.
% %
% En la subsecci\'on~\ref{estructuras} introducimos las estructuras de datos utlizadas para generar la hsitoria.
% %
% En la subsecci\'on~\ref{trueskill} realizamos la inicializaci\'on de la historia, la que genera un resultado equivalente a trueskill.
% %
% En la subseci\'on~\ref{TTT} mostramos el algoritmo utilizado para converger las estmaciones.
% %
% 

\subsection{Sum-product algorithm} \label{sec:sumProductAlgorithm}

\en{The \emph{sum-product algorithm}~\citep{Kschischang2001} is a general procedure that takes advantage of the structure of the joint probability distribution imposed by the causal model to efficiently apply the rules of probability, the \ref{eq:sum_rule} and the \ref{eq:product_rule}.}
\es{El \emph{sum-product algorithm}~\citep{Kschischang2001} es un procedimiento general que aprovecha la estructura de la disstribuci\'on de probabilidad conjunta que impone el modelo causal para aplicar eficientemente las reglas de la probabilidad, la~\ref{eq:sum_rule} y la~\ref{eq:product_rule}.}
%
\en{Represented as joint distributions, the models can be factored into the product of simple conditional probabilities.}
\es{Representados como distribuciones conjuntas, los modelos pueden factorizarse en el producto de probabilidades condicionales simples.}
%
\en{Our generative model (Figure~\ref{fig:generative_model}) can be factored as,}
\es{Nuestro modelo generativo (figura~\ref{fig:generative_model}) puede factorizarse como,}
%
\begin{equation} \label{eq:factorization}
 p(\bm{s},\bm{p},d,r) = p(s_1)p(s_2)p(p_1|s_1)p(p_2|s_2)p(d|\bm{p})P(r|d)
\end{equation}
%
\en{In the Figure~\ref{fig:factor_graph}, we show its factorization graphically.}
\es{En la figura~\ref{fig:factor_graph} mostramos gr\'aficamente la factorizaci\'on.}
%
\en{These types of representations are known as \emph{factor graph}.}
\es{A este tipo de representaciones se las conoce como \emph{factor graph}.}
%
\en{The \emph{factor graph} are bipartite graphs, consisting of variable nodes $v$ and function nodes (or factors) $f$.}
\es{Los \emph{factor graph} son gr\'afos bipartitos, compuestos por nodos variables $v$ y nodos funciones (o factores) $f$.}
%
\en{The edge between variables and functions represent the mathematical relationship ``the variable $v$ is an argument of the function $f$''.}
\es{Los ejes entre variables y funciones representan la relaci\'on matem\'atica ``la variable $v$ es argumento de la funci\'on $f$''.}
%
\begin{figure}[h!]
\centering \small
    \tikz{         
%         \node[const, above=of fr] (nfr) {$f_r$}; %
% 	\node[const, above=of nfr] (dfr) {\large $\mathbb{I}(d >0)$}; %
    
    
    \node[factor] (fr) {} ; 
    %\node[const, left=of fr, xshift=-1.35cm] (r_name) {\small \en{Result}\es{Resultado}:}; 
    \node[const, left=of fr] (nfr) {\normalsize $P(r|d)$}; 
    \node[const, right=of fr] (dfr) {\normalsize \hspace{2.4cm} $P(r|d)=\mathbb{I}(d>0)$}; 

    \node[latent, above=of fr, yshift=-0.6cm] (d) {$d$} ; %
    \node[const, left=of d, xshift=-1.35cm] (d_name) {\small \en{Difference}\es{Diferencia}:};
    
    
    \node[factor, above=of d,yshift=-0.6cm] (fd) {} ; 
    \node[const, left=of fd] (nfd) {\normalsize $p(d|\bm{p})$}; 
    \node[const, right=of fd] (dfd) {\normalsize \hspace{2.4cm} $p(d|\bm{p}) =\mathbb{I}(d=p_1-p_2) \ o \ \delta() $}; 
    
    
    \node[latent, above=of fd, xshift=-0.8cm, yshift=-0.6cm] (p1) {$p_1$} ; %
    \node[latent, above=of fd, xshift=0.8cm, yshift=-0.6cm] (p2) {$p_2$} ; %
    \node[const, left=of p1, xshift=-0.55cm] (p_name) {\small \en{Performance}\es{Rendimiento}:}; 

    \node[factor, above=of p1 ,yshift=-0.6cm] (fp1) {} ; 
    \node[factor, above=of p2 ,yshift=-0.6cm] (fp2) {} ; 
    
    \node[latent, above=of fp1,yshift=-0.6cm] (s1) {$s_1$} ; %
    \node[latent, above=of fp2,yshift=-0.6cm] (s2) {$s_2$} ; %
    
    \node[factor, above=of s1 ,yshift=-0.6cm] (fs1) {} ; 
    \node[factor, above=of s2 ,yshift=-0.6cm] (fs2) {} ; 
    
    
    \node[const, left=of fp1] (nfp1) {\normalsize $p(p_1|s_1)$};
    \node[const, right=of fp2] (nfp2) {\normalsize $p(p_2|s_2)$};
    \node[const, right=of fp2] (dfp2) {\normalsize \hspace{1.6cm} $p(p_i|s_i)=\N(p_i|s_i,\beta^2)$};

    \node[const, left=of s1, xshift=-.85cm] (s_name) {\small \en{Skill}\es{Habilidad}:}; 
    
    \node[const, left=of fs1] (nfs1) {\normalsize $p(s_1)$};
    \node[const, right=of fs2] (nfs2) {\normalsize $p(s_2)$};
    \node[const, right=of fs2] (dfs) {\normalsize \hspace{1.6cm} $p(s_i) = \N(s_i|\mu_i,\sigma_i^2)$};

    
    \edge[-] {d} {fr};
    \edge[-] {p1,p2,d} {fd};
    \edge[-] {fp1} {p1,s1};
    \edge[-] {fp2} {p2,s2};
    \edge[-] {fs1} {s1};
    \edge[-] {fs2} {s2};
    %\node[invisible, right=of p2, xshift=4.35cm] (s-dist) {};
}
     \caption{
     \en{Factorizaci\'on gr\'afica del modelo generativo (Fig.~\ref{fig:generative_model}).}
     %
     \en{Los cuadrados negros representan las funciones, los c\'irculos blancos representan las variable, y los ejes entre ellos representan la relaci\'on matem\'atica ``la variable es argumento de la funci\'on''.}
     %
     }
    \label{fig:factor_graph}
\label{modelo}
\end{figure} 
%
\en{The structure encodes the minimum number of steps required to calculate any marginal probability distribution.}
\es{La estructura codifica la m\'inima cantidad de pasos que se requieren para calcular cualquier distribuci\'on de probabilidad marginal.}
%
\en{In our case we want to compute two marginals, the posterior of the skills $p(s_i|r)$ and the a prior probability of the result $p(r)$.}
\es{En nuestro caso querermos computar dos marginales, el posterior de las habilidades $p(s_i|r)$ y la probabilidad a priori del resultado $p(r)$.}

% Parrafo

\en{The \emph{sum-product algorithm} is a general way of breaking down the rules of probability as messages that are sent locally between the variables of the \emph{factor graph}.}
\es{El \emph{sum-product algorithm} es una forma general de descomponer las reglas de la probabilidad como mensajes que se env\'ian localmente las variables del \emph{factor graph}.}
%
\en{There are two types of messages: the messages that variable nodes send to their functions neighbors ($m_{v \rightarrow f}(v)$); and the messages that function nodes send to their variable neighbors ($m_{f \rightarrow v}(v)$).}
\es{Hay dos tipos de mensajes: los mensajes que envian los nodos variables a sus funciones vecinas ($m_{v \rightarrow f}(v)$); y los mensajes que envian los nodos funciones a sus variables vecinas ($m_{f \rightarrow v}(v)$).}
%
\en{The messages sent by the variable nodes encode a portion of the product rule.}
\es{Los mensajes que env\'ian los nodos variables codifican una porci\'on de la regla del producto.}
%
\begin{equation}\label{eq:m_v_f} \tag{\text{product step}}
m_{v \rightarrow f}(v) = \prod_{h \in n(v) \setminus \{f\} } m_{h \rightarrow v}(v)
\end{equation}
%
\en{Where $n(v)$ represents the set of node neighbors of $v$.}
\es{Donde $n(v)$ representa el conjunto de vecinos del nodo $v$.}
%
\en{In short, the messages sent by a $v$ variable is simply the product of the messages that $v$ received from the rest of their neighbors $h \in n(v)$ except $f$.}
\es{En pocas palabras, los mensajes que env\'ia una variables $v$ es simplemente la multiplicaci\'on de los mensajes que recibi\'o del resto de sus vecinos $h \in n(v)$ salvo $f$.}
%
\en{And the messages sent by the function nodes encode a portion of the sum rule.}
\es{Y los mensajes que env\'ian los nodos funciones codifican una parte de la regla de la suma.}
%
\begin{equation}\label{eq:m_f_v}  \tag{\text{sum step}}
m_{f \rightarrow v}(v) = \int \cdots \int \Big( f(\bm{h},v) \prod_{h \in n(f) \setminus \{v\} } m_{h \rightarrow f}(h) \Big) \,  d\bm{h}
\end{equation}
%
\en{Where $\bm{h} = n(f)\setminus \{v\}$ is the set of all of neighbors of $f$ except $v$, and $f(\bm{h},v)$ represents the function $f$, evaluated in all its arguments.}
\es{Donde $\bm{h} = n(f)\setminus \{v\}$ es el conjunto de todos los vecinos de $f$ salvo $v$, y $f(\bm{h},v)$ represeta la funci\'on $f$, evaluada en todos sus argumentos.}
%
\en{In short, the messages sent by a function $f$ to a neighboring variable $v$ is simply the integration over $\bm{h}$ of the product of itself and all the messages that $f$ receives from the rest of its neighbors $\bm{h}$ except $v$.}
\es{En pocas palabras, los mensajes que enviado por una funci\'on $f$ a una variable vecina $v$ es simplemente la integraci\'on sobre $\bm{h}$ del producto de si mismo con todos los mensajes que $f$ recibe del resto de sus vecinos $\bm{h}$ salvo $v$.}
%
\en{The composition of messages generates a partial computation.}
\es{La composici\'on de mensajes va generando un computo parcial.}
%
\en{Finally, the marginal probability distribution of a $v$ variable is simply the product of the messages that $v$ receives from its neighbors.}
\es{Finalmente, la distribuci\'on de probabilidad marginal de una variable $v$ es simplemente la multiplicaci\'on de los mensajes que $v$ recibe de sus vecinos.}
%
\begin{equation}\label{eq:marginal}
g_i(x_i) = \prod_{h \in n(x_i)} m_{h \rightarrow x_i}
\end{equation}



\subsection{\en{Mathematical properties and notation}\es{Propiedades matem\'aticas y notaci\'on}}\label{sec:propiedades}

\en{The efficiency of TrueSkill Through Time is due to the fact that margins, whether exact or approximate, are solved analytically.}
\es{La eficiencia de TrueSkill Through Time se debe a que las marginales, sean exactas o aproximadas, se resuelven de forma anal\'itica.}
%
\en{In this section we list the properties that we will use to derive the exact messages that arise from the sum-product algorithm.}
\es{En esta secci\'on enumeramos las propiedades que usaremos para derivar los mensajes exactos que surgen del \emph{sum-product algorithm}.}
%
\en{Although these properties are widely known, we attach their full demonstrations in the supplemental material.}
\es{Aunque estas propiedades son ampliamente conocidas, adjuntamos sus demostraciones completas en material suplementario.}

% Parrafo

\en{Let $\N$ be the Gaussian probability distribution, $\Phi$ the cumulative Gaussian distribution, $\mathbb{I}$ the indicator function.}
\es{Sea $\N$ la ditribuci\'on de probabilidad Gaussiana, $\Phi$ la acumulada de una distribuc\'on Gaussiana, $\mathbb{I}$ la funci\'on indicadora.}
%
\begin{equation}\label{eq:propiedad_1} \tag{\text{prop 1}}
\N(x|\mu_1,\sigma_1^2)\N(x|\mu_2,\sigma_2^2) \overset{\ref{multiplicacion_normales}}{=} \N(\mu_1|\mu_2,\sigma_1^2+\sigma_2^2) \N(x|\mu_{*},\sigma_{*}^2)
\end{equation}
%
con $\mu_{*} = \frac{\mu_1}{\sigma_1^2} + \frac{\mu_2}{\sigma_2^2}$ y $\sigma_{*}^2 = \left(\frac{1}{\sigma_1^2} + \frac{1}{\sigma_2^2} \right)^{-1}$ 

\begin{equation}\label{eq:propiedad_2} \tag{\text{prop 2}}
\N(x|\mu_1,\sigma_1^2)/\N(x|\mu_2,\sigma_2^2) \overset{\ref{sec:division_normales}}{=} \N(\mu_1|\mu_2,\sigma_1^2+\sigma_2^2) \N(x|\mu_{\div},\sigma_{\div}^2)
\end{equation}
%
con $\mu_{\div} = \frac{\mu_1}{\sigma_1^2} - \frac{\mu_2}{\sigma_2^2}$ y $\sigma_{\div}^2 = \left(\frac{1}{\sigma_1^2} - \frac{1}{\sigma_2^2} \right)^{-1}$ 

\begin{equation}\label{eq:integral_con_indicadora} \tag{\text{prop 3}}
\begin{split}
 \iint  \mathbb{I}(x=h(y,z)) f(x) g(y)\, dx\, dy = \int f(h(y,z)) g(y) dy
 \end{split}
\end{equation}

\begin{equation}\label{eq:simetria} \tag{\text{prop 4}}
 \N(x|\mu,\sigma^2) = \N(\mu|x,\sigma^2) = \N(-\mu|-x,\sigma^2) = \N(-x|-\mu,\sigma^2) 
\end{equation}

\begin{equation}\label{eq:estandarizar} \tag{\text{prop 5}}
  \N(x|\mu,\sigma^2) = \N((x-\mu)/\sigma | 0, 1)
\end{equation}

\begin{equation}\label{eq:phi_norm} \tag{\text{prop 6}}
 \frac{\partial}{\partial x} \Phi(x|\mu,\sigma^2) = \N(x|\mu,\sigma^2)
\end{equation}

\begin{equation}\label{eq:phi_simetria} \tag{\text{prop 7}}
\Phi(0|\mu,\sigma^2) = 1-\Phi(0|-\mu,\sigma^2)
\end{equation}
%
\en{Because we develop packages in three programming languages, by displaying code we will identify each syntax as follows.}
\es{Debido a que desarrollamos paquetes en tres lenguajes de programaci\'on, al mostrar c\'odigo identificaremos cada sintaxis del siguiente modo.}
%
\begin{lstlisting}[backgroundcolor=\color{all}, belowskip=-0.77 \baselineskip]
Syntax common to Julia, Python and R
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}]
Julia sintax
\end{lstlisting}
  \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}]
Python sintax
\end{lstlisting}
   \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}]
R syntax
\end{lstlisting}  
\end{paracol}
%

\subsection{Gaussian}\label{sec:Gasussian}

\en{The \texttt{Gaussian()} class does most of the computation of the packages.}
\es{La clase \texttt{Gaussian()} realiza la mayor parte del c\'omputo en todos los paquetes.}
%
\en{It is represented by two parameters, the mean and the standard deviation.}
\es{Se representa mediante dos par\'ametros, la media y el desv\'io estandar.}
%
\begin{lstlisting}[backgroundcolor=\color{white},label=lst:N1_N2, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}, belowskip=-0.77 \baselineskip]
N1 = Gaussian(mu = 1.0, sigma = 1.0); N2 = Gaussian(1.0, 2.0)  
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}]
m1 = N1.mu
v1 = N1.sigma^2
v2 = N2.sigma^2
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}]
m1 = N1.mu
v1 = N1.sigma**2
v2 = N2.sigma**2
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}]
m1 = N1$mu
v1 = N1$sigma^2
v2 = N2$sigma^2
\end{lstlisting}
\end{paracol}
%
\en{The class overwrites the operators addition (\texttt{+}), subtraction (\texttt{-}), product (\texttt{*}) and division (\texttt{/}) with the main properties required to compute the marginal distributions in the TrueSkill Through Time model.}
\es{La clase sobreescribe los operadores suma (\texttt{+}), resta (\texttt{-}), producto (\texttt{*}) y divisi\'on (\texttt{/}) con las principales propiedades requeridas para computar las distribuciones marginales en el modelo TrueSkill Through Time.}
%
\begin{equation} \tag{\texttt{N1 * N2}}
 \N(x|\mu_1,\sigma_1^2)\N(x|\mu_2,\sigma_2^2) \propto \N(x|\mu_{*},\sigma_{*}^2)
\end{equation}
%
\begin{equation} \tag{\texttt{N1 / N2}}
 \N(x|\mu_1,\sigma_1^2)/\N(x|\mu_2,\sigma_2^2) \propto \N(x|\mu_{\div},\sigma_{\div}^2)
\end{equation} 
%
\vspace{-0.3cm}
%
\begin{equation} \tag{\texttt{N1 + N2}} \label{eq:suma_normales}
\begin{split}
\iint \mathbb{I}(t = x + y) \N(x|\mu_1, \sigma_1^2)\N(y|\mu_2, \sigma_2^2) dxdy = \N(t|\mu_1+\mu_2,\sigma_1^2 + \sigma_2^2)
\end{split}
\end{equation}
%
\vspace{-0.5cm}
%
\begin{equation} \tag{\texttt{N1 - N2}} \label{eq:resta_normales}
\begin{split}
\iint \mathbb{I}(t = x - y) \N(x|\mu_1, \sigma_1^2)\N(y|\mu_2, \sigma_2^2) dxdy = \N(t|\mu_1 - \mu_2,\sigma_1^2 + \sigma_2^2)
\end{split}
\end{equation}
%
\en{For its part, the following property will be computed ``by hand''.}
\es{Por su parte, la siguiente propiedad la computaremos ``a mano''.}
%
\begin{equation} \label{eq:normal_de_normal} \tag{\texttt{Gaussian(m1, sqrt(v1+v2))}}
\int \N(y| x, \sigma_y^2) \N(x| \mu_x, \sigma_x^2) dx = \N(y|\mu_x,\sigma_y^2 + \sigma_x^2)   
\end{equation}
%
\en{Note that the value of \texttt{m1},\texttt{v1},\texttt{v2} has been previously defined.}
\es{Notar que el valor de \texttt{m1},\texttt{v1},\texttt{v2} a sido definido previamente.}

\subsection{Rating} \label{sec:rating}

\en{The class \texttt{Rating()} is represented by: the mean (\texttt{mu}) and the deviation (\texttt{sigma}) of the prior Gaussian distribution; the performance standard deviation (\texttt{beta}); and the temporal volatility of the skills (\texttt{gamma}).}
\es{La clase \texttt{Rating()} se representa con cuatro atributos: la media (\texttt{mu}) y el desv\'io (\texttt{sigma}) de la distribuci\'on Gaussiana a priori; el dev\'io de los rendimientos (\texttt{beta}); y la volatilidad temporal de las habilidades (\texttt{gamma}).}
%
\begin{lstlisting}[backgroundcolor=\color{white},label=lst:rating, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}]
mu = 0.0; sigma = 6.0; beta = 1.0; gamma = 0.0
r1 = Rating(mu, sigma, beta, gamma); r2 = Rating(mu, sigma, beta, gamma)
r3 = Rating(mu, sigma, beta, gamma); r4 = Rating(mu, sigma, beta, gamma)
\end{lstlisting}  
%
\en{For efficiency, the prior is stored pre-computed.}
\es{Por cuesti\'on de eficiencia, el prior Gaussiano se guarda precomputado.}
%
\begin{lstlisting}[backgroundcolor=\color{white},label=lst:prior, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}]
prior = r1.prior
beta == r1.beta
gamma == r1.gamma
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}]
prior = r1.prior
beta == r1.beta
gamma == r1.gamma
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}]
prior = r1$prior
beta == r1$beta
gamma == r1$gamma
\end{lstlisting}
\end{paracol}
%

\subsection{Games} \label{sec:game}

\en{The class \texttt{Game()} is used to compute the posteriors and the evidence of events such as described in Figure~\ref{fig:generative_model}.}
\es{La clase \texttt{Game()} se utiliza para computar los posteriors y la evidencia de eventos como los descritos en la figura~\ref{fig:generative_model}.}
%
\en{As an example, we initialize a game with two teams of two players.}
\es{A modo de ejemplo, inicializamos una partida con dos equipos de dos jugadores.}
%
\begin{lstlisting}[backgroundcolor=\color{white},label=lst:game, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}, belowskip=-0.77 \baselineskip]
team_a = [ r1, r2 ]
team_b = [ r3, r4 ]
teams = [team_a, team_b]
result = [1,0]
\end{lstlisting}
  \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}, belowskip=-0.77 \baselineskip]
team_a = [ r1, r2 ]
team_b = [ r3, r4 ]
teams = [team_a, team_b]
result = [1,0]
\end{lstlisting}
   \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}, belowskip=-0.77 \baselineskip]
team_a = c(r1, r2)
team_b = c(r3, r4)
teams = list(team_a, team_b)
result = c(1,0)
\end{lstlisting}  
\end{paracol}
\begin{lstlisting}[backgroundcolor=\color{all}]
g = Game(teams, result)
\end{lstlisting}
%
\en{Its attributes, besides the \texttt{teams} and the \texttt{result}, are the approximate (Gaussian) \texttt{likelihoods} and the \texttt{evidence}.}
\es{Sus atributos, adem\'as de los \texttt{teams} y el \texttt{result}, son los \texttt{likelihoods} aproximados (Gaussianos) y la \texttt{evidencia}.}
%
\begin{lstlisting}[backgroundcolor=\color{white},label=lst:game_attributes, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}]
teams == g.teams
result == g.result
lhs = g.likelihoods
ev = g.evidence
\end{lstlisting}
  \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}]
teams == g.teams
result == g.result
lhs = g.likelihoods
ev = g.evidence
\end{lstlisting}
   \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}]
teams == g$teams
result == g$result
lhs = g$likelihoods
ev = g$evidence
\end{lstlisting}  
\end{paracol}
%
\en{In the presence of teams, the observed result is modeled as a direct consequence of the difference of the team performance, $d = \sum_{i \in A} p_i - \sum_{i \in B} p_i$.}
\es{En presencia de equipos, el resultado observado se modela como consecuencias directa de la diferencia de los rendimientos de cada equipo, $d = \sum_{i \in a} p_i) - \sum_{i \in b} p_i)$}
%
\en{In the figure~\ref{fig:modelo_trueskill_2vs2}, we show its graphical factorization.}
\es{En la figura~\ref{fig:modelo_trueskill_2vs2} mostramos su factorizaci\'on gr\'afica.} 
%
\begin{figure}[h!]
  \centering
  \scalebox{.9}{
  \tikz{
      
        \node[factor] (fr) {} ;
        \node[const, right=of fr] (nfr) {$f_{r}$}; %
	
	\node[latent, above=of fr, yshift=-0.4cm] (d) {$d$} ; %
        \node[factor, above=of d, yshift=-0.4cm] (fd) {} ;
        \node[const, above=of fd] (nfd) {$f_{d}$}; %
	
        
        \node[latent, left=of fd,xshift=0.4cm] (ta) {$t_a$} ; %
        \node[factor, left=of ta,xshift=0.4cm] (fta) {} ;
        \node[const, above=of fta] (nfta) {$f_{t_a}$}; %
        
        \node[latent, left=of fta,yshift=1cm,xshift=0.4cm] (p1) {$p_1$} ; %
        \node[factor, left=of p1,xshift=0.4cm] (fp1) {} ;
        \node[const, above=of fp1] (nfp1) {$f_{p_1}$}; %
        
        \node[latent, left=of fp1,xshift=0.4cm] (s1) {$s_1$} ; %
        \node[factor, left=of s1,xshift=0.4cm] (fs1) {} ;
	\node[const, above=of fs1] (nfs1) {$f_{s_1}$}; %
     
        \node[latent, left=of fta,yshift=-1cm,xshift=0.4cm] (p2) {$p_2$} ; %
        \node[factor, left=of p2,xshift=0.4cm] (fp2) {} ;
        \node[const, above=of fp2] (nfp2) {$f_{p_2}$}; %
        
        \node[latent, left=of fp2,xshift=0.4cm] (s2) {$s_2$} ; %
        \node[factor, left=of s2,xshift=0.4cm] (fs2) {} ;
	\node[const, above=of fs2] (nfs2) {$f_{s_2}$}; %
        
            
        \node[latent, right=of fd,xshift=-0.4cm] (tb) {$t_b$} ; %
        \node[factor, right=of tb,xshift=-0.4cm] (ftb) {} ;
        \node[const, above=of ftb] (nftb) {$f_{t_b}$}; %
        
        \node[latent, right=of ftb,yshift=1cm,xshift=-0.4cm] (p3) {$p_3$} ; %
        \node[factor, right=of p3,xshift=-0.4cm] (fp3) {} ;
        \node[const, above=of fp3] (nfp3) {$f_{p_3}$}; %
        
        \node[latent, right=of fp3,xshift=-0.4cm] (s3) {$s_3$} ; %
        \node[factor, right=of s3,xshift=-0.4cm] (fs3) {} ;
	\node[const, above=of fs3] (nfs3) {$f_{s_3}$}; %
     
        \node[latent, right=of ftb,yshift=-1cm,xshift=-0.5cm] (p4) {$p_4$} ; %
        \node[factor, right=of p4,xshift=-0.4cm] (fp4) {} ;
        \node[const, above=of fp4] (nfp4) {$f_{p_4}$}; %
        
        \node[latent, right=of fp4,xshift=-0.4cm] (s4) {$s_4$} ; %
        \node[factor, right=of s4,xshift=-0.4cm] (fs4) {} ;
	\node[const, above=of fs4] (nfs4) {$f_{s_4}$}; %
     
        \edge[-] {fr} {d};
	\edge[-] {d} {fd};
	
        \edge[-] {fd} {ta};
        \edge[-] {ta} {fta};
        \edge[-] {fta} {p1};
        \edge[-] {p1} {fp1};
        \edge[-] {fp1} {s1};
        \edge[-] {s1} {fs1};
        \edge[-] {fta} {p2};
        \edge[-] {p2} {fp2};
        \edge[-] {fp2} {s2};
        \edge[-] {s2} {fs2};
        	
	\edge[-] {fd} {tb};
        \edge[-] {tb} {ftb};
        \edge[-] {ftb} {p3};
        \edge[-] {p3} {fp3};
        \edge[-] {fp3} {s3};
        \edge[-] {s3} {fs3};
        \edge[-] {ftb} {p4};
        \edge[-] {p4} {fp4};
        \edge[-] {fp4} {s4};
        \edge[-] {s4} {fs4};
        
	
	\node[const, below=of fr,xshift=7cm,yshift=-0.3cm] (dfr) { $f_r = \mathbb{I}(d>0)$}; %
	\node[const, left=of dfr,xshift=-0.5cm] (dfd) {$f_d = \mathbb{I}(d=t_a - t_b)$}; %
	\node[const, left=of dfd,xshift=-0.5cm] (dft) {$f_{t_e} = \mathbb{I}(t_e = \sum_{i \in A_e} p_i)$}; %
        \node[const, left=of dft,xshift=-0.5cm] (dfp) {$f_{p_i} = \N(p_i|s_i,\beta^2)$}; %
        \node[const, left=of dfp,xshift=-0.5cm] (dfs) {$f_{s_i} = \N(s_i|\mu_i,\sigma^2)$}; %
   }
   }
  \caption{
  \en{Graphical factorization of a 2 vs 2 game.}
  \es{Factorizaci\'on gr\'afica de una partida 2 vs 2.}
  }
  \label{fig:modelo_trueskill_2vs2}
\end{figure}

\subsection{\en{Exact posterior}\es{Posterior exacta}} \label{sec:exactSolution}

\en{Every game with two teams has an exact solution.}
\es{Todo partida con dos equipos tiene soluci\'on exacta.}
%
\en{The exact likelihoods can be computed  \proglang{Julia}, \proglang{Python} y \proglang{R} by the method \texttt{exact\_likelihoods()}.}
\es{y los likelihoods exactos pueden computarse en \proglang{Julia}, \proglang{Python} y \proglang{R} mediante el m\'etodo \texttt{exact\_likelihoods()}.}
%
\begin{lstlisting}[backgroundcolor=\color{white},label=lst:elhs, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}]
elhs = exact_likelihoods(g)
\end{lstlisting}
  \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}]
elhs = g.exact_likelihoods()
\end{lstlisting}
   \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}]
elhs = g$exact_likelihoods()
\end{lstlisting}  
\end{paracol}
%
\en{In this section we will show the steps to compute the evidence and an exact likelihood of a game with two teams of two players.}
\es{En esta secci\'on vamos a mostrar los pasos para calcular la evidencia  y un likelihood exacto de una partida con dos equipos de dos jugadores.}
%
\en{We will start first with the ``descending'' messages, from the priors to the result, until compute the evidence.}
\es{Empezaremos primero con los mensajes ``descendentes'', desde los priors hasta el resultado, para calcular la evidencia.}
%
\en{Then we will continue with the ``ascending'' messages to compute the posterior of an agent from the observed result and the prior of the rest of the agents.}
\es{Luego seguiremos con los mensajes ``ascendentes'' que permiten calcular el posterior de un agente a partir del resultado observado y el prior del resto de los agentes.}
%
%\en{To compute the messages we will only use the sum-product algorithm and the properties mentioned above.}
%\es{Para computar los mensajes utilizaremos solamente el \emph{sum-product algorithm} y las propiedades arriba mencionadas.}

%

\en{Because of the rules of the sum-product algorithm and the factorization of the model, the messages from the skill factors $f_{s_i}$ to their variable $s_i$ are just the prior.}
\es{Debido a las reglas del algoritmo de suma-producto y a la factorizaci\'on del modelo, los mensajes de los factores de habilidad $f_{s_i}$ a su variable $s_i$ no son otra cosa m\'as que el prior.}
%
\begin{equation}\label{eq:m_fs_s} \tag{\texttt{prior}}
 m_{f_{s_i} \rightarrow s_i}(s_i) = \N(s_i| \mu_i, \sigma_i^2)
\end{equation}
%
\en{We have already defined the variable \texttt{prior} in the code \ref{lst:prior}.}
\es{Ya hemos definimos la variable \texttt{prior} en el c\'odigo~\ref{lst:prior}.}
%
\en{The next message, that the variable $s_i$ sends to the performance factor $f_{p_i}$ will also be the prior.}
\es{El siguiente mensaje, que la variable $s_i$ le env\'ia al factor rendimiento $f_{p_i}$ tambi\'en ser\'a el prior.}
%
\en{Remember that the messages that the variables send are just the product of the messages that the variable receives from the rest of its neighboring factors.}
\es{Recordar que los mensajes que env\'ian las variables es tan solo la multiplicaci\'on de los mensajes que esa variable recibe del resto de los factores.}
%
\en{Since they are trivial, we will not make these types of messages explicit.}
\es{Por ser de trivial soluci\'on, no haremos expl\'icitos este tipo de mensajes.}
%
\en{Let's see then the message that the performance factors $f_{p_i}$ send to their variable $p_i$.}
\es{Veamos entonces el mensaje que env\'ian los factores rendimiento $f_{p_i}$ a su variable $p_i$.}
%
\begin{equation}\label{eq:m_fp_p} \tag{\texttt{performance()}}
m_{f_{p_i} \rightarrow p_i}(p_i) = \int \N(p_i| s_i, \beta^2) \N(s_i| \mu_i, \sigma_i^2) ds_i = \N(p_i|\mu_i,\beta^2 + \sigma_i^2)
\end{equation}
%
%\en{Computacionalmente, podemos calcular esto de la siguiente manera.}
\begin{lstlisting}[backgroundcolor=\color{white},label=lst:performance, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0.5 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}]
p1 = performance(r1)
  ...
p4 = performance(r4)
\end{lstlisting}
  \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}]
p1 = r1.performance()
  ...
p4 = r4.performance()
\end{lstlisting}
   \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}]
p1 = r1$performance()
  ...
p4 = r4$performance()
\end{lstlisting}  
\end{paracol}
%
\en{Then, the message sent by the team factors $f_{t_e}$ to the team variable $t_e$ are,}
\es{Luego, el mensaje que env\'ian los factores equipos $f_{t_e}$ a la variable equipo $t_e$ son,}
%
\begin{equation} \label{eq:m_ft_t} \tag{\texttt{ta = p1 + p2}}
\begin{split}
 m_{f_{t_e} \rightarrow t_e}(t_e) &= \iint \mathbb{I}(t_e = p_i + p_j) \N(p_i|\mu_i,\beta^2 + \sigma_i^2)\N(p_j|\mu_j,\beta^2 + \sigma_j^2) dp_idp_j  \\ &=  \N(t_e|\mu_i+\mu_j,2\beta^2 + \sigma_i^2 + \sigma_j^2)
\end{split}
\end{equation}
%
\en{In general (demo at annex section~\ref{suma_normales_induccion})}
\es{En general (demostraci\'on en secci\'on anexa~\ref{suma_normales_induccion})}.
%
\begin{equation*}
 m_{f_{t_e} \rightarrow t_e}(t_e) =  \N \Big( t_e | \underbrace{\sum_{i\in A_e } \mu_i}_{\hfrac{\text{Habilidad}}{\text{de equipo}} \ \mu_e}, \underbrace{\sum_{i \in A_e} \beta^2 + \sigma_i^2}_{\hfrac{\text{Varianza}}{\text{de equipo}} \ \sigma_e^2} \Big) = \N(t_e | \mu_e, \sigma_e^2)
\end{equation*}
%
\en{The message sent by the difference factor $f_{d_1}$ to the difference variable $d_1$ are,}
\es{El mensaje que env\'ia el factor diferencia $f_{d_1}$ a la variable diferencia $d_1$ es,}
%
\begin{equation}\label{eq:m_fd_d} \tag{\texttt{d = ta - tb}}
 \begin{split} 
  m_{f_{d_1} \rightarrow d_1}(d_1) & = \iint \mathbb{I}(d_1 = t_a - t_b) \N(t_a| \mu_a, \sigma_a^2)  \N(t_b| \mu_b, \sigma_b^2)  dt_adt_b \\[0.25cm]
  & = \N\big( d_1 | \underbrace{\mu_a - \mu_b}_{\hfrac{\text{Differencia}}{\text{esperada:} \ \delta} }, \underbrace{\sigma_a^2 +\sigma_b^2}_{\hfrac{\text{incertidumbre}}{\text{total:} \ \vartheta^2}}  \big) = \N(d_1 | \delta, \, \vartheta^2)
 \end{split}
\end{equation}
\begin{lstlisting}[backgroundcolor=\color{white},label=lst:difference, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0.5 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}, belowskip=-0.77 \baselineskip]
ta = p1 + p2; tb = p3 + p4
d = ta - tb
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}]
delta = d.mu
theta = d.sigma
ev = cdf(d, 0.0)
evidencia = ev
\end{lstlisting}  
 \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}]
delta = d.mu
theta = d.sigma
ev = cdf(0,delta,theta) 
evidencia = ev
\end{lstlisting} 
 \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}]
delta = d$mu
theta = d$sigma
ev = cdf(0,delta,theta) 
evidencia = ev
\end{lstlisting}   
\end{paracol}
%
\begin{equation}\label{eq:m_fr_r} \tag{\texttt{evidencia}}
\begin{split}
 m_{f_{r_1} \rightarrow r_1}(r_1) = \int \mathbb{I}(d_1 > 0) \N(d_1 | \delta, \vartheta^2)  dd_1 = \Phi(\frac{\delta}{\vartheta})
\end{split}
\end{equation}

% Parrafo

\en{Let us now examine the ascending messages.}
\es{Examinemos ahora los mensajes ascendentes.}
%
\begin{equation}\label{eq:m_fd_ta} \tag{\texttt{exact\_lhood\_ta}}
\begin{split}
m_{f_{d_1} \rightarrow t_a}(t_a) & = \iint \mathbb{I}(d_1 = t_a - t_b) \mathbb{I}(d_1 > 0) \N(t_b | \mu_b , \sigma_b^2 ) \, dd_1\,dt_b \\
& = \int \mathbb{I}( t_a > t_b)  \N(t_b | \mu_b , \sigma_b^2 ) \,dt_b  \\
& = 1 - \Phi (t_a| -\mu_b, \sigma_b^2) = \Phi (t_a| \mu_b, \sigma_b^2)
\end{split}
\end{equation}
%
\begin{equation}\label{eq:m_fta_p_inicial} \tag{\texttt{exact\_lhood\_p1}}
\begin{split}
m_{f_{t_a} \rightarrow p_1}(p_1)  & = \iint \mathbb{I}( t_a = p_1 + p_2) \, N(p_2| \mu_2, \beta^2 + \sigma_2^2 ) \, \Phi (t_a| \mu_b , \sigma_b^2 ) \, dt_a dp_2 \\
& = \int  \, \N(p_2| \mu_2, \beta^2 + \sigma_2^2 ) \, \Phi (p_1 + p_2| \mu_b , \sigma_b^2 ) \, dp_2 \\
& = 1 - \Phi( p_1 | \underbrace{\mu_2 - \mu_b}_{\delta-\mu_1}, \underbrace{\beta^2 + \sigma_2^2 + \sigma_b^2}_{\vartheta^2 - (\sigma_1^2 + \beta^2)}) 
\end{split}
\end{equation}
%
\begin{equation}\label{eq:m_fp_s1} \tag{\texttt{exact\_lhood\_s1}}
\begin{split}
m_{f_{p_1} \rightarrow s_1}(s_1) & = \int N(p_1| s_1, \beta^2) \, \Phi(p_1| \mu_1-\delta, \vartheta^2 - (\sigma_1^2 + \beta^2)) \, dp_1 \\[0.1cm]
& = 1 - \Phi(0 | \underbrace{(s_1 + \mu_2) - (\mu_3 + \mu_4)}_{\hfrac{\text{\en{Expected difference}\es{Diferencia esperada}}}{\text{\en{parameterized in }\es{parametrizada en }$s_1$}}: \ \delta_1(s_1) } \ , \underbrace{\ \ \ \ \vartheta^2 - \sigma_1^2 \ \ \ \ }_{\hfrac{\text{\en{Total uncertainty}\es{Incertidumbre total}}}{\text{\en{except for }\es{salvo la de }$s_1$}}: \ \vartheta_1^2})\end{split}
\end{equation}
%
\en{This last message, $m_{f_{p_1} \rightarrow s_1}(s_1)$, is the exact likelihood and computes the prior probability of winning if the player's true skill was $s_1$.}
\es{Este último mensaje, $m_{f_{p_1} \rightarrow s_1}(s_1)$, es el likelihood exacto y computa la probabilidad a priori de ganar si la verdadera habilidad del jugador fuera $s_1$.}
%
\en{Assuming that the skill is known, we must replace the average estimate $\mu_1$ by the hypothesis $s_1$ in the expected difference $\delta$, and remove its own uncertainty from the total uncertainty $\vartheta^2$.}
\es{Al suponer conocida la habilidad, debemos remplazar su estimaci\'on media $\mu_1$ por la hip\'otesis $s_1$ en la diferencia esperada $\delta$, y remover su propia incertidumbre de la incertidumbre total $\vartheta^2$.}
%
\begin{lstlisting}[backgroundcolor=\color{white},label=lst:delta_1, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}]
theta1 = theta^2 - sigma1^2
theta1 = sqrt(theta1)
function exact_lhood(s1)
  delta1 = delta - mu1 + s1 
  N= Gaussian(delta1,theta1)
  return 1-cdf(N,0.0)
end
\end{lstlisting}  
 \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}]
theta1 = theta**2 - sigma1**2
theta1 = sqrt(theta1)
def exact_lhood(s1):
    delta1 = delta - mu1 + s1 
    res=1-cdf(0,delta1,theta1)
    return res
    
\end{lstlisting} 
 \switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}]
theta1 = theta^2 - sigma1^2
theta1 = sqrt(theta1)
exact_lhood = function(s1){
  delta1 = delta - mu1 + s1 
  res=1-cdf(0,delta1,theta1)
  return(res)
}
\end{lstlisting}   
\end{paracol}

\subsection{\en{Elementary draw model}\es{Modelo b\'asico de empates}} \label{sec:empate}

\en{The draw model asummes that a tie occur when the difference in performance does not exceed a certain margin, $|t_a > t_b| \leq \varepsilon$.}
\es{El modelo supone que ocurre un empate cuando la diferencia de rendimientos no supera un cierto margen, $|t_a > t_b| \leq \varepsilon$.}
%
\en{In the figure~\ref{fig:draw_a} you can see in graphical terms the probabilities of the three possible outcomes.}
\es{En la figura~\ref{fig:draw_a} se puede ver en t\'erminos gr\'aficos las probabilidades de los tres resultados posibles.}
%
\en{The elementary model requires determining the value of the margin.}
\es{Este modelo b\'asico requiere determinar el valor del margen.}
%
\en{The original paper~\citep{Herbrich2007} proposed to use the empirical frequency of ties.}
\es{El art\'iculo original~\citep{Herbrich2007} propon\'ia usar la frecuencia emp\'irica de empates.}
%
\en{However, this value depends on the actual skill difference, which we just don't know.}
\es{Sin embargo, este valor depende de la diferencia de habilidad real, que justamente no conocemos.}
%
\en{In section~\ref{sec:ttt-d} we present the Bayesian solution to the darw model.}
\es{En la secci\'on~\ref{sec:ttt-d} presentamos la soluci\'on Bayesiana al modelo de empates.}
%
\en{In any case, assuming that we can define the ``probability of a draw between teams with same skill'', it is important to note that the margin also depends on the number of players.}
\es{En cualquier caso, suponiendo que podemos definir esa la ``probabilidad de empate entre equipos con misma habilidad'', es importante tener en cuenta que el margen tambi\'en depende de la cantidad de jugadores.}
%
\en{In the figure~\ref{fig:draw_b} you can see that to keep the tie area constant it is necessary to adapt the margin according to the uncertainty.}
\es{En la figura~\ref{fig:draw_b} se puede ver que para mantener el \'area de empates constante, es necesario adaptar el margen dependiendo de la incertidumbre.}
%
%\en{This is because the actual distribution of performance differences depends on how many players are in the game.}
%\es{Esto es as\'i porque la distribuci\'on de diferencias de rendimientos real depende de cu\'antos jugadores hay en la partida.}
%
\begin{figure}[h!]
\centering
\begin{subfigure}[t]{0.48\textwidth}
 \includegraphics[width=1\textwidth]{figures/draw.pdf} 
 \caption{Las distintas \'areas}
 \label{fig:draw_a}
\end{subfigure}
\begin{subfigure}[t]{0.48\textwidth}
  \includegraphics[page=2,width=1\textwidth]{figures/draw.pdf}
  \caption{Área de empate constante}
 \label{fig:draw_b}
\end{subfigure}
  \caption{Modelo de empate.}
  \label{fig:draw}
\end{figure}
%
\en{Since the observed results are independent of our beliefs, the only source of uncertainty comes from the variance of individual perfomances $\beta$.}
\es{Como los resultados observados son independientes de nuestras creencias, la \'unica fuente de incertidumbre proviene de varianza de los rendimientos $\beta$.}
%
\en{This is how we can define an equation that links the margin with the probability of a tie.}
\es{As\'i es que podemos definir una ecuaci\'on que vincula el margen con la probabilidades de empate.}
%
\begin{equation}
 \text{Draw probability} = \Phi(\frac{\varepsilon}{\sqrt{n_1+n_2}\beta}) - \Phi(\frac{-\varepsilon}{\sqrt{n_1+n_2}\beta})
\end{equation}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:draw, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia},belowskip=-0.77 \baselineskip]
na = length(team_a)
nb = length(team_b)
sd = sqrt(na + nb)*BETA
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python},belowskip=-0.77 \baselineskip]
na = len(team_a)
nb = len(team_b)
sd = math.sqrt(na + nb)*BETA
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r},belowskip=-0.77 \baselineskip]
na = length(team_a)
nb = length(team_b)
sd = sqrt(na + nb)*BETA
\end{lstlisting}
\end{paracol}
\begin{lstlisting}[backgroundcolor=\color{all}]
p_draw = 0.25
margin = compute_margin(p_draw, sd)
\end{lstlisting}  
%
%
% \en{In any case, an alternative is to use the classic optimization strategy: choose the value of $\varepsilon$ that maximizes some cost function.}
% \es{En cualquier caso, una alternativa es usar la estrategia cl\'asica de optimizaci\'on: elegir el valor de $\varepsilon$ que maximiza alguna funci\'on de costo.}
% %
% \begin{equation*}
% \varepsilon = \underset{\varepsilon}{\text{arg max}} \ p(\text{Data}|\text{Model}_{\varepsilon})
% \end{equation*}
% %
\subsection{\en{Optimal approximation of the exact posterior}\es{Aproximaci\'on \'optima del posterior exacto}} \label{sec:approximate_posterior}

\en{In the section~\ref{sec:exactSolution} we have seen how to find the exact posterior.}
\es{En la secci\'on~\ref{sec:exactSolution} hemos visto que el posterior exacta, si bien se parece a un Gaussiano, no lo es, .}
%
% \en{ although similar, is not a Gaussian distribution, preventing us from using the equation~\ref{eq:posterior_win}  iteratively.}
% \es{Es importante remarcar que la posterior, aunque se parezca, no es una distribuci\'on Gaussiana, lo que nos impedir\'a usar la ecuaci\'on~\ref{eq:posterior_win} iterativamente.}
% %
% 
% 
% \en{But due the shape of the exact posterior, a Gaussian seem to be a good enough approximation, allowing us to avoid the computational cost of the sampling methodologies.}
% \es{Por la forma del posterior exacto, una Gaussiana parece una aproximaci\'on suficientemente buena, que nos permitir\'ia evitar el costo computacional de la metodolog\'ias de sampleo.}
% %
% 
% \en{Dado que la forma exacta se parece a una Gaussiana (figura~\ref{fig:posterior_win}), usar una Gaussiana para representar el posterior no parecer\'ia ser tan grave en t\'erminos de aproximaci\'on y en cambio nos permitir\'ia realizar estimaciones sucesivas.}
% 
% % Parrafo
%\en{The methods for approximating an untractable distribution by means of a distribution belonging to a known family are known in Bayesian inference as ``variational''.}
%\es{Los m\'etodos para aproximar una distribuci\'on intratable mediante una distribuci\'on perteneciente a una familia conocida se conocen en inferencia bayesiana como ``variacionales''.}
%
\en{In this section we will show how to find the Gaussian distribution that best approximates the exact posterior, considering the possibility of ties.}
\es{En esta secci\'on mostraremos c\'omo encontrar la distribuci\'on Gaussiana que mejor aproxima al posterior exacto, considerando la posibilidad de empates.}
%
\en{The packages solve it with the following two lines of code.}
\es{Los paquetes lo resuelven con las siguientes dos l\'ineas de c\'odigo.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:post_2vs2, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all},belowskip=-0.77 \baselineskip]
g = Game(teams, result, p_draw)
\end{lstlisting}  
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}]
post = posteriors(g)
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}]
post = g.posteriors()
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}]
post = g$posteriors()
\end{lstlisting}
\end{paracol}
%
\en{Remember that \texttt{teams}, \texttt{results}, and \texttt{p\_draw}, were defined in Code \ref{lst:game} and \ref{lst:draw}.}
\es{Recuerden que \texttt{teams}, \texttt{results}, y \texttt{p\_draw}, fueron definidas en los c\'odigos \ref{lst:game} y \ref{lst:draw}.}

% Parrafo

\en{The need to approximate the posterior occurs because the probability distribution of the difference is a truncated Gasussian (Eq.~\ref{eq:p_d}).}
\es{La necesidad de aproximar el posterior ocurre debido a que la distribuci\'on de probabilidad de la diferencia es una Gasussian truncada (Eq.~\ref{eq:p_d}).}
%
\begin{equation}\label{eq:p_d}
p(d) =
\begin{cases}
\N(d|\delta,\vartheta^2) \mathbb{I}(\varepsilon < d < \varepsilon) & \text{tie} \\
\N(d|\delta,\vartheta^2) \mathbb{I}(d > \varepsilon) & \text{not tie}
\end{cases}
\end{equation}
%
\en{For Gaussian distributions, moment matching is known to minimize the Kullback-Leibler divergence~\citep{Herbrich2007}.}
\es{Se sabe que las distribuciones Gaussianas que minimizan la divergencia Kullback-Libler son las que tiene mismo momentos~\citep{Herbrich2007}.}
%
\en{The expectation and variance of a truncated Gaussian $\N(x|\mu,\sigma^2)$ in a $[a,b]$ interval are,}
\es{La esperanza y la varianza de una Gaussiana truncada $\N(x|\mu,\sigma^2)$ en un intervalo $[a,b]$ son,}
%
\begin{equation}\label{eq:mean_aprox_double}
 E(X| a < X < b) = \mu + \sigma \frac{\N(\alpha) - \N(\beta) }{\Phi(\beta) - \Phi(\alpha) }
\end{equation}
%
\begin{equation}\label{eq:variance_aprox_double}
 V(X| a < X < b) = \sigma^2 \Bigg( 1 + \bigg(\frac{\alpha N(\alpha) - \beta N(\beta) }{\Phi(\beta) - \Phi(\alpha) }\bigg) - \bigg(\frac{N(\alpha) - N(\beta) }{\Phi(\beta) - \Phi(\alpha) }\bigg)^2 \Bigg)
\end{equation}
%
\en{where $\beta = \frac{b-\mu}{\sigma}$ and $\alpha = \frac{a-\mu}{\sigma}$.}
\es{donde $\beta = \frac{b-\mu}{\sigma}$ y $\alpha = \frac{a-\mu}{\sigma}$.}
%
\en{With a single-sided truncation, these functions can be simplified as,}
\es{Con un \'unico truncamiento, estas funciones se pueden simplificar como,}
%
\begin{equation*}
 E(X| a < X )   =  \mu + \sigma \frac{\N(\alpha)}{1 - \Phi(\alpha) } \ \ , \ \ V(X| a < X )  = \sigma^2 \Bigg( 1 + \bigg(\frac{\alpha \N(\alpha)}{1 - \Phi(\alpha) }\bigg) - \bigg(\frac{\N(\alpha)}{1 - \Phi(\alpha) }\bigg)^2 \Bigg) 
\end{equation*}
%
\en{Then, the Gaussian that best approximates $p(d_1)$ in a winning case is}
\es{Luego, la Gaussiana que mejor aproxima a $p(d_1)$ en un caso ganador es}
%
\begin{equation}\label{eq:p*_d} \tag{\texttt{approx()}}
 \widehat{p}(d) = \N(d | \widehat{\delta}, \widehat{\vartheta}^2) =
 \begin{cases*}
 \N\Big(d \,  | \, E(d | -\varepsilon < d < \varepsilon ) , \,  V(d | -\varepsilon < d < \varepsilon ) \, \Big) & \text{tie} \\
\N\Big(d \,  | \, E(d | d > -\varepsilon ) , \,  V(d | d > -\varepsilon ) \, \Big) & \text{not tie}
  \end{cases*}
\end{equation}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:pd_approx, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia},belowskip=-0.77 \baselineskip]
tie, not_tie = true, false
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python},belowskip=-0.77 \baselineskip]
tie, not_tie = True, False
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r},belowskip=-0.77 \baselineskip]
tie = T; not_tie = F 
\end{lstlisting}
\end{paracol}
\begin{lstlisting}[backgroundcolor=\color{all}]
pd_approx = approx(d, margin, not_tie)
\end{lstlisting}
%
\en{Given $\widehat{p}(d_1)$, we can compute the approximate ascending message.}
\es{Dada $\widehat{p}(d_1)$, podemos calcular el mensaje ascendentes aproximado.}
%
\begin{equation}\label{eq:m^_d_fd} \tag{\texttt{approx\_lhood\_d1}}
\begin{split}
 m_{d_1 \rightarrow f_{d_1}}(d_1)   = \frac{p(d_1)}{m_{f_{d_1} \rightarrow d_1}(d_1)} 
 & \approx \frac{\widehat{p}(d_1)}{m_{f_{d_1} \rightarrow d_1}(d_1)}  \\
& = \frac{\N(d_1 \,  | \,\widehat{\delta} , \, \widehat{\vartheta}^{\,2} )}{\N(d_1 | \delta, \vartheta^2)} 
\propto N(d_1,\delta_{\div},\vartheta_{\div}^2 )
\end{split}
\end{equation}
%
\en{with}\es{con} $\delta_{\div} = \frac{\widehat{\delta}}{\widehat{\vartheta}^2} - \frac{\delta}{\vartheta^2}$ \en{and}\es{y} $\vartheta_{\div}^2 = (\frac{1}{\widehat{\vartheta}^2} - \frac{1}{\vartheta^2})^{-1}$ 
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:d_div, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all},belowskip=-0.77 \baselineskip]
approx_lhood_d1 = pd_approx/d
\end{lstlisting}  
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia}]
d_div = approx_lhood_d1.mu
v_div = approx_lhood_d1.sigma
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python}]
d_div = lhood_d1_approx.mu
v_div = lhood_d1_approx.sigma
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r}]
d_div = lhood_d1_approx$mu
v_div = lhood_d1_approx$sigma
\end{lstlisting}
\end{paracol}
%
\begin{equation}\label{eq:^m_fd_ta} \tag{\texttt{lhood\_ta\_approx}}
\begin{split}
\widehat{m}_{f_{d_1} \rightarrow t_a}(t_a) & =  \iint \mathbb{I}(d_1 = t_a - t_b) \N(d_1 | \delta_{\div}, \vartheta_{\div}^2) \N(t_b | \mu_b , \sigma_b^2 )  \, d{d_1} d_{t_b} \\
& = \int  \N( t_a-t_b | \delta_{\div}, \vartheta_{\div}^2) \N(t_b | \mu_b , \sigma_b^2 )  \,  d_{t_b} \\
& = \N(t_a \, | \, \mu_b + \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_b^2) \\
\end{split}
\end{equation}
%
\begin{equation}\label{eq:^m_fta_p} \tag{\texttt{lhood\_p1\_approx}}
\begin{split}
\widehat{m}_{f_{t_a} \rightarrow p_1}(p_1) &= \iint \mathbb{I}(t_a = p_1 + p_2) \N(t_a \, | \, \mu_b + \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_b^2) \N(p_2 | \mu_2 , \sigma_2^2 + \beta^2)  \, d{t_a} d_{p_2} \\
& = \int \N(p_1 + p_2 \, | \, \mu_b + \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_b^2) \N(p_2 | \mu_2 , \sigma_2^2+ \beta^2 )   \, d_{p_2} \\
& = \N( p_1 \,|\,  \underbrace{\mu_b - \mu_2}_{\mu_1-\delta} + \delta_{\div}  \,,\,\vartheta_{\div}^2 + \underbrace{\sigma_b^2 + \sigma_2^2 + \beta^2}_{\vartheta^2 - (\sigma_1^2 + \beta^2)})  \\
\end{split}
\end{equation}
%
\begin{equation}\label{eq:^m_fp_s} \tag{\texttt{lhood\_s1\_approx}}
\begin{split}
\widehat{m}_{f_{p_1} \rightarrow s_1}(s_1) & = \int \N(p_1|s_1,\beta^2) \N(p_1| \mu_1 - \delta + \delta_{\div}, \vartheta_{\div}^2 + \vartheta^2 - \sigma_1^2 - \beta^2)dp_1 \\
& = \N(s_1| \mu_1 - \delta + \delta_{\div}, \vartheta_{\div}^2 + \vartheta^2 - \sigma_1^2)
\end{split}
\end{equation}
%
\begin{equation}\label{eq:^p_s} \tag{\texttt{posterior\_s1\_approx}}
 \widehat{p}(s_1) = \N(s_1|\mu_1, \sigma_1^2) \N(s_1| \mu_1 - \delta + \delta_{\div}, \vartheta_{\div}^2 + \vartheta^2 - \sigma_1^2)
\end{equation}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:lhood_s1_approx, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia},belowskip=-0.77 \baselineskip]
mu1 = prior1.mu
v2, v_div_2 = v^2, v_div^2
sigma1_2 = prior1.sigma^2
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python},belowskip=-0.77 \baselineskip]
mu1 = prior1.mu
v2, v_div_2 = v**2, v_div**2 
sigma1_2 = prior1.sigma**2
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r},belowskip=-0.77 \baselineskip]
mu1 = prior1$mu
v2 = v^2; v_div_2 = v_div^2
sigma1_2 = prior1$sigma^2
\end{lstlisting}
\end{paracol}
\begin{lstlisting}[backgroundcolor=\color{all}]
lhood_s1_approx = Gaussian(mu = (mu1 - d + d_div), sigma = sqrt(v_div_2 + v2 - sigma1_2) )
posterior_s1_approx = prior1 * lhood_s1_approx
\end{lstlisting}

\subsection{\en{Multiples temas}\es{Varios equipos}} \label{sec:iterative_posterior} 
%
\en{In this section we will see how to find the best approximation to the exact posterior in cases where we have more than two teams.}
\es{En esta secci\'on veremos como encontrar la mejor aproximaci\'on al posterior exacto en casos en los que tenemos m\'as de dos equipos.}
%
\en{Let's assume that $n$ agents, organized in $k$ teams $\{1, \dots, k\}$, participate in an event.}
\es{Supongamos que $n$ agentes, organizados en $k$ equipos $\{1, \dots, k\}$, participan de un evento.}
%
\en{The team assignment is represented by a partition of the set of agents, $A$, into $k$ non-overlapping subsets, $A_i$.}
\es{La asignaci\'on de equipos se representa como una partici\'on del conjunto de agentes, $A$, en $k$ subconjuntos disjuntos, $A_i$.}
%
\en{Due to the transitivity of the result, it is enough to evaluate $k-1$ distribution of differences $d_i$ between consecutive teams in the ranking.}
\es{Gracias a la transitividad de los resultados, es suficiente con evaluar $k-1$ distribuciones de diferencia $d_i$ entre equipos consecutivos en el ranking.}
%
\en{For that purpose we define the order of teams that arises from the observed result, $ o:= (o_1, \ dots, o_k) $, where $ o_1 $ indicates the winning team, and in general $ o_i = e $ indicates that the team $ e $ was located at position $ i $.}
\es{Para ese prop\'osito definimos el orden de equipos que surge del resultado observdo, $o := (o_1, \dots, o_k)$, donde $o_1$ indica el equipo ganador, y en general $o_i = e$ indica que el equipo $e$ qued\'o ubicado en la posici\'on $i$.}
%
\begin{figure}[t!]
  \centering
  \scalebox{.9}{
  \tikz{ %
        \node[factor] (fr) {} ;
        \node[const, above=of fr] (nfr) {$f_r$}; %
	\node[const, above=of nfr] (dfr) {\large $\mathbb{I}(d_i>0)$}; %
        \node[latent, left=of fr] (d) {$d_j$} ; %
        \node[factor, left=of d] (fd) {} ;
        \node[const, above=of fd] (nfd) {$f_d$}; %
        \node[const, above=of nfd] (dfd) {\large $\mathbb{I}(d_i=t_{o_i} - t_{o_{i+1}})$}; %
        
        \node[latent, left=of fd,xshift=-0.9cm] (t) {$t_e$} ; %
        \node[factor, left=of t] (ft) {} ;
        \node[const, above=of ft] (nft) {$f_t$}; %
        \node[const, above=of nft,xshift=0.5cm] (dft) {\large $\mathbb{I}(t_e = \sum_{i \in A_e} p_i)$}; %

        \node[latent, left=of ft] (p) {$p_i$} ; %
        \node[factor, left=of p] (fp) {} ;
        \node[const, above=of fp] (nfp) {$f_p$}; %
        \node[const, above=of nfp] (dfp) {\large $N(p_i|s_i,\beta^2)$}; %

        \node[latent, left=of fp] (s) {$s_i$} ; %
        \node[factor, left=of s] (fs) {} ;
        \node[const, above=of fs] (nfs) {$f_s$}; %
        \node[const, above=of nfs] (dfs) {\large $N(s_i|\mu_i,\sigma^2)$}; %

        \edge[-] {d} {fr};
	\edge[-] {fd} {d};
        \edge[-] {fd} {t};
        \edge[-] {t} {ft};
        \edge[-] {ft} {p};
        \edge[-] {p} {fp};
        \edge[-] {fp} {s};
        \edge[-] {s} {fs};

        \plate {personas} {(p)(s)(fs)(nfs)(dfp)(dfs)} {$i \in A_e$}; %
        \node[invisible, below=of ft, yshift=-0.6cm] (inv_below_e) {};
	\node[invisible, above=of ft, yshift=1.1cm] (inv_above_e) {};
	\plate {equipos} {(personas) (t)(ft)(dft) (inv_above_e) (inv_below_e)} {$  \text{\en{Let $A$ be a partition of agents }\es{Sea $A$ una partici\'on de agentes } }$  \hspace{3cm} $0 < e \leq |A|$}; %
	\node[invisible, below=of fr, yshift=-0.6cm] (inv_below) {};
	\node[invisible, above=of fr, yshift=1.1cm] (inv_above) {};
	\plate {comparaciones} {(fd) (dfd) (d) (fr) (dfr) (inv_below) (inv_above)} {$o:=$\en{ observed order}\es{ orden observado} \hspace{1cm} $1 \leq i < |A|$};
    }  
    }
  \caption{
  \en{Factorization of the generic multi-team model.}
  \es{Factorizaci\'on del modelo de multiequipos gen\'erico.}
  %
  \en{Plates indicate replication.}
  \es{Las placas indican replicaci\'on.}
  %
  }
  \label{fig:factorGraph_trueskill}
\end{figure}
%
\en{In Figure ~\ref{fig:factorGraph_trueskill} we show the factorization of the general TrueSkill model.}
\es{En la figura~\ref{fig:factorGraph_trueskill} mostramos la factorizaci\'on del modelo general de TrueSkill.}
%
\en{Let's see how to solve a game with 3 teams.}
\es{Veamos como se resuelve un caso de 3 equipos.}
%
\en{For the users of the package there is no difference regarding the previous case.}
\es{Para los usuarios del paquete no hay ninguna diferencia respecto del caso anterior.}
%
\vspace{-0.6cm}
\begin{figure}[H]
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:multi_team_game, caption=\relax, belowskip=-1.5 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{subfigure}[t]{0.32\textwidth}
\begin{lstlisting}[backgroundcolor=\color{julia}]
team_a = [ r1 ]
team_b = [ r2, r3 ]
team_b = [ r4 ]
teams= [team_a,team_b,team_c]
result = [1,0,0]
g = Game(teams,result,p_draw)
p = posteriors(g)
\end{lstlisting} 
\end{subfigure}
\begin{subfigure}[t]{0.32\textwidth}
\begin{lstlisting}[backgroundcolor=\color{python}]
team_a = [ r1 ]
team_b = [ r2, r3 ]
team_b = [ r4 ]
teams= [team_a,team_b,team_c]
result = [1,0,0]
g = Game(teams,result,p_draw)
p = g.posteriors()
\end{lstlisting}
\end{subfigure}
\begin{subfigure}[t]{0.32\textwidth}
\begin{lstlisting}[backgroundcolor=\color{r}]
teams = list()
teams$team_a = c(r1)
teams$team_b = c(r2, r3)
teams$team_c = c(r4)
result = c(1,0,0)
g = Game(teams,result,p_draw)
p = g$posteriors()
\end{lstlisting}   
\end{subfigure}
\end{figure}
\vspace{-0.6cm}
%
\en{In these cases it is impossible to perform a one-shot inference because of the mutual dependency between the distribution of difference, $p(d_i)$.}
\es{En estos caso es imposible realizar la inference de una sola pasada por la dependencia mutua entre las distribuciones de diferencia, $p(d_i)$.}
%
\en{The basic idea is to update repeatedly forward and backward all messages in the shortest path between any two marginals $p(d_i)$ until convergence, as shown in Figure~\ref{fig:ep_ts}.}
\es{La idea b\'asica es actualizar repetidamente hacia adelante y hacia atr\'as todos los mensajes en el camino m\'as corto entre dos marginales $p(d_i)$ hasta la convergencia, como se muestra en la figura~\ref{fig:ep_ts}.}
%
\begin{figure}[H]
  \centering
  \scalebox{.9}{
\tikz{ %        
        \node[factor, xshift=-5cm] (fta) {} ;
        \node[const, right=of fta] (nfta) {$f_{t_a}$}; %
        \node[latent, below=of fta,yshift=-0.5cm] (ta) {$t_a$} ; %
        
        \node[factor] (ftb) {} ;
        \node[const, right=of ftb] (nftb) {$f_{t_b}$}; %
        \node[latent, below=of ftb,yshift=-0.5cm] (tb) {$t_b$} ; %
        
        \node[factor, xshift=5cm] (ftc) {} ;
        \node[const, right=of ftc] (nftc) {$f_{t_c}$}; %        
        \node[latent, below=of ftc,yshift=-0.5cm] (tc) {$t_c$} ; %
        
        \node[factor, below=of tb, xshift=-3cm] (fd1) {} ;
        %\node[const, left=of fd1] (nfd1) {$f_{d_0}$}; %        
        \node[latent, below=of fd1,yshift=-1cm] (d1) {$d_1$} ; %
        \node[factor, below=of d1,yshift=-1cm] (fr1) {} ;
        
        \node[factor, below=of tb, xshift=3cm] (fd2) {} ;
        %\node[const, above=of fd2] (nfd2) {$f_{d_{1}}$}; %        
        \node[latent, below=of fd2,yshift=-1cm] (d2) {$d_2$} ; %
        \node[factor, below=of d2,yshift=-1cm] (fr2) {} ;
        
        \edge[-] {ta} {fta,fd1}
        \edge[-] {tb} {ftb,fd1,fd2}
        \edge[-] {tc} {ftc,fd2}
        \edge[-] {d1} {fd1,fr1}
        \edge[-] {d2} {fd2,fr2}
        
        \path[draw, -latex, fill=black!50,sloped] (fd1) edge[bend left,draw=black!50] node[midway,above,color=black!75] {\scriptsize  \texttt{lhood\_lose\_tb}} (tb);
        
        \path[draw, -latex, fill=black!50,sloped] (tb) edge[bend left,draw=black!50] node[midway,below,color=black!75] {\scriptsize \texttt{ \ posterior\_lose\_tb}} (fd1);
        
        \path[draw, -latex, fill=black!50,sloped] (fd2) edge[bend right,draw=black!50] node[midway,above,color=black!75] {\scriptsize \texttt{lhood\_win\_tb}} (tb);
        
        \path[draw, -latex, fill=black!50,sloped] (tb) edge[bend right,draw=black!50] node[midway,below,color=black!75] {\scriptsize \texttt{posterior\_win\_tb}} (fd2);
        
        \path[draw, -latex, fill=black!50,sloped] (fta) edge[bend left,draw=black!50] node[midway,above,color=black!75] {\scriptsize \texttt{prior\_ta}} (ta);
        
        \path[draw, -latex, fill=black!50,sloped] (fr1) edge[bend left,draw=black!50] node[midway,above,color=black!75, rotate=180] {\scriptsize \texttt{lhood\_d1}} (d1);
        
        \path[draw, -latex, fill=black!50,sloped] (d1) edge[bend left,draw=black!50] node[midway,above,color=black!75] {\scriptsize \texttt{lhood\_d1\_approx}} (fd1);
        
        \path[draw, -latex, fill=black!50,sloped] (fd1) edge[bend left,draw=black!50] node[midway,above,color=black!75] {\scriptsize \texttt{prior\_d1}} (d1);
        
        \path[draw, -latex, fill=black!50,sloped] (tc) edge[bend left,draw=black!50] node[midway,above,color=black!75] {\scriptsize \texttt{lhood\_tc\_approx}} (ftc);
        
        
        %\path[draw, -latex, fill=black!50,sloped] (fr2) edge[bend left,draw=black!50] node[midway,above,color=black!75, rotate=180] {\scriptsize \textbf{5:} \emph{likelihood}$(d_{0})$} (d2);
        
        %\path[draw, -latex, fill=black!50,sloped] (fd2) edge[bend left,draw=black!50] node[midway,above,color=black!75] {\scriptsize \textbf{4:} \emph{prior}$(d_{0})$} (d2);
        
        
} 
}
\caption{
 \en{Factorization of a game with 3 teams.}
 \es{Factorizaci\'on de una partida con 3 equipos.}
 %
 \en{We only show factors from the teams to the results.}
 \es{Mostramos s\'olo factores desde los equipos hasta los resultados.}
 %
 \en{The names will be used to explain the iterative procedure known as loopy belief propagation.}
 \es{Los nombres se usar\'an para explicar el procedimiento iterativo conocido como \emph{loopy belief propagatiion}.}
}
\label{fig:ep_ts}
\end{figure}
%
\en{First we define the Prior of the teams.}
\es{Primero definimos el prior de los equipos.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:team_prior, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}]
prior_ta= performance(team_a); prior_tb= performance(team_b); prior_tc= performance(team_c)
\end{lstlisting}
%
\en{Messages that are not yet defined are initialized with a neutral form, such as a Gaussian distribution with infinite variance.}
\es{Los mensajes que aún no est\'an definidos se inicializan con una forma neutra, como una distribuci\'on gaussiana con varianza infinita.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:init_lhood, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia},belowskip=-0.77 \baselineskip]
N_inf = Gaussian(0., Inf)
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python},belowskip=-0.77 \baselineskip]
N_inf = Gaussian(0, inf)
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r},belowskip=-0.77 \baselineskip]
N_inf = Gaussian(0, Inf)
\end{lstlisting}
\end{paracol}
\begin{lstlisting}[backgroundcolor=\color{all}]
lhood_lose_ta = N_inf; lhood_win_ta = N_inf
lhood_lose_tb = N_inf; lhood_win_tb = N_inf
lhood_lose_tc = N_inf; lhood_win_tc = N_inf
\end{lstlisting}
%
\en{We compute the margins for each comparison, $d_i$.}
\es{Calculamos el los margenes para cada comparaci\'on $d_1$.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:margin, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}]
margin = compute_margin(p_draw, sqrt(3)*BETA)
\end{lstlisting}
%
\en{Let's start the iterative process by computing the messages of one distributions of difference, for example $d_1$.}
\es{Empezmos el proceso iterativo calculando una de las distribuciones de diferencia, por ejemplo $d_1$.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:d1, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}]
posterior_win_ta = prior_ta * lhood_lose_ta 
posterior_lose_tb = prior_tb * lhood_win_tb
prior_d1 = posterior_win_ta - posterior_lose_tb
lhood_d1_approx = approx(prior_d1, margin, not_tie) / prior_d1 
\end{lstlisting}
%
\en{The message \texttt{lhood\_d1\_approx} allows us to update the distribution of performance $t_b$.}
\es{El mensahe \texttt{lhood\_d1\_approx} nos permite actualizar la distribuci\'on de rendimietos $t_b$.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:tb_lose, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}]
lhood_lose_tb = posterior_win_ta - lhood_d1_approx 
\end{lstlisting}
%
\en{Then we compute the the messages of the next distribution of differences $d_2$.}
\es{Luego computamos los mensajes de la siguiente distirbuci\'on de diferencia $d_2$.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:d2, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}]
posterior_win_tb = prior_tb * lhood_lose_tb
posterior_lose_tc = prior_tc * lhood_win_tc 
prior_d2 = posterior_win_tb - posterior_lose_tc
lhood_d2_approx = approx(prior_d2, margin, tie) / prior_d2 
\end{lstlisting}
%
\en{The message \texttt{lhood\_d2\_approx} allows us to update the distribution of performance $t_b$.}
\es{El mensaje \texttt{lhood\_d2\_approx} nos permite actualizar la distribuci\'on de rendimiento $t_b$.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:tb_win, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}]
lhood_win_tb = posterior_lose_tc + lhood_d2_approx
\end{lstlisting}
%
\en{Then, loop code \ref{lst:d1}, \ref{lst:tb_lose}, \ref{lst:d2}, \ref{lst:tb_win} until convergence.}
\es{Entonces, repite los c\'odigos \ref{lst:d1}, \ref{lst:tb_lose}, \ref{lst:d2}, \ref{lst:tb_win} hasta alcanzar convergencia.}
%
\en{Once the iteration is finished, we send the last ascending message to the teams on the sides.}
\es{Finalizada la iteraci\'on, enviamos los últimos mensajes ascendentes a los equipos de los bordes.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:te_side, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}]
lhood_win_ta = posterior_lose_tb + lhood_d1_approx
lhood_lose_tc = posterior_win_tb - lhood_d2_approx
\end{lstlisting}
%
\en{We are now able to compute the likelihood of each team.}
\es{Ahora estamos en condiciones de computar los likelihood de cada equipo.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:lhood_te_approx, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{lstlisting}[backgroundcolor=\color{all}]
lhood_ta_approx = lhood_lose_ta * lhood_win_ta 
lhood_tb_approx = lhood_lose_tb * lhood_win_tb
lhood_tc_approx = lhood_lose_tc * lhood_win_tc
\end{lstlisting}
%
\en{As an example, we compute the posterior of player 2.}
\es{A modo de ejemplo, computamos el posterior del jugador 2.}
%
\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:posterior_s2_approx, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia},belowskip=-0.77 \baselineskip]
prior2 = r2.N
ex = exclude(prior_tb,prior2)
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python},belowskip=-0.77 \baselineskip]
prior2 = r2.N
ex = prior_tb.exclude(prior2)
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r},belowskip=-0.77 \baselineskip]
prior2 = r2$N
ex = prior_tb$exclude(prior2)
\end{lstlisting}
\end{paracol}
\begin{lstlisting}[backgroundcolor=\color{all}]
team_b_without_s2 = ex
lhood_s2_approx = lhood_ta_approx - team_b_without_s2 
posterior_s2_approx = prior2 * lhood_s2_approx 
\end{lstlisting}

\subsection{History} \label{sec:throguthTime}

\en{In this section we will see how to find the best approximation to the exact posterior in a history of events in which $n$ players compete over a period of $T$ time steps or temporal batches (e.g. day, week, month, year).}
\es{En esta secci\'on vamos a ver c\'omo se obtiene la mejor aproximaci\'on al posterior exacto en una historia de eventos en la que $n$ agentes compiten durante $T$ pasos temporales o \emph{batches} (e.g. d\'ia, semana, mes, año).}
% 
\en{Within each time step $t$ an agent $i$ can participate in $K$ events, $K_{i,t}$.}
\es{Al interior de cada paso temporal $t$ un agente $i$ puede participar en $K$ eventos, $K_{i_t}$}
%
\begin{figure}[h!]
  \centering
  \scalebox{.9}{
\tikz{ %
        \node[latent] (s0) {$s_{i_{t-1}}$} ; %

        \node[factor, right=of s0,xshift=1cm ] (fs1) {} ;
        \node[const, above=of fs1] (nfs1) {$f_{s_{i_{t}}}$}; %

        \node[latent, right=of fs1, xshift=1.25cm] (s1) {$s_{i_t}$} ; %

        \node[factor, right=of s1, xshift=1.25cm ] (fs2) {} ;
        \node[const, above=of fs2] (nfs2) {$f_{s_{i_{t+1}}}$}; %

        \node[latent, right=of fs2,xshift=1cm] (s2) {$s_{i_{t+1}}$} ; %

        \node[factor, below=of s1,xshift=-1.4cm,yshift=-1cm] (fp0) {} ;
        \node[const, right=of fp0] (nfp0) {$f_{p_{i_t}(1)}$}; %

        \node[factor, color=white, below=of s1] (fp1) {} ;
        \node[const, below=of fp1, yshift=0.2cm] (nfp1) {$\dots$}; %

        \node[factor, below=of s1,xshift=1.4cm,yshift=-1cm] (fp2) {} ;
        \node[const, left=of fp2] (nfp2) {$f_{p_{i_t}(k)}$}; %

        \node[latent, below=of fp0] (p0) {\footnotesize$p_{i_t}(1)$} ; %
        %\node[latent, below=of fp1] (p1) {\footnotesize$p_i^{t}(2)$} ; %
        \node[latent, below=of fp2] (p2) {\footnotesize$p_{i_t}(k)$} ; %

        %\draw[bend right=90] (fs1) arc (s1) node[midway,above]{label};
        %\draw[bend left,->]  (fs1) to node [auto] {Link} (s1);
        \edge[-] {s1} {fp0,fp1,fp2};
        \edge[-] {fp0} {p0};
        %\edge[-] {fp1} {p1};
        \edge[-] {fp2} {p2};
        \edge[-] {fs1} {s0,s1};
        \edge[-] {fs2} {s1,s2};
        %\edge[bend right] {s0} {fs1};
        \path[draw, -latex, fill=black!50] (s0) edge[bend right,draw=black!50] node[midway,below,color=black!75] {\scriptsize \emph{posterior}$(t-1)$} (fs1);
        \path[draw, -latex, fill=black!50] (fs1) edge[bend left,draw=black!50] node[midway,above,color=black!75] {\scriptsize \emph{prior}$(t)$} (s1);
        \path[draw, -latex, fill=black!50] (s2) edge[bend left,draw=black!50] node[midway,below,color=black!75] {\scriptsize \emph{\ \ inversePosterior}$(t+1)$} (fs2);
        \path[draw, -latex, fill=black!50] (fs2) edge[bend right,draw=black!50] node[midway,above,color=black!75] {\scriptsize \emph{inversePrior}$(t)$} (s1);
        \path[draw, -latex, fill=black!50,sloped] (fp0) edge[bend left,draw=black!50] node[midway,above,color=black!75] {\scriptsize \emph{likelihood}$(t,k)$} (s1);
        \path[draw, -latex, fill=black!50,sloped] (s1) edge[bend left,draw=black!50] node[midway,above,color=black!75] {\scriptsize \emph{\ \ withinPrior}$(t,k)$} (fp2);
}
}
\caption{
\en{Factor graph of a history of events around a skill variable $s$ of an agent $i$ at a time step $t$.}
\es{Grafo de factorizaci\'on de una historia de eventos alrededor de la habilidad $s$ de un agente $i$ en el paso temporal $t$}
%
\en{The variables $ p_ {i_t} (j) $ represents the performance $ p $ that player $i$ had in their $j$-th game within the time step $ t $.}
\es{Las variables $p_{i_t}(j)$ representa el rendimiento $p$ que ese jugador tuvo en la $j$-\'esima partida al interior del paso temporal $t$.}
%
\en{The arrows represents messages computed by the sum-product algorithm.}
\es{Las flechas representan los mensajes computados por el algoritmo de sum-product.}
%
\en{The names were selected for the sole purpose of simplifying the notation.}
\es{Los nombres fueron elegidos solamente para simplificar la notaci\'on.}
}
\label{fig:history}
\end{figure}
%
\en{In the Figure~\ref{fig:history} we show a schematic representation of the factor graph of a history of events.}
\es{En la figura~\ref{fig:history} mostramos representaci\'on esquem\'atica del grapho de factorizaci\'on de un historia de eventos.}
%
\en{By the sum-product algorithm, we know that the marginal distribution of any variable is the product of the messages it receives from its neighbours.}
\es{Mediante el algoritmo de sum-product, sabemos que la distribuci\'on marginal de cualquier variable es el producto de los mensajes que esta recibe de sus vecinos.}
\en{Replaced the messages by the selected names, the distribution can be expressed as,}
\es{Remplazando los mensajes por los nombres seleccionados, esta distribuci\'on se puede expresar como,}
%
\begin{equation}
 p(s_{i_t}) = \emph{prior}_i(t) \cdot \emph{inversePrior}_i(t) \cdot \prod_{k=1}^{K_{i_t}} \emph{likelihood}_i(t,k)
\end{equation}
%
\en{The \emph{prior} and \emph{inversePrior} messages are the neighboring skill estimates, to which some uncertainty $\gamma$ is added due to the time step.}
\es{Los mensajes \emph{prior} e \emph{inversePrior} son las estimaciones de habilidad vecinas, a las que se le agrega cierta incertidumbre $\gamma$ por el paso temporal.}
%
\begin{equation*}
\emph{prior}_i(t) = \N(s_{i_t}|s_{i_{t-1}}, \gamma^2) \ \ \ \ \ \ \emph{inversePrior}_i(t) = \N(s_{i_t}|s_{i_{t+1}}, \gamma^2)
\end{equation*}
%
\en{And the likelihoods of events are computed following the section~\ref{sec:iterative_posterior}, using as prior all the information except that of the event of interest.}
\es{Y las verosimilituides se computan siguiendo la secci\'on~\ref{sec:iterative_posterior}, usando como prior toda la informaci\'on salvo la de la partida de inter\'es.}
%
 \begin{equation}
 \emph{withinPrior}_i(t,k) = \emph{prior}_i(t) \cdot \emph{inversePrior}_i(t) \cdot \prod_{\hfrac{q=1}{q\neq k}}^{K_{i_t}} \emph{likelihood}_i(t,q) = \frac{p(s_i^t) }{\emph{likelihood}_i(t,k)}
 \end{equation}
% 
\en{There is a mutual dependency between forward and backward messages that make imposible a one shot inference iteration.}
\es{Existe una dependencia muta entre los mensajes hacia adelante y hacia atras, haciendo imposible una inferencia de única iteraci\'on.}
%
\en{The basic idea is to update repeatedly forward and backward until convergence, making sure that the effect of the previous update is removed before the new effect is added.}
\es{La idea b\'asica es actualizar repetidas veces los mensajes hacia adelante y hacia atras hasta la convergencia, asegur\'andonos que el efecto de la actualizaci\'on previa sea removida antes de que el nuevo efecto se agregue.}
%
\en{The messages that are not yet defined, for example the inverse prior in the first forward pass, are replace it by a neutral form like a unit scalar or a Gaussian distribution with infinite variance.}
\es{Los mensajes que no est\'an todav\'ia definidos, por ejemplo el prior inverso en la primer pasada hacia adelante, es remplazado por una forma neutral como un escalar unidad o una distribuci\'on gausiana con infinita varianza.}
%
\en{Finally, the messages that the variable $s_{i_t}$ sends to the past and the future are,}
\es{Finalmente, los mensajes que la variable $s_{i_t}$ env\'ia al pasado y al futuro son,}
%
\begin{equation*}
  \emph{posterior}_i(t-1) = \frac{p(s_{i_{t-1}})}{\emph{inversePrior}_i(t-1)} \ \ \ , \ \ \ \emph{inversePosterior}_i(t+1) = \frac{p(s_{i_{t+1}})}{\emph{prior}_i(t+1)}
\end{equation*}



%

\begin{lstlisting}[backgroundcolor=\color
{white},label=lst:posterior_s2_approx, caption=\relax, belowskip=-1.0 \baselineskip, aboveskip=-0 \baselineskip]
\end{lstlisting}
\begin{paracol}{3}
\begin{lstlisting}[backgroundcolor=\color{julia},belowskip=-0.77 \baselineskip]
prior2 = r2.N
ex = exclude(prior_tb,prior2)
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{python},belowskip=-0.77 \baselineskip]
prior2 = r2.N
ex = prior_tb.exclude(prior2)
\end{lstlisting}
\switchcolumn
\begin{lstlisting}[backgroundcolor=\color{r},belowskip=-0.77 \baselineskip]
prior2 = r2$N
ex = prior_tb$exclude(prior2)
\end{lstlisting}
\end{paracol}
\begin{lstlisting}[backgroundcolor=\color{all}]
team_b_without_s2 = ex
lhood_s2_approx = lhood_ta_approx - team_b_without_s2 
posterior_s2_approx = prior2 * lhood_s2_approx 
\end{lstlisting}

\en{At each forward pass we store each forward message, i.e. \emph{prior}$_i(t+1)$.}
\es{En cada pasada hacia adelante, guardamos cada mensaje hacia adelante, i.e. \emph{prior}$_i(t+1)$.}
%
\en{And at each backward pass we compute the backward message, i.e. \emph{inversePrior}$_i(t-1)$.}
\es{En cada pasada hacia atr\'as computamos el mensaje hacia atr\'as, i.e. \emph{inversePrior}$_i(t-1)$.}
%
\subsection{Data Structures} \label{sec:estructuras} 

% 
% 
% 
% \begin{leftbar}
% Note that around the \verb|{equation}| above there should be no spaces (avoided
% in the {\LaTeX} code by \verb|%| lines) so that ``normal'' spacing is used and
% not a new paragraph started.
% \end{leftbar}
% 
% 
% \begin{leftbar}
% As the synopsis above is a code listing that is not meant to be executed,
% one can use either the dedicated \verb|{Code}| environment or a simple
% \verb|{verbatim}| environment for this. Again, spaces before and after should be
% avoided.
% 
% Finally, there might be a reference to a \verb|{table}| such as
% Table~\ref{tab:overview}. Usually, these are placed at the top of the page
% (\verb|[t!]|), centered (\verb|\centering|), with a caption below the table,
% column headers and captions in sentence style, and if possible avoiding vertical
% lines.
% \end{leftbar}

% \begin{table}[t!]
% \centering
% \begin{tabular}{lllp{7.4cm}}
% \hline
% Type           & Distribution & Method   & Description \\ \hline
% GLM            & Poisson      & ML       & Poisson regression: classical GLM,
%                                            estimated by maximum likelihood (ML) \\
% \end{tabular}
% \caption{\label{tab:overview} Overview of various count regression models. The
% table is usually placed at the top of the page (\texttt{[t!]}), centered
% (\texttt{centering}), has a caption below the table, column headers and captions
% are in sentence style, and if possible vertical lines should be avoided.}
% \end{table}
%












































%% -- Illustrations ------------------------------------------------------------

%% - Virtually all JSS manuscripts list source code along with the generated
%%   output. The style files provide dedicated environments for this.
%% - In R, the environments {Sinput} and {Soutput} - as produced by Sweave() or
%%   or knitr using the render_sweave() hook - are used (without the need to
%%   load Sweave.sty).
%% - Equivalently, {CodeInput} and {CodeOutput} can be used.
%% - The code input should use "the usual" command prompt in the respective
%%   software system.
%% - For R code, the prompt "R> " should be used with "+  " as the
%%   continuation prompt.
%% - Comments within the code chunks should be avoided - these should be made
%%   within the regular LaTeX text.

\section{Illustrations} \label{sec:illustrations}

%
\begin{comment}


\begin{CodeChunk}
\begin{CodeInput}
R> data("quine", package = "MASS")
\end{CodeInput}
\end{CodeChunk}

\begin{leftbar}
For code input and output, the style files provide dedicated environments.
Either the ``agnostic'' \verb|{CodeInput}| and \verb|{CodeOutput}| can be used
or, equivalently, the environments \verb|{Sinput}| and \verb|{Soutput}| as
produced by \fct{Sweave} or \pkg{knitr} when using the \code{render_sweave()}
hook. Please make sure that all code is properly spaced, e.g., using
\code{y = a + b * x} and \emph{not} \code{y=a+b*x}. Moreover, code input should
use ``the usual'' command prompt in the respective software system. For
\proglang{R} code, the prompt \code{"R> "} should be used with \code{"+  "} as
the continuation prompt. Generally, comments within the code chunks should be
avoided -- and made in the regular {\LaTeX} text instead. Finally, empty lines
before and after code input/output should be avoided (see above).
\end{leftbar}
\end{comment}

This tutorial will guide you through some of typical \textbf{TTT} package application.
Familiarity with Python is assumed, so if you are new to Python there is plenty of online documentation like the official Python documentation
page at \href{http://www.python.org/doc/}{\textcolor{blue}{http://www.python.org/doc/}}.
In addition to the module \textbf{TTT}, the libraries collections, dateutil and mathematics(Gaussian) are also required.
In this section its show some applications, starting with an example of TrueSkill of 1vs1, then an example with a data set, and the last one a first example of Trueskill Through Time.


\subsection{Example 1: TrueSkill 1vs1}
The first examples is the most basic one we figure out. Its one of the first examples in the official python package of \texttt{Trueskill}.
In this case, we consider a game that can be won or lost but not tied, in which two players face each other and we want to update our prior of them knowing the result of it.
For that we start creating an environment of \texttt{TrueSkill}, specifying the parameter \texttt{draw\_probability} to zero, not to consider the possibility of a tie.
Then we define the prior of each player. 
Because in this case we don't know anithing of each, they start with a default prior.
This one can be set up at will.
The parameters of this, is the mean and standard deviation of the skill (mu and sigma), the standard deviation of the performance (beta), and the noise add it in the posterior, as the method suggest (noise).
The result of the game, is in format of a list, with a number for each player, meaning 0 for the one that lost the game, and 1 for the winner.
After this, define the game with the method \texttt{Game}, and calculate this the posterior of the player with the method \texttt{posterior}.
We update the prior of each player with the posterior.

Also we show how to get some of the parameters, using the method with name of the parameters in this object.

Our library, its almost four times faster than the official, when computing posteriors.
% explicar el ejemplo de que esta pasando
% presentar variables, mapeo entre ejemplo  y teoria
\lstinputlisting{./code/Example1.py}
\begin{lstlisting}
[Out]: Posterior:  TrueSkill.Rating(mu=29.205, sigma=7.194, beta=4.167, noise=0.083) Mean:  29.2052208700336 Variance:  7.194481348831081
\end{lstlisting}

As we can see, we print the posterior of one of them, showing as the object of the class \texttt{TrueSkill}, with the new parameters.
Esta mal la forma en que devuelve, player 1 deberia haber empeorado por perder. Ademas creo que sort teams solo funca para dos equipos
This show that player 2, that won the game, update his skill with mean $25$ and standard deviation $25/3$ to have a mean $29.20$ and standard deviation $7.19$ approximately.

% la habilidad del jugador 1 es babla
%The time average of this example in a microprocessor i7 babla, its about $4.5$ $10^{-5}$, and for the python package its about $1.9$ $10^{-4}$. About four times faster.
Tabla de valores temporales, esperar a tener el codigo optimizado 
% sacar esto del tiempo aca y hacerlo en el data set y como escala a medida que agrando el data set, presentarlo en una tabla de tiempos.
% 3 o 4 resultados
\subsection{Example 2: TrueSkill data-set}
Another example we want to show how TrueSkill can be used with a data set. 
To start, we will show the implementation for the users that already are familiar with the original TrueSkill package making an almost same implementation and then we will show the way that this package its intend to be used. 
With this way, the use of \textbf{TTT} its trivial. 
For the first and second case we will use as input the Table \ref{tab:csvExample2}. Its important to have the input "Result" as the same format as shown in the table.
In this first case we will use the library Pandas, but it can be done with out it, the only important its how to upload the data set and loop with it. For the second case we still using Pandas but only to keep the same way of reading the CSV file that the first one. 
In this case we don't need to loop manually through the data set.


\begin{table}[h!]
	\centering
	%\resizebox{\textwidth}{!}{%
		\begin{tabular}{llll}
			\hline
			Id  & Player1        & Player2        & Result \\ \hline
			101 & matt64      & Chuk         & [1,0]      \\
			102 & matt64      & David        & [1,0]      \\
			103 & ggg          & matt64       & [0,1]      \\
			104 & Chuk         & David        & [0,1]      \\
			105 & ggg         & TheProffesor & [0,1]      \\
			106 & ggg          & matt64       & [1,0]      \\
			107 & Chuk         & TheProffesor & [0,1]      \\
			108 & Chuk         & NaT          & [1,0]      \\
			109 & David        & TheProffesor & [1,0]      \\
			110 & David        & Chuk         & [1,0]      \\
			111 & TheProffesor & Chuk         & [0,1]      \\
			112 & Mona         & matt64       & [1,0]      \\
			113 & TiNi         & David        & [1,0]      \\
			113 & Chuk         & matt64       & [1,0]      \\
			115 & ggg          & matt64       & [1,0]      \\ \hline
		\end{tabular}%
	%}
	\caption{An example of Data set, used in example 2. }
	\label{tab:csvExample2}
\end{table}

% \subsubsection{Existing Implementation}
% 
% As we can see, the implantation requires a more manual job, by defining dictionary and also adding noise to the priors, like the TrueSkill algorithm suggest. This default noise can be change to other. 
% The only thing we must do manually its to pass the input in the correct format.
% \lstinputlisting{./code/Example2.py}
% [Out]:Time $7.7$ $10^{-3}$ seconds
% 
% In this example, we use the method get, so we can use the global prior only for the first game for each player.
% As the same way of the first example, we are updating the prior of each player with the posterior of each game.
% In this case we are saving this in a dictionary with the name of each player as key.
% Printing at the end this, we will have each player with the latest posterior.
% 
% % explicar como usar la salida
% \subsubsection{Our proposed Implementation}
\lstinputlisting{./code/Example2-1.py}
[Out]:Time $2.8$ $10^{-3}$ seconds
%\todo[inline]{No olvidar agregar los prints que muestra este c\'odigo, no solo el Out}

We create an instance of the class \texttt{history} and use it as parameter for the game composition.
This object contains the list of game's results.

%\todo[inline]{Explicar qu\'e es history bien y mostrar un ejemplo}

Then using the method \texttt{trueskill} in this object, we compute the posteriors. 
ONLINE NO SERIA TRUE PARA SER CMOMO TRUESKILL?
For last, we can see the last posterior of each player, calling the method \texttt{posteriors\_players()}
Like we can see, the new way of implementation its more compact and simple than the original.

\subsection{Example 3: Trueskill True Time}

As it was mentioned already, one of the advantage of \textbf{TTT}, its the way that the algorithm pass information to the past to the future and vice versa, getting a more accurate estimation.
This package is the first implementation of this method, beside the original \texttt{Microsoft} package in \texttt{F\#}, of not free access. CHEQUEAR ESTO
For that, we use the next example. 
Three player, three games, that each one wins one game and lose the other one. 
So if we do TrueSkill, the order of how we compute the games will have importance, making at the end three player with three different skill. 
With \textbf{TTT} this kind of problem its solve.

\lstinputlisting{./code/Example3.py}
\vspace{-0.3cm}
[Out]:Poner Trueskill

[Out]:Poner TTT
\vspace{0.3cm}
We print the posteriors in two instance, to the reason for comparing the posteriors with \texttt{TrueSkill} vanilla, and with \texttt{TTT}.
The 
% y aclarar que pasa si sale con TTT y que saldria si corro trueskill
% poner el el grafico que corro trueskill
%cambiar nombre de throguth time por trueskill
To extend this example to a data set with more games, the only thing that matter is to pass the information in the format show. 
In first place is the composition of games, that its a list, that contain a list for each game, that it have another list for each team. 
So its a list of list of list. 
Then its have a list of list of results, where each element is a list of numbers, representing the result of each team in each game. 
The next important input its the time batches, as default it will make each game in a 


\subsection{Example 4: Estimating the Evolution of the Skill}

%\todo{inline]{poner el ejemplo de seguimiento de la habilidad de un jugador a medida que van pasando los partidos con una funci\'on de evoluci\'on conocida. ejemplo sinte\'etico}









\subsection{Example 5: Performance Analysis}


%\todo[inline]{Aca tendremos dos figuras analizando la base de Go: 1) TT original, TT nuestro, TT-R y TT-Julia ; y otra figura con TTT: Python, Julia y R}


















%% -- Summary/conclusions/discussion -------------------------------------------

\section{Summary and discussion} \label{sec:summary}

\begin{leftbar}
As usual \dots
\end{leftbar}

























%% -- Optional special unnumbered sections -------------------------------------

\section*{Computational details}

\begin{leftbar}
If necessary or useful, information about certain computational details
such as version numbers, operating systems, or compilers could be included
in an unnumbered section. Also, auxiliary packages (say, for visualizations,
maps, tables, \dots) that are not cited in the main text can be credited here.
\end{leftbar}

The results in this paper were obtained using
\proglang{R}~3.4.1 with the
\pkg{MASS}~7.3.47 package. \proglang{R} itself
and all packages used are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at
\url{https://CRAN.R-project.org/}.


\section*{Acknowledgments}

\begin{leftbar}
All acknowledgments (note the AE spelling) should be collected in this
unnumbered section before the references. It may contain the usual information
about funding and feedback from colleagues/reviewers/etc. Furthermore,
information such as relative contributions of the authors may be added here
(if any).
\end{leftbar}

 
\newpage
%% -- Bibliography -------------------------------------------------------------
%% - References need to be provided in a .bib BibTeX database.
%% - All references should be made with \cite, \citet, \citep, \citealp etc.
%%   (and never hard-coded). See the FAQ for details.
%% - JSS-specific markup (\proglang, \pkg, \code) should be used in the .bib.
%% - Titles in the .bib should be in title case.
%% - DOIs should be included where available.

\bibliography{../../bibliografia/journalsAbbr,../../bibliografia/Gaming/gaming}

\newpage

































% \begin{appendix}
% 
% \section{Propiedades}\label{sec:propiedades}
% 
% Las siguientes tres propiedades, junto con las reglas del \emph{sum-product algorithm}, es lo \'unico que se necesita para calcular la posterior anal\'itica del modelo bayesiano.
% 
% \subsection*{Multiplicacion de normales}
% \begin{equation}\label{eq:multiplicacion_normales}
% \begin{split}
%  \int_{-\infty}^{\infty} N(x|\mu_x,\sigma_x^2)N(x|\mu_y,\sigma_y^2) \, dx  &  \overset{*}{=} \int_{-\infty}^{\infty}  \underbrace{N(\mu_x|\mu_y,\sigma_x^2+\sigma_y^2)}_{\text{constante}} N(x|\mu_{*},\sigma_{*}^2) dx \\
%  & = N(\mu_x|\mu_y,\sigma_x^2+\sigma_y^2) \underbrace{\int_{-\infty}^{\infty}  N(x|\mu_{*},\sigma_{*}^2) dx}_{1} \\
%  & = N(\mu_x|\mu_y,\sigma_x^2+\sigma_y^2)
% \end{split}
% \end{equation}
% 
% Donde la igualdad destacada ($\overset{*}{=}$) se demuestra en la secci\'on~\ref{multiplicacion_normales} anexa.
% 
% \subsection*{Integrales con funci\'on indicadora}
% \begin{equation}\label{eq:integral_con_indicadora}
% \begin{split}
%  \int_{-\infty}^{\infty}  \int_{-\infty}^{\infty}  \mathbb{I}(x=h(y,z)) f(x) g(y)\, dx\, dy &=  \int_{-\infty}^{\infty} \int_{h(y,z)}^{h(y,z)} f(h(y,z)) g(y)\, dx\, dy\\
%  & = \int_{-\infty}^{\infty} f(h(y,z)) g(y) dy
%  %& \propto \int f(h(y,z)) g(y) dy
% \end{split}
% \end{equation}
% 
% \subsection*{Simetr\'ia de normales}
% \begin{equation}\label{eq:simetria}
%  N(x|\mu,\sigma^2) = N(\mu|x,\sigma^2) = N(-\mu|-x,\sigma^2) = N(-x|-\mu,\sigma^2)
% \end{equation}
% 
% \subsection*{Derivada de la acumulada normal}
% \begin{equation}\label{eq:phi_norm}
%  \frac{\partial}{\partial x} \Phi(x|\mu,\sigma^2) = N(x|\mu,\sigma^2)
% \end{equation}
% 
% \subsection*{Distribuci\'on normal estandarizada}
% \begin{equation}\label{eq:estandarizar}
%  X \sim N(\mu,\sigma^2) \Rightarrow \frac{X-\mu}{\sigma} \sim N(0,1)
% \end{equation}
% 
% 
% 
% \section{Ejemplo 2 vs 2}
% 
% \begin{figure}[t!]
%   \centering
%   \scalebox{.75}{\input{modelos/trueskill_factorGraph_2equiops.tex}}
%   \caption{\small Grafo bipartito de factorizaci\'on del modelo \texttt{TrueSkill} (Caso 2 vs 2)}
%   \label{fig:modelo_trueskill_2vs2}
% \end{figure}
% 
% 
% \subsection{Mensajes descendentes}
% 
% \paragraph{$\bm{m_{f_s \rightarrow s}(s)}:$}
% 
% \begin{equation}\label{eq:m_fs_s}
% \begin{split}
%  m_{f_{s_i} \rightarrow s_i}(s_i) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{s_i}(\bm{x}) \prod_{h \in n(f_{s_i}) \setminus \{s_i\} } m_{h \rightarrow f_{s_i}}(h) d\bm{x}_{\setminus \{s_i\}}  \\
% & \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{=} \int \dots \int N(s_i| \mu_i, \sigma_i^2) d\bm{x}_{\setminus \{s_i\} } \\
% & \underset{*}{\overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=}} N(s_i| \mu_i, \sigma_i^2)
% \end{split}
% \end{equation}
% 
% Notar que la igualdad se\~nalada $\overset{*}{=}$ vale por definici\'on de la notaci\'on resumen (Eq.~\ref{eq:m_f_v}),
% 
% \begin{equation*}
% \begin{split}
% \bm{x}_{\setminus \{s_i\} } & = \text{arg}(f) \setminus \{s_i\} \\
% &= \text{arg}(N(s_i| \mu_i, \sigma_i^2)) \setminus \{s_i\} \\
% &= \{s_i\} \setminus \{s_i\} \\
% & = \emptyset
% \end{split}
% \end{equation*}
% 
% 
% 
% \paragraph{$\bm{m_{s \rightarrow f_p}(s)}:$}
% 
% \begin{equation}\label{eq:m_s_fp}
%  m_{s_i \rightarrow f_{p_i}}(s_i) \overset{\hfrac{\text{eq}}{\ref{eq:m_v_f}}}{=} \prod_{g \in n(s_i) \setminus  \{f_{p_i} \}} m_{g \rightarrow s_i} (s_i) \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{=} m_{f_{s_i} \rightarrow s_i}(s_i) \overset{\hfrac{\text{eq}}{\ref{eq:m_fs_s}}}{=}   N(s_i| \mu_i, \sigma_i^2)
% \end{equation}
% 
% 
% 
% \paragraph{$\bm{m_{f_p \rightarrow p}(p)}:$}
% 
% \begin{equation}\label{eq:m_fp_p}
% \begin{split}
%  m_{f_{p_i} \rightarrow p_i}(p_i) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{p_i}(\bm{x}) \prod_{h \in n(f_{p_i}) \setminus \{p_i\} } m_{h \rightarrow f_{p_i}}(h) d\bm{x}_{\setminus \{p_i\} }  \\
%  & \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_s_fp}}}{=}} \int \dots \int N(p_i| s_i, \beta^2) N(s_i| \mu_i, \sigma_i^2) d\bm{x}_{\setminus \{p_i\} } \\[0.3cm]
%  & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int N(p_i| s_i, \beta^2) N(s_i| \mu_i, \sigma_i^2) ds_i \\
%  & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \int N(s_i|p_i, \beta^2) N(s_i| \mu_i, \sigma_i^2) ds_i \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:multiplicacion_normales}}}{=} N(p_i|\mu_i,\beta^2 + \sigma_i^2)
% \end{split}
% \end{equation}
% 
% \paragraph{$\bm{m_{p \rightarrow f_t}(p)}:$}
% 
% \begin{equation}\label{eq:m_p_ft}
% \begin{split}
%  m_{p_i \rightarrow f_{t_e}}(p_i) & \overset{\hfrac{\text{eq}}{\ref{eq:m_v_f}}}{=} \prod_{g \in n(p_i) \setminus  \{f_{t_e} \}} m_{g \rightarrow p_i} (p_i) \\
%  & \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{=} m_{f_{p_i} \rightarrow p_i}(p_i) \overset{\hfrac{\text{eq}}{\ref{eq:m_fp_p}}}{=} N(p_i|\mu_i,\beta^2 + \sigma_i^2)
% \end{split}
% \end{equation}
% 
% \paragraph{$\bm{m_{f_t \rightarrow t}(t)}:$}
% 
% \begin{equation}
% \begin{split}
%  m_{f_{t_e} \rightarrow t_e}(t_e) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{t_e}(\bm{x}) \prod_{h \in n(f_{t_e}) \setminus \{t_e\} } m_{h \rightarrow f_{t_e}}(h) d\bm{x}_{\setminus \{t_e\} }  \\
%  & \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_p_ft}}}{=}} \int \dots \int \mathbb{I}(t_e = p_i + p_j) N(p_i|\mu_i,\beta^2 + \sigma_i^2)N(p_j|\mu_j,\beta^2 + \sigma_j^2) d\bm{x}_{\setminus \{t_e\} }\\[0.3cm]
%  & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \iint \mathbb{I}(t_e = p_i + p_j) N(p_i|\mu_i,\beta^2 + \sigma_i^2)N(p_j|\mu_j,\beta^2 + \sigma_j^2) dp_idp_j \\
%  & \overset{\hfrac{\text{eq}}{\ref{eq:integral_con_indicadora}}}{=} \int N(p_i|\mu_i,\beta^2 + \sigma_i^2) N(t_e - p_i|\mu_j,\beta^2 + \sigma_j^2) dp_i   \\
%  & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \int N(p_i|\mu_i,\beta^2 + \sigma_i^2) N(p_i|t_e - \mu_j,\beta^2 + \sigma_j^2) dp_i \\
%  & \overset{\hfrac{\text{eq}}{\ref{eq:multiplicacion_normales}}}{=} N(t_e|\mu_i+\mu_j,2\beta^2 + \sigma_i^2 + \sigma_j^2)
% \end{split}
% \end{equation}
% 
% \vspace{0.3cm}
% 
% General (por inducci\'on)
% \begin{equation}\label{eq:m_ft_t}
%  m_{f_{t_e} \rightarrow t_e}(t_e) =  N \Big( t_e | \underbrace{\sum_{i\in A_e } \mu_i}_{\hfrac{\text{Habilidad}}{\text{de equipo}} \ \mu_e}, \underbrace{\sum_{i \in A_e} \beta^2 + \sigma_i^2}_{\hfrac{\text{Varianza}}{\text{de equipo}} \ \sigma_e^2} \Big) = N(t_e | \mu_e, \sigma_e^2)
% \end{equation}
% 
% Ver anexo~\ref{suma_normales_induccion}, la secci\'on sobre suma de $n$ normales.
% 
% \paragraph{$\bm{m_{t \rightarrow f_d}(t)}:$}
% 
% \begin{equation}\label{eq:m_t_fd}
% \begin{split}
% m_{t_e \rightarrow f_{d_{k}}}(d_{k}) & \overset{\hfrac{\text{eq}}{\ref{eq:m_v_f}}}{=} \prod_{g \in n(t_e) \setminus  \{f_{d_{k}} \}} m_{g \rightarrow t_e} (t_e) \\[0.3cm]
%  & \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{=} m_{f_{t_e} \rightarrow t_e}(t_e) \overset{\hfrac{\text{eq}}{\ref{eq:m_ft_t}}}{=} N(t_e| \sum_{i \in A_e} \mu_i, \sum_{i \in A_e} \beta^2 + \sigma_i^2) \overset{\hfrac{\text{eq}}{\ref{eq:m_ft_t}}}{=} N(t_e|\mu_e,\sigma_e^2)
% \end{split}
% \end{equation}
% 
% \paragraph{$\bm{m_{f_d \rightarrow d}(d)}:$}
% 
% \begin{equation}
%  \begin{split}
%   m_{f_{d_1} \rightarrow d_1}(d_1) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{d_1}(\bm{x}) \prod_{h \in n(f_{d_1}) \setminus \{d_1\} } m_{h \rightarrow f_{d_1}}(h) \, d\bm{x}_{\setminus \{d_1\} }  \\
%   & \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_t_fd}}}{=}} \int \int \mathbb{I}(d_1 = t_a - t_b) N(t_a| \mu_a, \sigma_a^2)  N(t_b| \mu_b, \sigma_b^2)  dt_adt_b \\[0.25cm]
%   & \overset{\hfrac{\text{eq}}{\ref{eq:integral_con_indicadora}}}{=} \int N(d_1 + t_b| \mu_a, \sigma_a^2)  N(t_b| \mu_a, \sigma_b^2)  dt_b \\
%   & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \int N(t_b| \mu_a - d_1 , \sigma_a^2)  N(t_b| \mu_b, \sigma_b^2)  dt_b \\
%   & \overset{\hfrac{\text{eq}}{\ref{eq:multiplicacion_normales}}}{=} N( \mu_a - d_1 | \mu_b, \sigma_a^2 +\sigma_b^2  ) \\
%   & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} N( d_1 | \mu_a - \mu_b, \sigma_a^2 +\sigma_b^2  )
%  \end{split}
% \end{equation}
% 
% General
% 
% \begin{equation} \label{eq:m_fd_d}
%  m_{f_{d_1} \rightarrow d_1}(d_1) = N\Bigg(d_1 \ | \ \underbrace{\sum_{i \in A_a} \mu_i - \sum_{i \in A_b} \mu_i}_{\hfrac{\text{Diferencia}}{\text{esperada}} \, (\delta)} \ , \  \underbrace{\sum_{i \in A_a \cup A_b} \beta^2 + \sigma_i^2}_{\hfrac{\text{Varianza}}{\text{total}} \, (\vartheta) } \Bigg) = N(d_1 | \delta, \vartheta)
% \end{equation}
% 
% \paragraph{$\bm{m_{d \rightarrow f_r}(r)}:$}
% 
% \begin{equation}\label{eq:m_d_fr}
% \begin{split}
% m_{d \rightarrow f_r}(d) & \overset{\hfrac{\text{eq}}{\ref{eq:m_v_f}}}{=} \prod_{g \in n(t_e) \setminus  \{f_{d_{k}} \}} m_{g \rightarrow t_e} (t_e) \\[0.3cm]
%  & \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{=} m_{f_d \rightarrow d}(d) \overset{\hfrac{\text{eq}}{\ref{eq:m_fd_d}}}{=} N(d_1| \delta, \vartheta)
% \end{split}
% \end{equation}
% 
% \paragraph{$\bm{m_{f_r \rightarrow r}(r)}:$} (Caso ganador)
% 
% \begin{equation}\label{eq:m_fr_r}
% \begin{split}
%  m_{f_{r_1} \rightarrow r_1}(r_1) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{r_1}(\bm{x}) \prod_{h \in n(f_{r_1}) \setminus \{r_1\} } m_{h \rightarrow f_{r_1}}(h) \, d\bm{x}_{\setminus \{r_1\} }  \\[0.2cm]
%  & \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_d_fr}}}{=}} \int \mathbb{I}(d_1 > 0) N(d_1 | \delta, \vartheta)  dd_1 \\[0.2cm]
%  &  \overset{\hfrac{\text{eq}}{\ref{eq:estandarizar}}}{=} \int \mathbb{I}(d_1 > 0) N( \frac{d_1 - \delta}{\vartheta}) dd_1 \\[0.2cm]
%  & = 1 - \Phi(\frac{-\delta}{\vartheta}) \\
%  & = \Phi(\frac{\delta}{\vartheta})
% \end{split}
% \end{equation}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% \subsubsection{Mensajes ascendentes}
% 
% \paragraph{$\bm{m_{f_r \rightarrow d}(d)}:$}
% 
% \begin{equation}\label{eq:m_fr_d}
% \begin{split}
% m_{f_r \rightarrow d_1}(d_1) & \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=}} \mathbb{I}(d_1 > 0)
% \end{split}
% \end{equation}
% 
% 
% \paragraph{$\bm{m_{d \rightarrow f_d}(d)}:$}
% \begin{equation}\label{eq:m_d_fd}
% \begin{split}
% m_{d_1 \rightarrow f_{d_1}}(d_1) & \overset{\hfrac{\text{eq}}{\ref{eq:m_v_f}}}{=} \prod_{g \in n(d_1) \setminus  \{f_{d_1} \}} m_{g \rightarrow d_1} (d_1) \\[0.3cm]
%  & \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{=} m_{f_r \rightarrow d_1}(d_1) \overset{\hfrac{\text{eq}}{\ref{eq:m_fr_d}}}{=} \mathbb{I}(d_1 > 0)
% \end{split}
% \end{equation}
% 
% \paragraph{$\bm{m_{f_{d_1} \rightarrow t_a}(t_a)}:$} (Caso ganador)
% \begin{equation}\label{eq:m_fd_ta}
% \begin{split}
% m_{f_{d_1} \rightarrow t_a}(t_a) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{d_1}(\bm{x}) \prod_{h \in n(f_{d_1}) \setminus \{t_a\} } m_{h \rightarrow f_{d_1}}(h) \, d\bm{x}_{\setminus \{t_a\} }  \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_t_fd}}}{=}}  \int \dots \int \mathbb{I}(d_1 = t_a - t_b) \mathbb{I}(d_1 > 0) N(t_b | \mu_b , \sigma_b^2 )  \, d\bm{x}_{\setminus \{t_a\} } \\[0.1cm]
% & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \iint \mathbb{I}(d_1 = t_a - t_b) \mathbb{I}(d_1 > 0) N(t_b | \mu_b , \sigma_b^2 ) \, dd_1\,dt_b \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:integral_con_indicadora}}}{=} \int \mathbb{I}( t_a > t_b)  N(t_b | \mu_b , \sigma_b^2 ) \,dt_b  \\
% & \overset{\hfrac{\text{fig}}{\ref{fig:m_fd_t}}}{=} \Phi (t_a| \mu_b, \sigma_b^2)  \overset{\hfrac{\mu_b}{\sigma_b}}{=}  \Phi \Big(t_a| \sum_{i \in A_b} \mu_i , \sum_{i \in A_b} \beta^2 + \sigma_i^2 \Big)
% \end{split}
% \end{equation}
% 
% \paragraph{$\bm{m_{f_{d_1} \rightarrow t_b}(t_b)}:$} (Caso perdedor)
% \begin{equation}\label{eq:m_fd_tb}
% \begin{split}
% m_{f_{d_1} \rightarrow t_b}(t_b) &\overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{d_1}(\bm{x}) \prod_{h \in n(f_{d_1}) \setminus \{t_b\} } m_{h \rightarrow f_{d_1}}(h) \, d\bm{x}_{\setminus \{t_a\} }  \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_t_fd}}}{=}}  \int \dots \int \mathbb{I}(d_1 = t_a - t_b) \mathbb{I}(d_1 > 0) N(t_a | \mu_a , \sigma_a^2 )  \, d\bm{x}_{\setminus \{t_b\} } \\[0.1cm]
% &\overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \iint \mathbb{I}(d_1 = t_a - t_b) \mathbb{I}(d_1 > 0)  N(t_a | \mu_a , \sigma_a^2 )  \, dd_1\,dt_a \\
% &\overset{\hfrac{\text{eq}}{\ref{eq:integral_con_indicadora}}}{=} \int \mathbb{I}( t_a > t_b)   N(t_a | \mu_a , \sigma_a^2 ) \,dt_a \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:m_fd_t}}}{=} 1 - \Phi (t_b| \mu_a , \sigma_a^2 ) \overset{\hfrac{\mu_a}{\sigma_a}}{=} 1 - \Phi \Big(t_b| \sum_{i \in A_a} \mu_i , \sum_{i \in A_a} \beta^2 + \sigma_i^2 \Big)
% \end{split}
% \end{equation}
% 
% \begin{figure}[t!]
% \centering
%   \begin{subfigure}[t]{0.48\textwidth}
%   \includegraphics[width=\textwidth]{figures/m_d_ta.pdf}
%   \caption{$m_{f_{d_1} \rightarrow t_a}(t_a)$: (Caso ganador)}
%   \label{fig:m_fd_ta}
%   \end{subfigure}
%   \begin{subfigure}[t]{0.48\textwidth}
%   \includegraphics[width=\textwidth]{figures/m_d_tb.pdf}
%   \caption{$m_{f_{d_1} \rightarrow t_b}(t_b)$: (Caso perdedor)}
%   \label{fig:m_fd_tb}
%   \end{subfigure}
%   \caption{Notar que en el caso ganador, $t_a$ es un valor fijo que entra como par\'ametro en la funci\'on $m_{f_{d_1} \rightarrow t_a}(t_a)$. El caso perdedor es an\'alogo.}
%   \label{fig:m_fd_t}
% \end{figure}
% 
% \paragraph{$\bm{m_{t_a \rightarrow f_{t_a}}(t_a)}:$} (Caso ganador)
% 
% \begin{equation}\label{eq:m_ta_ft}
% \begin{split}
%  m_{t_a \rightarrow f_{t_a}}(t_a) \overset{\hfrac{\text{eq}}{\ref{eq:m_v_f}}}{=} \prod_{g \in n(t_a) \setminus  \{f_{t_a} \}} m_{g \rightarrow t_a} (t_a)  \overset{\hfrac{\text{eq}}{\ref{eq:m_fd_ta}}}{=} \Phi(t_a|\mu_b,\sigma_b^2) \overset{\hfrac{\mu_b}{\sigma_b}}{=} \Phi \Big(t_a| \sum_{i \in A_b} \mu_i , \sum_{i \in A_b} \beta^2 + \sigma_i^2 \Big)
% \end{split}
% \end{equation}
% 
% \paragraph{$\bm{m_{t_b \rightarrow f_{t_b}}(t_b)}:$} (Caso perdedor)
% \begin{equation}\label{eq:m_tb_ft}
% \begin{split}
%  m_{t_b \rightarrow f_{t_b}}(t_b) \overset{\hfrac{\text{eq}}{\ref{eq:m_v_f}}}{=} \prod_{g \in n(t_b) \setminus  \{f_{t_b} \}} m_{g \rightarrow t_b} (t_b)  \overset{\hfrac{\text{eq}}{\ref{eq:m_fd_tb}}}{=} 1- \Phi(t_b|\mu_a,\sigma_a^2) \overset{\hfrac{\mu_a}{\sigma_a}}{=} 1 - \Phi \Big(t_b| \sum_{i \in A_a} \mu_i , \sum_{i \in A_a} \beta^2 + \sigma_i^2 \Big)
% \end{split}
% \end{equation}
% 
% 
% 
% \paragraph{$\bm{m_{f_{t_a} \rightarrow p_1}(p_1)}:$} (Caso ganador)
% \begin{equation}\label{eq:m_fta_p_inicial}
% \begin{split}
% m_{f_{t_a} \rightarrow p_1}(p_1)  &\overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{t_a}(\bm{x}) \prod_{h \in n(f_{t_a}) \setminus \{p_1\} } m_{h \rightarrow f_{t_a}}(h) \, d\bm{x}_{\setminus \{p_1\} }  \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_ta_ft}}}{=}} \int \dots \int \mathbb{I}( t_a = p_1 + p_2) N(p_2| \mu_2, \beta^2 + \sigma_2^2 ) \, \Phi (t_a| \mu_b , \sigma_b^2 ) \, d\bm{x}_{\setminus \{p_1\} }\\[0.1cm]
% &\overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \iint \mathbb{I}( t_a = p_1 + p_2) \, N(p_2| \mu_2, \beta^2 + \sigma_2^2 ) \, \Phi (t_a| \mu_b , \sigma_b^2 ) \, dt_a dp_2 \\
% &\overset{\hfrac{\text{eq}}{\ref{eq:integral_con_indicadora}}}{=} \int  \, N(p_2| \mu_2, \beta^2 + \sigma_2^2 ) \, \Phi (p_1 + p_2| \mu_b , \sigma_b^2 ) \, dp_2 \\
% &\overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \int  N(p_2| \mu_2, \beta^2 + \sigma_2^2 ) \, \Phi (p_1 | \mu_b - p_2 , \sigma_b^2) \, dp_2 \\
% &= \kappa(p_1)
% \end{split}
% \end{equation}
% 
% La derivada de la funci\'on de distribuci\'on acumulada $\Phi(\,)$ es el valor de la densidad de la funci\'on de probabilidad $N(\,)$. Con esta idea en mente, tomamos la derivada de ambos lados de la igualdad:
% 
% \begin{equation}\label{eq:ta-p_derivada}
% \begin{split}
% \frac{\partial\kappa(x)}{\partial x} &= \frac{\partial}{\partial x} \int  N(y| \mu_y, \sigma_y^2 ) \,   \Phi (x | \mu_x -y , \sigma_x^2 ) \, dy \\
% &= \int  N(y| \mu_y, \sigma_y^2 ) \, \frac{\partial}{\partial x} \,\Phi (x| \mu_x - y, \sigma_x^2 )  \, dy   \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:phi_norm}}}{=} \int  N(y| \mu_y, \sigma_y^2 ) \, N(x| \mu_x -y , \sigma_x^2)  \, dy  \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \int  N(y| \mu_y, \sigma_y^2 ) \, N(y| \mu_x  -x , \sigma_x^2)  \, dy  \\
% &\overset{\hfrac{\text{eq}}{\ref{eq:multiplicacion_normales}}}{\underset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=}} N(x| \mu_x - \mu_y, \sigma_x^2 + \sigma_y^2)
% \end{split}
% \end{equation}
% 
% Luego
% 
% \begin{equation}\label{eq:m_fta_p}
%  m_{f_{t_a} \rightarrow p_1}(p_1) \overset{\hfrac{\text{eq}}{\ref{eq:m_fta_p_inicial}}}{\underset{\hfrac{\text{eq}}{\ref{eq:ta-p_derivada}}}{=}}  \Phi(p_1| \mu_b - \mu_2, \beta^2 + \sigma_2^2 + \sigma_b^2)  \overset{\hfrac{\mu_b}{\sigma_b}}{=}  \Phi\Big(p_1| \sum_{i \in A_b} \mu_i - \mu_2, \beta^2 + \sigma_2^2 + \sum_{i \in A_b} \beta^2 + \sigma_i^2 \Big)
% \end{equation}
% 
% \paragraph{$\bm{m_{f_{t_b} \rightarrow p_3}(p_3)}:$} (Caso perdedor)
% \begin{equation}\label{eq:m_ftb_p}
% \begin{split}
% m_{f_{t_b} \rightarrow p_3}(p_3)&\overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{t_a}(\bm{x}) \prod_{h \in n(f_{t_a}) \setminus \{p_1\} } m_{h \rightarrow f_{t_a}}(h) \, d\bm{x}_{\setminus \{p_1\} }  \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_tb_ft}}}{=}} \int \dots \int \mathbb{I}( t_b = p_3 + p_4) \, (1-\Phi (t_b| \mu_a , \sigma_a^2 )) \, N(p_4| \mu_4, \beta^2 + \sigma_4^2 ) \, d\bm{x}_{\setminus \{p_3\} }\\[0.1cm]
% &\overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \iint \mathbb{I}( t_b = p_3 + p_4) N(p_4| \mu_4, \beta^2 + \sigma_4^2 )  (1 - \Phi (t_b| \mu_a , \sigma_a^2) )\, dt_b dp_4 \\
% &\overset{\hfrac{\text{eq}}{\ref{eq:integral_con_indicadora}}}{\underset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=}} \int N(p_4| \mu_4, \beta^2 + \sigma_4^2 )  (1 - \Phi (p_3 | \mu_a - p_4 , \sigma_a^2 ) ) \,  dp_4 \\
% & =  \underbrace{\int N(p_4| \mu_4, \beta^2 + \sigma_4^2 )dp_4}_{1}  -  \underbrace{\int N(p_4| \mu_4, \beta^2 + \sigma_4^2 ) \Phi (p_3 | \mu_a - p_4 , \sigma_a^2 ) ) \, dp_4}_{\kappa(p_3)} \\
% &\overset{\hfrac{\text{eq}}{\ref{eq:ta-p_derivada}}}{=} 1 - \Phi(p_3, \mu_a  - \mu_4, \beta^2 + \sigma_4^2 + \sigma_a^2)\\[0.1cm]
% &\overset{\hfrac{\mu_a}{\sigma_a}}{=} 1 - \Phi\Big(p_3, \sum_{i \in A_a} \mu_i  - \mu_4, \beta^2 + \sigma_4^2 + \sum_{i \in A_a} \beta^2 + \sigma_i^2  \Big)
% \end{split}
% \end{equation}
% 
% \paragraph{$\bm{m_{p_1 \rightarrow f_{p_1}}(s_1)}:$} (Caso ganador)
% 
% \begin{equation}\label{eq:m_p1_fp}
% \begin{split}
%  m_{p_1 \rightarrow f_{p_1}}(p_1) \overset{\hfrac{\text{eq}}{\ref{eq:m_v_f}}}{=} \prod_{g \in n(p_1) \setminus  \{f_{p_1} \}} m_{g \rightarrow p_1} (p_1)  \overset{\hfrac{\text{eq}}{\ref{eq:m_fta_p}}}{=}  \Phi(p_1| \mu_b - \mu_2, \beta^2 + \sigma_2^2 + \sigma_b^2)
% \end{split}
% \end{equation}
% 
% 
% \paragraph{$\bm{m_{p_3 \rightarrow f_{p_3}}(s_1)}:$} (Caso perdedor)
% 
% \begin{equation}\label{eq:m_p3_fp}
% \begin{split}
%  m_{p_3 \rightarrow f_{p_3}}(p_3) \overset{\hfrac{\text{eq}}{\ref{eq:m_v_f}}}{=} \prod_{g \in n(p_3) \setminus  \{f_{p_3} \}} m_{g \rightarrow p_3} (p_3)  \overset{\hfrac{\text{eq}}{\ref{eq:m_ftb_p}}}{=}  1 - \Phi(p_3, \mu_a  - \mu_4, \beta^2 + \sigma_4^2 + \sigma_a^2)
% \end{split}
% \end{equation}
% 
% \paragraph{$\bm{m_{f_{p_1} \rightarrow s_1}(s_1)}:$} (Caso ganador)
% \begin{equation}\label{eq:m_fp_s1}
% \begin{split}
% m_{f_{p_1} \rightarrow s_1}(s_1) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{p_1}(\bm{x}) \prod_{h \in n(f_{p_1}) \setminus \{s_1\} } m_{h \rightarrow f_{p_1}}(h) \, d\bm{x}_{\setminus \{s_1\} }  \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_p1_fp}}}{=}} \int \dots \int N(p_1| s_1, \beta^2) \, \Phi(p_1| \mu_b - \mu_2, \beta^2 + \sigma_2^2 + \sigma_b^2 ) \, d\bm{x}_{\setminus \{s_1\} }
% \\[0.1cm]
% & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{\underset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=}} \int N(p_1| s_1, \beta^2) \, \Phi(\mu_2| \mu_b -  p_1, \beta^2 + \sigma_2^2 + \sigma_b^2) \, dp_1 \\[0.1cm]
% &\overset{\hfrac{\text{eq}}{\ref{eq:ta-p_derivada}}}{=} \Phi(s_1| \mu_b - \mu_2, 2\beta^2 + \sigma_2^2 + \sigma_b^2)
% \end{split}
% \end{equation}
% 
% General (N vs N)
% \begin{equation}\label{eq:m_fp_s1_gral}
% \begin{split}
% m_{f_{p_1} \rightarrow s_1}(s_1) & \overset{\hfrac{\text{eq}}{\ref{eq:m_fp_s1}}}{=} \Phi(s_1| \mu_b - \mu_a + \mu_1, \sigma_b^2 +\sigma_a^2 - \sigma_1^2 )  \\
% & \overset{\hfrac{\mu_b}{\sigma_b}}{=} \Phi\Big(s_1| \underbrace{\sum_{i \in A_b} \mu_i - \sum_{i \in A_a} \mu_i }_{-\hfrac{\text{Diferencia}}{\text{esperada}} \, -\delta = \delta } + \mu_1 , \underbrace{\sum_{i \in A_b \cup A_a} \beta^2 + \sigma_i^2}_{\hfrac{\text{Varianza}}{\text{total}} \, \vartheta^2} - \sigma_1^2   \Big) \\
% & \overset{\hfrac{\delta}{\vartheta}}{=} \Phi(s_1|-\delta + \mu_1,\vartheta^2-\sigma_1^2) \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} 1- \Phi(0| \underbrace{\delta - \mu_1 + s_1}_{\hfrac{\text{Diferencia esperada}}{\text{parametrizada}} \, \delta_1(s_1)},\underbrace{\vartheta^2-\sigma_1^2}_{\vartheta_1^2}) \\
% & \overset{\hfrac{\delta_1}{\vartheta_1}}{=} 1- \Phi(0|\delta_1(s_1),\vartheta_1^2) \\
% &\overset{\hfrac{\text{eq}}{\ref{eq:estandarizar}}}{=} 1- \Phi\Big(\frac{0-\delta_1(s_1)}{\vartheta_1}\Big)\\
% &\overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \Phi\Big(\frac{\delta_1(s_1)}{\vartheta_1}\Big)
% \end{split}
% \end{equation}
% 
% \textbf{Nota}: el mensaje $m_{f_{p_1} \rightarrow s_1}(s_1)$ computa la ``probabilidad de ganar parametrizada'', esto es la probabilidad de ganar si conoci\'eramos la habilidad del jugador. Si conocemos la habilidad del jugador entonces hay que eliminar la varianza de la distribuci\'on de creencias de la varianza total (lo que hacemos en $\vartheta_1$) y hay que remplazar la media de la distribuci\'on de creencias por la verdadera habilidad en la diferencia esperada (lo que hacemos en $\delta_1(s_1)$).
% 
% \paragraph{$\bm{m_{f_{p_3} \rightarrow s_3}(s_3)}:$}
% 
% \begin{equation}\label{eq:m_fp_s3}
% \begin{split}
% m_{f_{p_3} \rightarrow s_3}(s_3) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{p_3}(\bm{x}) \prod_{h \in n(f_{p_3}) \setminus \{s_3\} } m_{h \rightarrow f_{p_3}}(h) \, d\bm{x}_{\setminus \{s_3\} }  \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_p3_fp}}}{=}} \int \dots \int N(p_3| s_3, \beta^2) (1 - \Phi(p_3, \mu_a  - \mu_4, \beta^2 + \sigma_4^2 + \sigma_a^2)) \, d\bm{x}_{\setminus \{s_3\} }\\
% & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{\underset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=}} \int N(p_3| s_3, \beta^2) (1 - \Phi(\mu_4, \mu_a  - p_3, \beta^2 + \sigma_4^2 + \sigma_a^2)) \, dp_3 \\
% &=\int N(p_3| s_3, \beta^2) \, dp_3 -  \int N(p_3| s_3, \beta^2)  \Phi(\mu_4, \mu_a  - p_3, \beta^2 + \sigma_4^2 + \sigma_a^2) \, dp_3 \\
% &\overset{\hfrac{\text{eq}}{\ref{eq:ta-p_derivada}}}{=} 1 - \Phi\Big(s_3| \mu_a-  \mu_4, 2\beta^2 + \sigma_4^2 + \sigma_a^2 \Big)
% \end{split}
% \end{equation}
% 
% General (N vs N)
% 
% \begin{equation}
% \begin{split}
% m_{f_{p_3} \rightarrow s_3}(s_3) & \overset{\hfrac{\text{eq}}{\ref{eq:m_fp_s3}}}{=} 1 - \Phi\Big(s_3| \underbrace{\mu_a-\mu_b}_{\delta}+\mu_3, \underbrace{\sigma_a^2 + \sigma_b^2}_{\vartheta^2} - \sigma_3^2 \Big) \\
% & \overset{\hfrac{\delta}{\vartheta}}{=} 1 - \Phi\Big(s_3| \delta +\mu_3, \vartheta^2- \sigma_3^2 \Big) \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \Phi\Big(0| \underbrace{-\delta-\mu_3+s_3}_{\delta_3(s_3)}, \underbrace{\vartheta^2- \sigma_3^2}_{\vartheta_3^2} \Big) \\
% & \overset{\hfrac{\delta_3}{\vartheta_3}}{=} \Phi(0|\delta_3(s_3),\vartheta_3^2)  \overset{\hfrac{\text{eq}}{\ref{eq:estandarizar}}}{=}  \Phi\left(\frac{0-\delta_3(s_3)}{\vartheta_3}\right) \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \Phi\Big(\frac{-\delta_3(s_3)}{\vartheta_3}\Big)
% \end{split}
% \end{equation}
% 
% \textbf{Nota}: el mensaje $m_{f_{p_3} \rightarrow s_3}(s_3)$ computa la ``probabilidad de perder parametrizada'' (que es la misma que la probabilidad de ganar de su contrincante). Si conoci\'eramos la habilidad del jugador entonces hay que eliminar la varianza de la distribuci\'on de creencias de la varianza total (lo que hacemos en $\vartheta_3$) y hay que remplazar la media de la distribuci\'on de creencias por la verdadera habilidad en la diferencia esperada (lo que hacemos en $\delta_3(s_3)$).
% 
% \subsubsection{Posterior ganador y perdedor}
% \paragraph{Ganador}
% \begin{equation}\label{eq:posterior_ganador}
%  p(s_1|o,A) \overset{\hfrac{\text{eq}}{\ref{eq:marginal}}}{=} \prod_{h \in n(x_i)} m_{h \rightarrow x_i} \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_fp_s1_gral}}}{=}}  N(s_1| \mu_1, \sigma_1^2)  \Phi\left(\frac{\delta_1(s_1)}{\vartheta_1}\right)
% \end{equation}
% 
% 
% \begin{figure}[t!]
% \centering
%   \begin{subfigure}[t]{0.48\textwidth}
%   \includegraphics[page=1,width=\textwidth]{figures/posterior_ganador.pdf}
%   \caption{}
%   \label{posterior_ganador_image}
%   \end{subfigure}
%   \begin{subfigure}[t]{0.48\textwidth}
%   \includegraphics[page=2,width=\textwidth]{figures/posterior_ganador.pdf}
%   \caption{}
%   \label{posterior_ganador_distribution}
%   \end{subfigure}
%   \caption{Posterior ganador}
%   \label{posterior_ganador}
% \end{figure}
% 
% \paragraph{Perdedor}
% 
% \begin{equation}\label{eq:posterior_perdedor}
%  p(s_1|o,A) \overset{\hfrac{\text{eq}}{\ref{eq:marginal}}}{=} \prod_{h \in n(x_i)} m_{h \rightarrow x_i} \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_fp_s1_gral}}}{=}}  N(s_1| \mu_1, \sigma_1^2)  \Phi\left(\frac{-\delta_1(s_1)}{\vartheta_1}\right)
% \end{equation}
% 
% 
% \begin{figure}[t!]
% \centering
%   \begin{subfigure}[t]{0.48\textwidth}
%   \includegraphics[page=1,width=\textwidth]{figures/posterior_perdedor.pdf}
%   \caption{}
%   \label{posterior_perdedor_image}
%   \end{subfigure}
%   \begin{subfigure}[t]{0.48\textwidth}
%   \includegraphics[page=2,width=\textwidth]{figures/posterior_perdedor.pdf}
%   \caption{}
%   \label{posterior_perdedor_distribution}
%   \end{subfigure}
%   \caption{Posterior perdedor}
%   \label{posterior_perdedor}
% \end{figure}
% 
%  \begin{figure}[t!]
% \centering
%   \begin{subfigure}[t]{0.48\textwidth}
%   \includegraphics[page=1,width=\textwidth]{figures/evidence_win.pdf}
%   \caption{Evidence}
%   \label{fig:evidence_win}
%   \end{subfigure}
%   \begin{subfigure}[t]{0.48\textwidth}
%   \caption{Prior predictive}
%   \label{fig:prior_predictive_win}
%   \end{subfigure}
%   \caption{The Evidence and the Prior predictive are the same object, so they have the same area under the curve}
%   \label{fig:evidence_prior_predictive}
% \end{figure}
% 
%  Caso ganador
% 
%  \begin{equation}\label{eq:prior_predictive}
%   P(r=\text{win}) = \prod_{h \in n(r)} m_{h \rightarrow r}  = m_{f_r \rightarrow r}(r) =  \Phi(\frac{\delta_1}{\vartheta_1})
%  \end{equation}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
%  \subsection{Aproximacion de la posterior (DRAFT)}
% 
% La probabilidad de una diferencia cuando se conoce el resultado (Eq.~\ref{eq:p_d}) es una Normal truncada.
% %
% \begin{equation}\label{eq:p_d}
% \begin{split}
%  P(d_1) & \overset{\hfrac{\text{eq}}{\ref{eq:marginal}}}{=}   \prod_{h \in n(d_1)} m_{h \rightarrow d_1} \overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{=} m_{f_{d_1} \rightarrow d_1}(d_1) \, m_{f_r \rightarrow d_1}(d_1) \overset{\hfrac{\text{eq}}{\ref{eq:m_fr_d}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_d_fd}}}{=}}  m_{f_{d_1} \rightarrow d_1}(d_1) \, m_{d_1 \rightarrow f_{d_1}}(d_1)  \\
%  & = N(d_1|\delta,\vartheta) \mathbb{I}(d_1 > 0)
% \end{split}
% \end{equation}
% %
% Para tener una posterior normal lo que se hace es un buscar la normal que m\'as se aproxima a esta normal truncada
% 
% \vspace{0.3cm}
% 
% Se sabe que la Normal que mejor aproxima a una Normal truncada tiene como esperanza
% 
% \begin{equation}\label{eq:mean_aprox_double}
%  E(X| a < X < b) = \mu + \sigma \frac{N(\frac{a-\mu}{\sigma}) - N(\frac{b-\mu}{\sigma}) }{\Phi(\frac{b-\mu}{\sigma}) - \Phi(\frac{a-\mu}{\sigma}) } = \mu + \sigma \frac{N(\alpha) - N(\beta) }{\Phi(\beta) - \Phi(\alpha) }
% \end{equation}
% 
% done $\beta = \frac{b-\mu}{\sigma}$ y $\alpha = \frac{a-\mu}{\sigma}$.
% 
% Y la varianza
% 
% \begin{equation}\label{eq:variance_aprox_double}
%  V(X| a < X < b) = \sigma^2 \Bigg( 1 + \bigg(\frac{\alpha N(\alpha) - \beta N(\beta) }{\Phi(\beta) - \Phi(\alpha) }\bigg) - \bigg(\frac{N(\alpha) - N(\beta) }{\Phi(\beta) - \Phi(\alpha) }\bigg)^2 \Bigg)
% \end{equation}
% 
% Usando  \'unico truncamiento estas funciones se pueden simplificar como sigue
% 
% \begin{equation}\label{eq:mean_aprox_}
% \begin{split}
%  E(X|  X > a)  & \overset{\hfrac{\text{eq}}{\ref{eq:mean_aprox_double}}}{=}  \mu + \sigma \frac{N(\alpha)}{1 - \Phi(\alpha) } = \mu + \sigma \frac{N(\frac{a-\mu}{\sigma})}{1 - \Phi(\frac{a-\mu}{\sigma}) }\\
%  & = \mu + \sigma \underbrace{\frac{N(\frac{\mu-a}{\sigma})}{\Phi(\frac{\mu-a}{\sigma}) }}_{\text{\small $V_1(t)$} } = \mu + \sigma V_1(t)
%  \end{split}
% \end{equation}
% 
% con $t = \frac{\mu -a}{\sigma} = -\alpha  $
% 
% \begin{equation}\label{eq:variance_aprox_}
% \begin{split}
%  V(X|  X > a) & \overset{\hfrac{\text{eq}}{\ref{eq:variance_aprox_double}}}{=} \sigma^2 \Bigg( 1 + \bigg(\frac{\alpha N(\alpha)}{1 - \Phi(\alpha) }\bigg) - \bigg(\frac{N(\alpha)}{1 - \Phi(\alpha) }\bigg)^2 \Bigg) \\
%  & = \sigma^2 \Bigg( 1 + \bigg(\frac{\alpha N(-\alpha)}{\Phi(-\alpha) }\bigg) - \bigg(\frac{N(-\alpha)}{\Phi(-\alpha) }\bigg)^2 \Bigg) \\
%  & = \sigma^2 \Bigg( 1 + \bigg(\frac{-t N(t)}{\Phi(t) }\bigg) - \bigg(\frac{N(t)}{\Phi(t) }\bigg)^2 \Bigg) \\
%  & = \sigma^2 \Big( 1 +  -t V_1(t) - V_1(t)^2 \Big) \\
%  & = \sigma^2 \Big( 1 + V_1(t) \big(-t  - V_1(t)\big) \Big)  \\
%  & = \sigma^2 \Big( 1 - \underbrace{V_1(t) \big(V_1(t) + t \big)}_{W_1(t)} \Big)  = \sigma^2 \big( 1 - W_1(t) \big)
%  \end{split}
% \end{equation}
% 
% Luego, la normal aproximada es
% 
% \begin{equation}\label{eq:p*_d}
%  \widehat{P}(d_1) \overset{\hfrac{\text{eq}}{\ref{eq:mean_aprox_}}}{\underset{\hfrac{\text{eq}}{\ref{eq:variance_aprox_}}}{=}} N\Bigg(d1 \,  \bigg| \, \underbrace{ \delta + \vartheta \, V_1(t) \,}_{\hfrac{\text{\scriptsize Media}}{\text{\scriptsize aproximada}} \, \text{\small $\widehat{\delta}$}} , \,  \underbrace{ \vartheta^2 \big( 1 - W_1(t) \big) }_{\hfrac{\text{\scriptsize Varianza}}{\text{\scriptsize aproximada}} \,\text{\small $\widehat{\vartheta}^{\,2}$}} \, \Bigg)
% \end{equation}
% 
% donde, en caso de que no se contemple el empate, $\alpha=\frac{-\delta_1}{\vartheta_1}$.
% 
% Teniendo la normal aproximada $\widehat{P}(d_1)$ podemos calcular el mensaje ascendentes aproximado
% 
% \paragraph{$\bm{\widehat{m}_{d \rightarrow f_{d}}(d)}$}
% 
% \begin{equation}\label{eq:m^_d_fd}
% \begin{split}
%  m_{d_1 \rightarrow f_{d_1}}(d_1) &\overset{\hfrac{\text{eq}}{\ref{eq:p_d}}}{=} \frac{P(d_1)}{m_{f_{d_1} \rightarrow d_1}(d_1)} \\
%  &\overset{\hfrac{\text{eq}}{\ref{eq:mean_aprox_}}}{\underset{\hfrac{\text{eq}}{\ref{eq:variance_aprox_}}}{\approx}} \frac{\widehat{P}(d_1)}{m_{f_{d_1} \rightarrow d_1}(d_1)} \\
%  & \overset{\hfrac{\text{eq}}{\ref{eq:p*_d}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m_fd_d}}}{=}}  \frac{N(d_1 \,  | \,\widehat{\delta} , \, \widehat{\vartheta}^{\,2} )}{N(d_1 | \delta, \vartheta^2)} \\
%  &\overset{\hfrac{\text{sec}}{\ref{sec:division_normales}}}{\propto} N(d_1,\delta_{\div},\vartheta_{\div}^2 )
% \end{split}
% \end{equation}
% 
% \begin{equation}
%  \vartheta_{\div} = \sqrt{\frac{\widehat{\vartheta}^{\,2}\vartheta^2}{(\vartheta^2 - \widehat{\vartheta}^{\,2})}}
% \end{equation}
% 
% \begin{equation}
%  \delta_{\div} = \frac{(\vartheta^2\widehat{\delta} - \widehat{\vartheta}^{\,2}\delta)}{(\vartheta^2 - \widehat{\vartheta}^{\,2})}
% \end{equation}
% 
% \paragraph{$\bm{\widehat{m}_{f_d \rightarrow f_{t_a}}(t_a)}$} (Caso ganador)
% 
% \begin{equation}\label{eq:^m_fd_ta}
% \begin{split}
% m_{f_{d_1} \rightarrow t_a}(t_a) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{d_1}(\bm{x}) \prod_{h \in n(f_{d_1}) \setminus \{t_a\} } m_{h \rightarrow f_{d_1}}(h) \, d\bm{x}_{\setminus \{t_a\} }  \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m^_d_fd}}}{\approx}}  \int \dots \int \mathbb{I}(d_1 = t_a - t_b) N(d_1 | \delta_{\div}, \vartheta_{\div}^2) N(t_b | \mu_b , \sigma_b^2 )  \, d\bm{x}_{\setminus \{t_a\} } \\[0.1cm]
% \widehat{m}_{f_{d_1} \rightarrow t_a}(t_a)  & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \int \mathbb{I}(d_1 = t_a - t_b) N(d_1 | \delta_{\div}, \vartheta_{\div}^2) N(t_b | \mu_b , \sigma_b^2 )  \, d{d_1} d_{t_b} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:integral_con_indicadora}}}{=} \int  N(t_a - t_b | \delta_{\div}, \vartheta_{\div}^2) N(t_b | \mu_b , \sigma_b^2 )  \, d_{t_b} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \int  N( - t_b | \delta_{\div} - t_a, \vartheta_{\div}^2) N(t_b | \mu_b , \sigma_b^2 )  \, d_{t_b} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \int  N( t_b | t_a - \delta_{\div}, \vartheta_{\div}^2) N(t_b | \mu_b , \sigma_b^2 )  \,  d_{t_b} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:multiplicacion_normales}}}{=} N(t_a - \delta_{\div} \, | \, \mu_b \, , \, \vartheta_{\div}^2 + \sigma_b^2) \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} N(t_a \, | \, \mu_b + \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_b^2) \\
% \end{split}
% \end{equation}
% 
% 
% \paragraph{$\bm{\widehat{m}_{f_d \rightarrow f_{t_b}}(t_b)}$} (Caso perdedor)
% 
% \begin{equation}\label{eq:^m_fd_tb}
% \begin{split}
% m_{f_{d_1} \rightarrow t_b}(t_b) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{d_1}(\bm{x}) \prod_{h \in n(f_{d_1}) \setminus \{t_b\} } m_{h \rightarrow f_{d_1}}(h) \, d\bm{x}_{\setminus \{t_b\} }  \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:m^_d_fd}}}{\approx}}  \int \dots \int \mathbb{I}(d_1 = t_a - t_b) N(d_1 | \delta_{\div}, \vartheta_{\div}^2) N(t_a | \mu_a , \sigma_a^2 )  \, d\bm{x}_{\setminus \{t_a\} } \\[0.1cm]
% \widehat{m}_{f_{d_1} \rightarrow t_b}(t_b)  & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \int \mathbb{I}(d_1 = t_a - t_b) N(d_1 | \delta_{\div}, \vartheta_{\div}^2) N(t_a | \mu_a , \sigma_a^2 )  \, d{d_1} d_{t_a} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:integral_con_indicadora}}}{=} \int  N(t_a - t_b | \delta_{\div}, \vartheta_{\div}^2) N(t_a | \mu_a , \sigma_a^2 )  \, d_{t_a} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \int  N( t_a | \delta_{\div} + t_b, \vartheta_{\div}^2) N(t_a | \mu_a , \sigma_a^2 )  \, d_{t_a} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:multiplicacion_normales}}}{=} N(t_b + \delta_{\div} \, | \, \mu_a \, , \, \vartheta_{\div}^2 + \sigma_a^2) \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} N(t_b \, | \, \mu_a - \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_a^2) \\
% \end{split}
% \end{equation}
% 
% \paragraph{$\bm{\widehat{m}_{f_{t_a} \rightarrow p_1}(p_1)}$} (Caso ganador)
% 
% \begin{equation}\label{eq:^m_fta_p}
% \begin{split}
% m_{f_{t_a} \rightarrow p_1}(p_1) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{t_a}(\bm{x}) \prod_{h \in n(f_{t_a}) \setminus \{p_1\} } m_{h \rightarrow f_{t_a}}(h) \, d\bm{x}_{\setminus \{p_1\} }  \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:^m_fd_ta}}}{\approx}}  \int \dots \int \mathbb{I}(t_a = p_1 + p_2) N(t_a \, | \, \mu_b + \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_b^2) N(p_2 | \mu_2 , \sigma_2^2 + \beta^2)  \, d\bm{x}_{\setminus \{p_1\} } \\[0.1cm]
% \widehat{m}_{f_{t_a} \rightarrow p_1}(p_1)  & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \int \mathbb{I}(t_a = p_1 + p_2) N(t_a \, | \, \mu_b + \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_b^2) N(p_2 | \mu_2 , \sigma_2^2 + \beta^2)  \, d{t_a} d_{p_2} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:integral_con_indicadora}}}{=} \int N(p_1 + p_2 \, | \, \mu_b + \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_b^2) N(p_2 | \mu_2 , \sigma_2^2+ \beta^2 )   \, d_{p_2} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=}\int N(p_2 \, | \, \mu_b - p_1 + \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_b^2) N(p_2 | \mu_2 , \sigma_2^2 + \beta^2)   \, d_{p_2} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:multiplicacion_normales}}}{=} N(\mu_b - p_1 + \delta_{\div} \,|\, \mu_2 \,,\,\vartheta_{\div}^2 + \sigma_b^2 + \sigma_2^2 + \beta^2)   \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=}  N( p_1 \,|\,  (\mu_b - \mu_2) + \delta_{\div}  \,,\,\vartheta_{\div}^2 + \sigma_b^2 + \sigma_2^2 + \beta^2)  \\
% \end{split}
% \end{equation}
% 
% 
% En general
% \begin{equation}
% \begin{split}
% \widehat{m}_{f_{t_a} \rightarrow p_1}(p_1) &= N( p_1 \,|\, (\mu_b  - \sum_{i \in A_a, i\neq1} \mu_i) + \delta_{\div}  \,,\,\vartheta_{\div}^2 + \sigma_b^2 + \sum_{i \in A_a, i\neq1} \sigma_i^2 + \beta^2 ) \\
%  & = N( p_1 \,|\, (-\delta + \mu_1) + \delta_{\div}  \,,\,\vartheta_{\div}^2 + (\vartheta^2 - \sigma_1^2 - \beta^2))
% \end{split}
% \end{equation}
% 
% 
% \paragraph{$\bm{\widehat{m}_{f_{t_b} \rightarrow p_3}(p_3)}$} (Caso perdedor)
% 
% \begin{equation}\label{eq:^m_ftb_p}
% \begin{split}
% m_{f_{t_b} \rightarrow p_3}(p_3) & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \dots \int f_{t_b}(\bm{x}) \prod_{h \in n(f_{t_b}) \setminus \{p_3\} } m_{h \rightarrow f_{t_b}}(h) \, d\bm{x}_{\setminus \{p_3\} }  \\
% &\overset{\hfrac{\text{fig}}{\ref{fig:modelo_trueskill_2vs2}}}{\underset{\hfrac{\text{eq}}{\ref{eq:^m_fd_tb}}}{\approx}}  \int \dots \int \mathbb{I}(t_b = p_3 + p_4) N(t_b \, | \, \mu_a - \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_a^2) N(p_4 | \mu_4 , \sigma_4^2 + \beta^2)  \, d\bm{x}_{\setminus \{p_3\} } \\[0.1cm]
% \widehat{m}_{f_{t_b} \rightarrow p_3}(p_3)  & \overset{\hfrac{\text{eq}}{\ref{eq:m_f_v}}}{=} \int \int \mathbb{I}(t_b = p_3 + p_4) N(t_b \, | \, \mu_a - \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_a^2) N(p_4 | \mu_4 , \sigma_4^2 + \beta^2) \, d{t_b} d_{p_4} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:integral_con_indicadora}}}{=} \int N(p_3 + p_4 \, | \, \mu_a - \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_a^2) N(p_4 | \mu_4 , \sigma_4^2 + \beta^2) \, d_{p_4} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=} \int N(p_4 \, | \, \mu_a - \delta_{\div} - p_3 \, , \, \vartheta_{\div}^2 + \sigma_a^2) N(p_4 | \mu_4 , \sigma_4^2 + \beta^2) \, d_{p_4} \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:multiplicacion_normales}}}{=} N(\mu_a - \delta_{\div} - p_3  \,|\, \mu_4 \, , \, \vartheta_{\div}^2 + \sigma_a^2 + \sigma_4^2 + \beta^2)   \\
% & \overset{\hfrac{\text{eq}}{\ref{eq:simetria}}}{=}   N(  p_3  \,|\, (\mu_a - \mu_4)  - \delta_{\div} \, , \, \vartheta_{\div}^2 + \sigma_a^2 + \sigma_4^2 + \beta^2)  \\
% \end{split}
% \end{equation}
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% 
% \section{Propiedades de las funciones de densidad Normales}
% 
% \subsection{Multiplicacion de normales}\label{multiplicacion_normales}
% 
% Luego, el problema que tenemos que resolver es
% \begin{equation}
%  \int N(x;\mu_1,\sigma_1^2)N(x;\mu_2,\sigma_2^2) dx
% \end{equation}
% 
% Por defnici\'on,
% \begin{equation}
% \begin{split}
%  N(x;y,\beta^2)N(x;\mu,\sigma^2) & = \frac{1}{\sqrt{2\pi}\sigma_1}e^{-\frac{(x-\mu_1)^2}{2\sigma_1^2}} \frac{1}{\sqrt{2\pi}\sigma_2}e^{-\frac{(x-\mu_2)^2}{2\sigma_2^2}}  \\
%  & = \frac{1}{2\pi\sigma_1\sigma_2}\text{exp}\Bigg(-\underbrace{\left( \frac{(x-\mu_1)^2}{2\sigma_1^2} + \frac{(x-\mu_2)^2}{2\sigma_2^2} \right)}_{\theta} \Bigg)
% \end{split}
% \end{equation}
% 
% Luego,
% \begin{equation}
%  \theta = \frac{\sigma_2^2(x^2 + \mu_1^2 - 2x\mu_1) + \sigma_1^2(x^2 + \mu_2^2 - 2x\mu_2) }{2\sigma_1^2\sigma_2^2}
% \end{equation}
% 
% Expando y reordeno los factores por potencias de $x$
% \begin{equation}
%  \frac{(\sigma_1^2 + \sigma_2^2) x^2 - (2\mu_1\sigma_2^2 + 2\mu_2\sigma_1^2) x + (\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2)}{2\sigma_1^2\sigma_2^2}
% \end{equation}
% 
% Divido al numerador y el denominador por el factor de $x^2$
% \begin{equation}
%  \frac{x^2 - 2\frac{(\mu_1\sigma_2^2 + \mu_2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) } x + \frac{(\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) }}{2\frac{\sigma_1^2\sigma_2^2}{(\sigma_1^2 + \sigma_2^2)}}
% \end{equation}
% 
% Esta ecuaci\'on es cuadr\'atica en x, y por lo tanto es proporcional a una funci\'on de densidad gausiana con desv\'io
% \begin{equation}
% \sigma_{\times} = \sqrt{\frac{\sigma_1^2\sigma_2^2}{\sigma_1^2+\sigma_2^2}}
% \end{equation}
% 
% y media
% \begin{equation}
%  \mu_{\times} = \frac{(\mu_1\sigma_2^2 + \mu_2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) }
% \end{equation}
% 
% Dado que un t\'ermino $\varepsilon = 0$ puede ser agregado para completar el cuadrado en $\theta$, esta prueba es suficiente cuando no se necesita una normalizaci\'on.
% Sea,
% \begin{equation}
%  \varepsilon = \frac{\mu_{\times}^2-\mu_{\times}^2}{2\sigma_{\times}^2} = 0
% \end{equation}
% 
% Al agregar este t\'ermino a $\theta$ tenemos
% \begin{equation}
%  \theta = \frac{x^2 - 2\mu_{\times}x + \mu_{\times}^2 }{2\sigma_{\times}^2} + \underbrace{\frac{ \frac{(\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) } - \mu_{\times}^2}{2\sigma_{\times}^2}}_{\varphi}
% \end{equation}
% 
% Reorganizando el t\'ermino $\varphi$
% \begin{equation}
% \begin{split}
% \varphi & = \frac{\frac{(\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) } - \left(\frac{(\mu_1\sigma_2^2 + \mu_2\sigma_1^2)}{(\sigma_1^2 + \sigma_2^2) }\right)^2 }{2\frac{\sigma_1^2\sigma_2^2}{\sigma_1^2+\sigma_2^2}}  \\
% & = \frac{(\sigma_1^2 + \sigma_2^2)(\mu_1^2\sigma_2^2 + \mu_2^2\sigma_1^2) - (\mu_1\sigma_2^2 + \mu_2\sigma_1^2)^2}{\sigma_1^2 + \sigma_2^2}\frac{1}{2\sigma_1^2\sigma_2^2} \\[0.3cm]
% & = \frac{(\mu_1^2\sigma_1^2\sigma_2^2 + \cancel{\mu_2^2\sigma_1^4} + \bcancel{\mu_1^2\sigma_2^4} + \mu_2^2\sigma_1^2\sigma_2^2) - (\bcancel{\mu_1^2\sigma_2^4} + 2\mu_1\mu_2\sigma_1^2\sigma_2^2 + \cancel{\mu_2^2\sigma_1^4} )}{\sigma_1^2 + \sigma_2^2}  \frac{1}{2\sigma_1^2\sigma_2^2} \\[0.3cm]
% & = \frac{(\sigma_1^2\sigma_2^2)(\mu_1^2 + \mu_2^2 - 2\mu_1\mu_2)}{\sigma_1^2 + \sigma_2^2}\frac{1}{2\sigma_1^2\sigma_2^2} = \frac{\mu_1^2 + \mu_2^2 - 2\mu_1\mu_2}{2(\sigma_1^2 + \sigma_2^2)} = \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)}
% \end{split}
% \end{equation}
% 
% Luego,
% \begin{equation}
%  \theta = \frac{(x-\mu_{\times})^2}{2\sigma_{\times}^2} + \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)}
% \end{equation}
% 
% Colocando esta forma de $\theta$ en su lugar
% \begin{equation}
% \begin{split}
%  N(x;y,\beta^2)N(x;\mu,\sigma^2) & = \frac{1}{2\pi\sigma_1\sigma_2}\text{exp}\Bigg(-\underbrace{\left( \frac{(x-\mu_{\times})^2}{2\sigma_{\times}^2} + \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)} \right)}_{\theta} \Bigg) \\
%  & = \frac{1}{2\pi\sigma_1\sigma_2}\text{exp}\left(  - \frac{(x-\mu_{\times})^2}{2\sigma_{\times}^2} \right) \text{exp} \left( - \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)} \right)
% \end{split}
% \end{equation}
% 
% Multiplicando por $\sigma_{\times}\sigma_{\times}^{-1}$
% \begin{equation}
% \overbrace{\frac{\cancel{\sigma_1\sigma_2}}{\sqrt{\sigma_1^2+\sigma_2^2}}}^{\sigma_{\times}} \frac{1}{\sigma_{\times}} \frac{1}{2\pi\cancel{\sigma_1\sigma_2}}\text{exp}\left(  - \frac{(x-\mu_{\times})^2}{2\sigma_{\times}^2} \right) \text{exp} \left( - \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)} \right)
% \end{equation}
% 
% Luego,
% \begin{equation}
%  \frac{1}{\sqrt{2\pi}\sigma_{\times}}\text{exp}\left(  - \frac{(x-\mu_{\times})^2}{2\sigma_{\times}^2} \right) \frac{1}{\sqrt{2\pi(\sigma_1^2+\sigma_2^2)}} \text{exp} \left( - \frac{(\mu_1 - \mu_2)^2}{2(\sigma_1^2 + \sigma_2^2)} \right)
% \end{equation}
% 
% Retonando a la integral
% \begin{equation}
% \begin{split}
% I & = \int N(x;\mu_{\times},\sigma_{\times}^2) \overbrace{N(\mu_1;\mu_2,\sigma_1^2 + \sigma_2^2)}^{\text{Escalar independiente de x}} dx \\[0.3cm]
% & = N(\mu_1;\mu_2,\sigma_1^2 + \sigma_2^2) \underbrace{\int N(x,\mu_{\times},\sigma_{\times}^2)  dx}_{\text{Integra 1}} \\
% & = N(\mu_1;\mu_2,\sigma_1^2 + \sigma_2^2)
% \end{split}
% \end{equation}
% 
% \subsection{Suma de n normales}\label{suma_normales_induccion}
% 
% Sabemos que
% 
% \begin{equation}
% t_n = \sum_{i=1}^n x_i \sim \int \dots \int \mathbb{I}(t_n= \sum_{i=1}^n x_i ) \left( \prod_{i=1}^n N(x_i;\mu_i,\sigma_i^2) \right) dx_1 \dots dx_n = N(t;\sum_{i=1}^n \mu_i,\sum_{i=1}^n \sigma_i^2 )
% \end{equation}
% 
% 
% Queremos probar por inducci\'on.
% \begin{equation}
%  P(n):= \int \dots \int \mathbb{I}(t_n= \sum_{i=1}^n x_i ) \left( \prod_{i=1}^n N(x_i;\mu_i,\sigma_i^2) \right) dx_1 \dots dx_n \overset{?}{=} N(t;\sum_{i=1}^n \mu_i,\sum_{i=1}^n \sigma_i^2 )
% \end{equation}
% 
% \paragraph{Casos base}
% 
% \begin{equation}
% \begin{split}
%  P(1) := \int \mathbb{I}(t_1 = x_1) N(x_1;\mu_1,\sigma_1^2) dx_1 = N(x;\mu_1,\sigma_1^2)
% \end{split}
% \end{equation}
% 
% Luego $P(1)$ es verdadera.
% 
% \begin{equation}
%  \begin{split}
% P(2) & := \iint \mathbb{I}(t_2 = x_1 + x_2) N(x_1|\mu_1, \sigma_1^2)N(x_2|\mu_2, \sigma_2^2) dx_1dx_2 \\
%  &= \int N(x_1|\mu_1, \sigma_1^2) N(t_2 - x_1|\mu_2, \sigma_2^2) dx_1   \\
%  & = \int N(x_1|\mu_1, \sigma_1^2) N(x_1|t_2 - \mu_2, \sigma_2^2) dx_1 \\
%  & \overset{*}{=} \int \underbrace{N(t_2|\mu_1+\mu_2,\sigma_1^2 + \sigma_2^2)}_{\text{const.}} \underbrace{N(x_1|\mu_{*},\sigma_{*}^2) dx_1}_{1} \\
%  & = N(t_2|\mu_1+\mu_2,\sigma_1^2 + \sigma_2^2)
%  \end{split}
%  \end{equation}
% 
%  Donde $\overset{*}{=}$ vale por la demostraci\'on de miltiplicaci\'on de normales en la secci\'on~\ref{multiplicacion_normales}.
%  Luego, vale $P(2)$.
% 
% 
% \paragraph{Paso inductivo} $P(n) \Rightarrow P(n+1)$
% 
% Sea,
% \begin{equation}
%  P(n) :=\int \dots \int \mathbb{I}(t_n= \sum_{i=1}^n x_i ) \left( \prod_{i=1}^n N(x_i;\mu_i,\sigma_i^2) \right) dx_1 \dots dx_n = N(t;\sum_{i=1}^n \mu_i,\sum_{i=1}^n \sigma_i^2 )
% \end{equation}
% 
% Queremos ver que vale $P(n+1)$
% 
% \begin{equation}
%  P(n+1) := \int \dots \int \mathbb{I}(t_{n+1}=  x_{n+1} + \sum_{i=1}^{n} x_i ) \left( \prod_{i=1}^{n} N(x_i;\mu_i,\sigma_i^2) \right) N(x_{n+1};\mu_{n+1},\sigma_{n+1}^2) dx_1 \dots dx_{n} dx_{n+1}
% \end{equation}
% 
% Por independencia
% \begin{equation}
%  \int N(x_{n+1};\mu_{n+1},\sigma_{n+1}^2) \left( \int \dots \int \mathbb{I}(t_{n+1}= x_{n+1} + \sum_{i=1}^{n} x_i ) \left( \prod_{i=1}^{n} N(x_i;\mu_i,\sigma_i^2) \right)  dx_1 \dots dx_{n}\right) dx_{n+1}
% \end{equation}
% 
% Por hip\'otesis inductiva
% \begin{equation}
%  \int N(x_{n+1};\mu_{n+1},\sigma_{n+1}^2) N(t-x_{n+1};\sum_{i=1}^n \mu_i,\sum_{i=1}^n \sigma_i^2) dx_{n+1}
% \end{equation}
% 
% Por demostraci\'on de la secci\'on~\ref{multiplicacion_normales},
% \begin{equation}
%   N(t;\mu_{n+1}+\sum_{i=1}^{n} \mu_i,\sigma_{n+1}^2 \sum_{i=1}^n \sigma_i^2) dx_{n+1}
% \end{equation}
% 
% Luego, vale $P(n+1)$.
% 
% \subsection{Normal por acumulada de Normal}
% 
% Queremos resolver la integral
% 
% \begin{equation}
%  f(x) = \int N(y;\mu_1,\sigma_1^2)\Phi(y+x;\mu_2,\sigma_2^2) dy
% \end{equation}
% 
% Para ello trabajamos con la drivada $\frac{\partial}{\partial x}f(x) = \theta(x)$,
% \begin{equation}
%  \theta(x) = \frac{\partial}{\partial x}\int N(y;\mu_1,\sigma_1^2)\Phi(y+x;\mu_2,\sigma_2^2) dy
% \end{equation}
% 
% Por ``Dominated convergence theorem, integrales y derivadas pueden intercambiar posiciones.
% \begin{equation}
%  \theta(x) = \int N(y;\mu_1,\sigma_1^2)\frac{\partial}{\partial x}\Phi(y+x;\mu_2,\sigma_2^2) dy
% \end{equation}
% 
% La derivada de $\Phi$ es justamente una normal,
% \begin{equation}
% \begin{split}
% \theta(x) & = \int N(y;\mu_1,\sigma_1^2)N(y+x;\mu_2,\sigma_2^2) dy \\
% & = \int N(y;\mu_1,\sigma_1^2)N(y;\mu_2-x,\sigma_2^2) dy
% \end{split}
% \end{equation}
% 
% Por la demostraci\'on de la secci\'on~\ref{multiplicacion_normales} sabemos
% \begin{equation}
%  \theta(x) = N(\mu_1; \mu_2 - x, \sigma_1^2 + \sigma_2^2)
% \end{equation}
% 
% Por simetr\'ia
% \begin{equation}
%  \theta(x) = N(x; \mu_2 - \mu_1, \sigma_1^2 + \sigma_2^2)
% \end{equation}
% 
% Retornando a $f(x)$
% \begin{equation}
%  f(x) = \Phi(x; \mu_2 - \mu_1, \sigma_1^2 + \sigma_2^2)
% \end{equation}
% 
% \subsection{Division de Normales}\label{sec:division_normales}
% 
% \begin{equation}
% \kappa = \frac{N(x;\mu_f,\sigma_f^2)}{N(x;\mu_g,\sigma_g^2)} = N(x;\mu_f,\sigma_f^2)N(x;\mu_g,\sigma_g^2)^{-1}
% \end{equation}
% 
% Por definici\'on
% \begin{equation}
% \begin{split}
% \kappa & = \frac{1}{\sqrt{2\pi}\sigma_f}e^{-\left(\frac{(x-\mu_f)^2}{2\sigma_f^2}\right)} \left( \frac{1}{\sqrt{2\pi}\sigma_g}e^{-\left(\frac{(x-\mu_g)^2}{2\sigma_g^2}\right)} \right)^{-1} \\[0.3cm]
% & = \frac{1}{\cancel{\sqrt{2\pi}}\sigma_f}e^{-\left(\frac{(x-\mu_f)^2}{2\sigma_f^2}\right)} \frac{\cancel{\sqrt{2\pi}}\sigma_g}{1} e^{\left(\frac{(x-\mu_g)^2}{2\sigma_g^2}\right)} \\[0.3cm]
% & = \frac{\sigma_g}{\sigma_f}\text{exp}\Bigg(-\underbrace{\Big(\frac{(x-\mu_f)^2}{2\sigma_f^2} - \frac{(x-\mu_g)^2}{2\sigma_g^2}\Big)}_{\theta}\Bigg)
% \end{split}
% \end{equation}
% 
% Reorganizando $\theta$
% \begin{equation}
% \begin{split}
%  \theta & = \frac{(x-\mu_f)^2}{2\sigma_f^2} - \frac{(x-\mu_g)^2}{2\sigma_g^2} = \frac{\sigma_g^2(x-\mu_f)^2 - \sigma_f^2(x-\mu_g)^2}{2\sigma_f^2\sigma_g^2} \\[0.3cm]
%  & = \frac{\sigma_g^2(x^2+\mu_f^2-2\mu_fx) - \sigma_f^2(x^2+\mu_g^2-2\mu_gx)}{2\sigma_f^2\sigma_g^2}
% \end{split}
% \end{equation}
% 
% Expandimos y ordenamos en base $x$,
% \begin{equation}
% \begin{split}
%  \theta & = \left((\sigma_g^2 - \sigma_f^2)x^2 - 2(\sigma_g^2\mu_f - \sigma_f^2\mu_g)x + (\sigma_g^2\mu_f^2 - \sigma_f^2\mu_g^2 )\right) \frac{1}{2\sigma_f^2\sigma_g^2} \\[0.3cm]
%  & = \left(x^2 - \frac{2(\sigma_g^2\mu_f - \sigma_f^2\mu_g)}{(\sigma_g^2 - \sigma_f^2)}x + \frac{(\sigma_g^2\mu_f^2 - \sigma_f^2\mu_g^2 )}{(\sigma_g^2 - \sigma_f^2)}\right) \frac{(\sigma_g^2 - \sigma_f^2)}{2\sigma_f^2\sigma_g^2}
% \end{split}
% \end{equation}
% 
% Esto es cuadr\'atico en x. Dado que un t\'ermino $\varepsilon=0$, independiente de $x$ puede ser agregado para completar el cuadrado en $\theta$, esta prueba es suficiente para dterminar la media y la varianza cuando no es necesario normalizar.
% 
% \begin{equation}
%  \sigma_{\div} = \sqrt{\frac{\sigma_f^2\sigma_g^2}{(\sigma_g^2 - \sigma_f^2)}}
% \end{equation}
% 
% \begin{equation}
%  \mu_{\div} = \frac{(\sigma_g^2\mu_f - \sigma_f^2\mu_g)}{(\sigma_g^2 - \sigma_f^2)}
% \end{equation}
% 
% agregado $\varepsilon = \frac{\mu_{\div}^2-\mu_{\div}^2}{2\sigma_{\div}^2}$
% 
% \begin{equation}
% \theta = \frac{x^2 - 2\mu_{\div} + \mu_{\div}^2 }{2\sigma_{\div}^2} + \underbrace{ \frac{ \frac{(\sigma_g^2\mu_f^2 - \sigma_f^2\mu_g^2)}{(\sigma_g^2 - \sigma_f^2)} - \mu_{\div}^2 }{2\sigma_{\div}^2} }_{\varphi}
% \end{equation}
% 
% Reorganizando $\varphi$
% \begin{equation}
% \begin{split}
%  \varphi & = \left( \frac{(\sigma_g^2\mu_f^2 - \sigma_f^2\mu_g^2)}{(\sigma_g^2 - \sigma_f^2)} - \left(\frac{(\sigma_g^2\mu_f - \sigma_f^2\mu_g)}{(\sigma_g^2 - \sigma_f^2)} \right)^2 \right) \frac{(\sigma_g^2 - \sigma_f^2)}{2\sigma_f^2\sigma_g^2} \\[0.3cm]
%  & = \left((\sigma_g^2\mu_f^2 - \sigma_f^2\mu_g^2)(\sigma_g^2 - \sigma_f^2) - \left((\sigma_g^2\mu_f - \sigma_f^2\mu_g) \right)^2 \right) \frac{1}{2\sigma_f^2\sigma_g^2(\sigma_g^2 - \sigma_f^2)} \\[0.3cm]
%  & =  \left( \cancel{\sigma_g^4\mu_f^2} - 2\sigma_f^2\sigma_g^2\mu_g^2 + \bcancel{\sigma_f^4\mu_g^2} - (\cancel{\sigma_g^4\mu_f^2} + \bcancel{\sigma_f^4\mu_g^2 } - 2\sigma_f^2\sigma_g^2\mu_f\mu_g)\right) \frac{1}{2\sigma_f^2\sigma_g^2(\sigma_g^2 - \sigma_f^2)}
%  \end{split}
% \end{equation}
% 
% Cancelando los $\sigma^2$
% \begin{equation}
%  \varphi = \frac{- \mu_g^2 - \mu_f^2 + 2\mu_f\mu_g}{2(\sigma_g^2 - \sigma_f^2)} = \frac{- (\mu_g - \mu_f)^2}{2(\sigma_g^2 - \sigma_f^2)}
% \end{equation}
% 
% Luego $\theta$
% \begin{equation}
%  \theta = \frac{(x - \mu_{\div})^2}{2\sigma_{\div}^2} - \frac{(\mu_g - \mu_f)^2)}{2(\sigma_g^2 - \sigma_f^2)}
% \end{equation}
% 
% Por lo tanto
% \begin{equation}
% \begin{split}
%  \kappa & = \frac{\sigma_g}{\sigma_f}  \, \text{exp}\left(- \frac{(x - \mu_{\div})^2}{2\sigma_{\div}^2} + \frac{(\mu_g - \mu_f)^2)}{2(\sigma_g^2 - \sigma_f^2)}  \right)\\[0.3cm]
%  & = \frac{\sigma_g}{\sigma_f} \, e^{-\frac{(x - \mu_{\div})^2}{2\sigma_{\div}^2}} \, e^{\frac{(\mu_g - \mu_f)^2)}{2(\sigma_g^2 - \sigma_f^2)}}
% \end{split}
% \end{equation}
% 
% Multiplicando por $\frac{\sqrt{2\pi}}{\sqrt{2\pi}}\frac{\sigma_{\div}}{\sigma_{\div}}\frac{\sqrt{\sigma_g^2 - \sigma_f^2}}{\sqrt{\sigma_g^2 - \sigma_f^2}}=1$,
% \begin{equation}
% \begin{split}
%  \kappa & =  \frac{1}{\sqrt{2\pi}\sigma_{\div}} \, e^{-\frac{(x - \mu_{\div})^2}{2\sigma_{\div}^2}} \, \left( \frac
%  {1}{\sqrt{2\pi(\sigma_g^2 - \sigma_f^2)} } e^{-\frac{(\mu_g - \mu_f)^2)}{2(\sigma_g^2 - \sigma_f^2)}} \right)^{-1} \, \frac{\sigma_{\div}}{\sqrt{\sigma_g^2 - \sigma_f^2}}\frac{\sigma_g}{\sigma_f}\\[0.3cm]
%  & = \frac{N\left(x; \mu_{\div},\sigma_{\div}\right)}{N\left(\mu_g;\mu_f,\sigma_g^2-\sigma_f^2\right)} \frac{\sigma_g^2}{\sigma_g^2 - \sigma_f^2}
% \end{split}
% \end{equation}
% 
% 
% 
% \section{More technical details} \label{app:technical}
% 
% \begin{leftbar}
% Appendices can be included after the bibliography (with a page break). Each
% section within the appendix should have a proper section title (rather than
% just \emph{Appendix}).
% 
% For more technical style details, please check out JSS's style FAQ at
% \url{https://www.jstatsoft.org/pages/view/style#frequently-asked-questions}
% which includes the following topics:
% \begin{itemize}
%   \item Title vs.\ sentence case.
%   \item Graphics formatting.
%   \item Naming conventions.
%   \item Turning JSS manuscripts into \proglang{R} package vignettes.
%   \item Trouble shooting.
%   \item Many other potentially helpful details\dots
% \end{itemize}
% \end{leftbar}
% 
% 
% \section[Using BibTeX]{Using \textsc{Bib}{\TeX}} \label{app:bibtex}
% 
% \begin{leftbar}
% References need to be provided in a \textsc{Bib}{\TeX} file (\code{.bib}). All
% references should be made with \verb|\cite|, \verb|\citet|, \verb|\citep|,
% \verb|\citealp| etc.\ (and never hard-coded). This commands yield different
% formats of author-year citations and allow to include additional details (e.g.,
% pages, chapters, \dots) in brackets. In case you are not familiar with these
% commands see the JSS style FAQ for details.
% 
% Cleaning up \textsc{Bib}{\TeX} files is a somewhat tedious task -- especially
% when acquiring the entries automatically from mixed online sources. However,
% it is important that informations are complete and presented in a consistent
% style to avoid confusions. JSS requires the following format.
% \begin{itemize}
%   \item JSS-specific markup (\verb|\proglang|, \verb|\pkg|, \verb|\code|) should
%     be used in the references.
%   \item Titles should be in title case.
%   \item Journal titles should not be abbreviated and in title case.
%   \item DOIs should be included where available.
%   \item Software should be properly cited as well. For \proglang{R} packages
%     \code{citation("pkgname")} typically provides a good starting point.
% \end{itemize}
% \end{leftbar}
% 
% \end{appendix}

%% -----------------------------------------------------------------------------


\end{document}
